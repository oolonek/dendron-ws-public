{"pageProps":{"note":{"id":"Mlb5F1TDswu1OkB4yKCXI","title":"Beast","desc":"","updated":1646061947037,"created":1634965352373,"custom":{},"fname":"tools.chemoinformatics.isfrag.beast","type":"note","vault":{"fsPath":"vault"},"contentHash":"fa4a4808a2571a5e9bdcc429e349718d","links":[{"type":"wiki","from":{"fname":"tools.chemoinformatics.isfrag.beast","id":"Mlb5F1TDswu1OkB4yKCXI","vaultName":"vault"},"value":"user.biolpc045600","alias":"@biolpc045600","position":{"start":{"line":32,"column":58,"offset":735},"end":{"line":32,"column":71,"offset":748},"indent":[]},"xvault":false,"to":{"fname":"user.biolpc045600"}},{"type":"ref","from":{"fname":"tools.chemoinformatics.isfrag.beast","id":"Mlb5F1TDswu1OkB4yKCXI","vaultName":"vault"},"value":"tools.chemoinformatics.isfrag","position":{"start":{"line":4,"column":1,"offset":57},"end":{"line":4,"column":35,"offset":91},"indent":[]},"xvault":false,"to":{"fname":"tools.chemoinformatics.isfrag"}}],"anchors":{"variant-of-the-is-fragmentation-recipee-on-the-beast":{"type":"header","text":"Variant of the is fragmentation recipee on the beast","value":"variant-of-the-is-fragmentation-recipee-on-the-beast","line":8,"column":0,"depth":1},"":{"type":"header","text":"","value":"","line":47,"column":0,"depth":5},"monday-28-february-2022":{"type":"header","text":"Monday 28 February 2022","value":"monday-28-february-2022","line":70,"column":0,"depth":2}},"children":[],"parent":"6qK8k4MF0vooncgMJZw5W","data":{}},"body":"<h1 id=\"beast\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#beast\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Beast</h1>\n<h1 id=\"variant-of-the-is-fragmentation-recipee-on-the-beast\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#variant-of-the-is-fragmentation-recipee-on-the-beast\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Variant of the is fragmentation recipee on the beast</h1>\n<p></p><p></p><div class=\"portal-container\">\n<div class=\"portal-head\">\n<div class=\"portal-backlink\">\n<div class=\"portal-title\">From <span class=\"portal-text-title\">Isfrag</span></div>\n<a href=\"/dendron-ws-public/notes/6qK8k4MF0vooncgMJZw5W\" class=\"portal-arrow\">Go to text <span class=\"right-arrow\">→</span></a>\n</div>\n</div>\n<div id=\"portal-parent-anchor\" class=\"portal-parent\" markdown=\"1\">\n<div class=\"portal-parent-fader-top\"></div>\n<div class=\"portal-parent-fader-bottom\"></div><p>Pasting an old recipee from ZettelKasten</p>\n<p>Linked to <a title=\"Private\" style=\"color: brown\" href=\"https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html\" target=\"_blank\">202002251433 (Private)</a> in silico fragmentation worflow.</p>\n<p>Children workflow on the beast MAPP </p>\n<p>Side notes : try to write everything as scripts so that they can be launched without a GUI (ex on X2Go or directly Boabab).</p>\n<h1 id=\"tutorial-for-npatlas-in-silico-fragmentation-data-treatment\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#tutorial-for-npatlas-in-silico-fragmentation-data-treatment\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Tutorial for NPatlas in silico fragmentation data treatment</h1>\n<h2 id=\"prior-to-fragmentation\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#prior-to-fragmentation\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Prior to fragmentation</h2>\n<h3 id=\"prepare-space-delimited-input-file\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#prepare-space-delimited-input-file\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Prepare space delimited input file</h3>\n<p>Complete metadate file is converted to list of Unique ID and smiles space separated (for cfm id input)</p>\n<p>python frag_list_preparator.py ../npatlas_data/np_atlas_2019_12.tsv ../npatlas_data/np_atlas_2019_12_for_frag.tsv NPAID SMILES</p>\n<p>python frag_list_preparator.py ../open_np_db_data/open_NP_db.tsv ../open_np_db_data/open_NP_db_tofrag.txt shortinchikey shortinchikey smiles</p>\n<h3 id=\"split-the-file\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#split-the-file\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Split the file</h3>\n<p>(Works on Linux based shells)</p>\n<p>split -a 5 -l 500 -d ../open<em>np_db_data/open_NP_db_tofrag.txt ../open_np_db_data/opennpdb_tofrag/opennpdb</em>\nsplit -a 5 -l 500 -d ./lotus<em>data/lotus_data_for_frag.txt ./lotus_data/lotus_data_for_frag/lotus_data</em></p>\n<p>split -a 5 -l 500 -d ./ ./lotus<em>data/lotus_data_for_frag/lotus_data</em>\nsplit -a 5 -l 500 -d cfm/cfm<em>input/platinum_tofrag.tsv cfm/cfm_input/splitted/lotus_to_frag</em></p>\n<p>This one allows to preserve extensions and is build on number of desired chunks without splitting lines\nsplit -a 5 -n l/199 -d --additional-suffix=.txt  cfm<em>input/sub_platinum_tofrag.tsv cfm_input/splitted/lotus_to_frag</em></p>\n<h3 id=\"when-using-the-docker-cli-files-need-to-have-an-extension-or-taken-as-folder-\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#when-using-the-docker-cli-files-need-to-have-an-extension-or-taken-as-folder-\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>When using the docker cli files need to have an extension (or taken as folder ?)</h3>\n<p>for f in *; do mv \"<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mi mathvariant=\"normal\">\"</mi><mi mathvariant=\"normal\">\"</mi></mrow><annotation encoding=\"application/x-tex\">f\" \"</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord\">\"\"</span></span></span></span></span>f.txt\"; done</p>\n<p>if you made a mistacke </p>\n<p>find / -type f -name '*.txt' -exec sh -c 'mv -- \"<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>0</mn><mi mathvariant=\"normal\">\"</mi><mi mathvariant=\"normal\">\"</mi></mrow><annotation encoding=\"application/x-tex\">0\" \"</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord\">0\"\"</span></span></span></span></span>{0%.txt}\"' {} \\;</p>\n<h3 id=\"prepare-mutilple-bash-file-to-launch-on-baobab\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#prepare-mutilple-bash-file-to-launch-on-baobab\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Prepare mutilple bash file to launch on baobab</h3>\n<p>(strangely enough the .sh incrementer script return an error on Linux, runned OK on MacOS command line )</p>\n<p>Note: apparently sbatch as been replaced by srun on the boabab server side. Be sure to update the scripts accordingly</p>\n<h2 id=\"fetching-cfm-predict-results\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#fetching-cfm-predict-results\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Fetching cfm-predict results</h2>\n<p>Download cfm-predict fragmentation results from the baob server using rsync command</p>\n<p>rsync -rvz -e 'ssh' --progress <a href=\"mailto:allardp@baobab2.unige.ch\">allardp@baobab2.unige.ch</a>:/home/allardp/CFM_results/npatlas ./results\nrsync -rvz -e 'ssh' --progress <a href=\"mailto:allardp@baobab2.unige.ch\">allardp@baobab2.unige.ch</a>:/home/allardp/CFM_results/coconut/ .</p>\n<p>find ./ -type f -name '*.mgf' | wc  </p>\n<p>allows to count all file in a folder\nHere 25090 files for NPatalas</p>\n<p>Coconut 384222 .log files</p>\n<p> 384150 mgf files</p>\n<h2 id=\"we-might-eventually-need-to-move-all-files-from-subfolders-recursively-to-a-superior-folder\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#we-might-eventually-need-to-move-all-files-from-subfolders-recursively-to-a-superior-folder\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>We might eventually need to move all files from subfolders recursively to a superior folder</h2>\n<p>find ./bacasable -type f -print0 | xargs -0 mv -t ./bacasable</p>\n<p>find ./results_coconut -type f -print0 | xargs -0 mv -t ./results_coconut</p>\n<h2 id=\"pruning-the-raw-log-files\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#pruning-the-raw-log-files\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Pruning the raw log files</h2>\n<p>The output of cfm-predict consist of .log file containing mass spectra, where each fragments are individually labelled and eventually linked to a substrcture. Such information might be usefull later but for now we only want to keep the raw ms data</p>\n<p>(need to define a help function here)</p>\n<p>python raw_log_treater_npatlas.py ../npatlas_data/results_npatlas/npatlas/ .log\npython raw_log_treater.py ../coconut_data/results_coconut/ .log</p>\n<p>At this step .log file should be pruned and contains only digits (m/z and intensities)</p>\n<p>for coconut Parsing directory../coconut_data/results_coconut/ with file extension :.log</p>\n<p>'mass' ../coconut_data/results_coconut/CNP0402147.log\n'mass' ../coconut_data/results_coconut/CNP0153817.log\n'mass' ../coconut_data/results_coconut/CNP0155980.log\n'mass' ../coconut_data/results_coconut/CNP0086807.log\n'mass' ../coconut_data/results_coconut/CNP0199206.log\n'mass' ../coconut_data/results_coconut/CNP0334817.log\n'mass' ../coconut_data/results_coconut/CNP0366374.log\n'mass' ../coconut_data/results_coconut/CNP0232712.log\n'mass' ../coconut_data/results_coconut/CNP0370068.log\n'mass' ../coconut_data/results_coconut/CNP0055178.log\n'mass' ../coconut_data/results_coconut/CNP0228597.log\n'mass' ../coconut_data/results_coconut/CNP0119974.log\n'mass' ../coconut_data/results_coconut/CNP0132139.log\n'mass' ../coconut_data/results_coconut/CNP0145457.log\n'mass' ../coconut_data/results_coconut/CNP0230801.log\n'mass' ../coconut_data/results_coconut/CNP0310370.log\n'mass' ../coconut_data/results_coconut/CNP0149436.log\n'mass' ../coconut_data/results_coconut/CNP0396848.log\n'mass' ../coconut_data/results_coconut/CNP0401434.log\n'mass' ../coconut_data/results_coconut/CNP0101561.log\n'mass' ../coconut_data/results_coconut/CNP0390928.log\n'mass' ../coconut_data/results_coconut/CNP0405256.log\n'mass' ../coconut_data/results_coconut/CNP0395006.log\n'mass' ../coconut_data/results_coconut/CNP0159145.log\n'mass' ../coconut_data/results_coconut/CNP0131085.log\n'mass' ../coconut_data/results_coconut/CNP0230696.log\n'mass' ../coconut_data/results_coconut/CNP0014450.log\n'mass' ../coconut_data/results_coconut/CNP0214739.log\n'mass' ../coconut_data/results_coconut/CNP0302005.log\n'mass' ../coconut_data/results_coconut/CNP0279314.log\n'mass' ../coconut_data/results_coconut/CNP0177036.log\n'mass' ../coconut_data/results_coconut/CNP0274256.log\n'mass' ../coconut_data/results_coconut/CNP0403745.log\n'mass' ../coconut_data/results_coconut/CNP0039287.log\n'mass' ../coconut_data/results_coconut/CNP0238803.log\n'mass' ../coconut_data/results_coconut/CNP0014261.log\n'mass' ../coconut_data/results_coconut/CNP0077076.log\n'mass' ../coconut_data/results_coconut/CNP0125300.log\n'mass' ../coconut_data/results_coconut/CNP0228582.log\n'mass' ../coconut_data/results_coconut/CNP0393136.log\n'mass' ../coconut_data/results_coconut/CNP0338003.log\n'mass' ../coconut_data/results_coconut/CNP0070182.log\n'mass' ../coconut_data/results_coconut/CNP0230961.log\n'mass' ../coconut_data/results_coconut/CNP0001326.log\n'mass' ../coconut_data/results_coconut/CNP0088652.log\n'mass' ../coconut_data/results_coconut/CNP0045797.log\n'mass' ../coconut_data/results_coconut/CNP0175458.log\n'mass' ../coconut_data/results_coconut/CNP0300969.log\n'mass' ../coconut_data/results_coconut/CNP0030335.log\n'mass' ../coconut_data/results_coconut/CNP0126194.log\n'mass' ../coconut_data/results_coconut/CNP0334816.log\n'mass' ../coconut_data/results_coconut/CNP0290616.log\n'mass' ../coconut_data/results_coconut/CNP0386127.log\n'mass' ../coconut_data/results_coconut/CNP0406328.log\n'mass' ../coconut_data/results_coconut/CNP0127289.log\n'mass' ../coconut_data/results_coconut/CNP0032755.log\n'mass' ../coconut_data/results_coconut/CNP0258640.log\n'mass' ../coconut_data/results_coconut/CNP0199475.log\n'mass' ../coconut_data/results_coconut/CNP0350989.log\n'mass' ../coconut_data/results_coconut/CNP0333350.log\n'mass' ../coconut_data/results_coconut/CNP0213544.log\n'mass' ../coconut_data/results_coconut/CNP0204567.log\n'mass' ../coconut_data/results_coconut/CNP0148525.log\n'mass' ../coconut_data/results_coconut/CNP0053639.log\n'mass' ../coconut_data/results_coconut/CNP0118368.log\n'mass' ../coconut_data/results_coconut/CNP0226584.log\n'mass' ../coconut_data/results_coconut/CNP0254221.log\n'mass' ../coconut_data/results_coconut/CNP0241364.log\n'mass' ../coconut_data/results_coconut/CNP0348684.log\n'mass' ../coconut_data/results_coconut/CNP0053255.log\n'mass' ../coconut_data/results_coconut/CNP0167909.log\n'mass' ../coconut_data/results_coconut/CNP0142603.log\nTreated 384150 files, skipped 72</p>\n<h2 id=\"populating-the-mgf-headers\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#populating-the-mgf-headers\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Populating the mgf headers</h2>\n<h3 id=\"preparation-of-the-adducted-metadata-table\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#preparation-of-the-adducted-metadata-table\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Preparation of the adducted metadata table</h3>\n<p>We need to prepare and adducted dataframe containing the protonated and deprotonated masses</p>\n<p>This script recquire rdkit so we build a environment.yml file from a dedicated conda env</p>\n<p>conda env export -n conda-env -f /path/to/environment.yml</p>\n<p>Eventually you need to fetch the file from the internet (use wget )</p>\n<p>wget <a href=\"https://zenodo.org/record/3547718/files/COCONUT4MetFrag.csv?download=1\">https://zenodo.org/record/3547718/files/COCONUT4MetFrag.csv?download=1</a></p>\n<p>Sometimes since SMILES or INchi can yield error and since there is a MF field, the emass can be calculated directly form the MF as described here\n<a href=\"https://bioinformatics.stackexchange.com/a/9273\">https://bioinformatics.stackexchange.com/a/9273</a>. Noooop actually not working since the GetMass() function yield a molecular weight and not and exact mass ....</p>\n<p>Script table_adducter_script.py is adapted to cope with different delimiters ... beware and note that $ is mandatory to input the tab delim</p>\n<p>python table_adducter_npatlas_script.py ../npatlas_data/np_atlas_2019_12.tsv ../npatlas_data/np_atlas_2019_12_adducted.tsv</p>\n<p>python table_adducter_script.py ../coconut_data/COCONUT4MetFrag.csv ',' ../coconut_data/COCONUT4MetFrag_adducted.csv $'\\t'</p>\n<h3 id=\"addition-of-the-metadata-to-the-individual-mgf-headers\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#addition-of-the-metadata-to-the-individual-mgf-headers\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Addition of the metadata to the individual mgf headers</h3>\n<p>We can now populate each raw mgf with its corresponding metadata. For this we use the treat_npatlas.py script</p>\n<p>python treat_npatlas.py ../npatlas_data/np_atlas_2019_12_adducted.tsv ../npatlas_data/results_npatlas/npatlas/</p>\n<p>python mgf_header_populater.py ../coconut_data/COCONUT4MetFrag_adducted.csv ../coconut_data/results_coconut/ Identifier</p>\n<p>on coconut </p>\n<p>Treated 384150 files, skipped 28161.</p>\n<h2 id=\"generating-the-final-spectral-file\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#generating-the-final-spectral-file\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Generating the final spectral file</h2>\n<p>We concatenate each documented mgf files to a single spectral mgf file.</p>\n<p>find ./ -type f -name '<em>.mgf' | while read F; do cat ${F} >> ../../npatlas_ISDB_pos.mgf; done\nfind ./ -type f -name '</em>.mgf' | while read F; do cat ${F} >> ../../coconut_ISDB_pos.mgf; done</p>\n<h2 id=\"outputting-non-fragmented-entries\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#outputting-non-fragmented-entries\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Outputting non-fragmented entries</h2>\n<p>For several reasons (charged compounds, some tautomers, structures too heavy to be fragmented in a reasonable amount of time) some entries might not have been fragmented. </p>\n<p>To find them we will first list all correctly converted mgf</p>\n<p>find ./ -type f -name '<em>.mgf' | sed 's!.</em>/!!' | sed 's!^!!' >  list_mgf.txt</p>\n<p>%%here eventually without the extension</p>\n<p>find ./ -type f -name '<em>.mgf' | sed 's!.</em>/!!' | sed 's!.mgf!!' >  ../../list_mgf.txt</p>\n<p>And then the list is compared to the initial input using the table_comparator.py </p>\n<p>python table_comparator.py ../npatlas_data/npatlas_for_frag.txt ../npatlas_data/list_mgf.txt ../npatlas_data/unfragged_list.txt</p>\n<h3 id=\"check-molvs-for-structure-standardization\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#check-molvs-for-structure-standardization\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>check molVS for structure standardization</h3>\n<p><a href=\"https://molvs.readthedocs.io/en/latest/index.html\">https://molvs.readthedocs.io/en/latest/index.html</a></p>\n</div></div><p></p><p></p>\n<p>I launched too many job on the beast so at the end memory was full and all cores saturated.\nNeed to find a way to handle this.\nI killed everything using </p>\n<p>sudo pkill cfm\nsudo pkill docker</p>\n<p>I will now need to list all calculated spectra</p>\n<p>~/cfm/cfm_output$ ls > ../calculated_spectra.txt</p>\n<p>I then fetch this back\nOr rather I will set up a connection to the beast via VSCode</p>\n<p>We use sed line to remove the extensions </p>\n<p>sed 's|.log||g' calculated_spectra.txt</p>\n<p>the -i operator allows to do it inplace</p>\n<p>sed -i 's|.log||g' calculated_spectra.txt</p>\n<p>I upload the full platinium to the beast\nrsync -rvz -e 'ssh' --progress ./platinum.tsv.gz allardpm<a title=\"Private\" style=\"color: brown\" href=\"https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html\" target=\"_blank\">@biolpc045600 (Private)</a>:/home/allardpm/cfm/</p>\n<p>I run the\nfrag_list_preparator_nb.py</p>\n<p>gzip -d  sub_platinum_tofrag.tsv.gz</p>\n<h5 id=\"\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a></h5>\n<p>messing around with gnu parralel</p>\n<p>parallel -a names.txt echo\n<a href=\"https://blog.ronin.cloud/gnu-parallel/\">https://blog.ronin.cloud/gnu-parallel/</a></p>\n<p>mv argument list too long </p>\n<p>find . -name . -o -type d -prune -o \\\n-name '<em>.jpg' -o -name '</em>.png' -o -name '*.bmp' -o \\\n-exec mv -t targetdir/ {} +</p>\n<p>find Programs/cfm-id-code/cfm/bin/cfm_output/ \\\n-name '*.log' -o \\\n-exec mv -t cfm/cfm_output/ {} +</p>\n<p>find ./cfm_output -name '*.log' -exec mv {} . \\;</p>\n<h2 id=\"monday-28-february-2022\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#monday-28-february-2022\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Monday 28 February 2022</h2>\n<p>Taking over\nlast bash files looked like </p>\n<pre><code>#!/bin/sh\n\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib:/home/allardpm/Programs/lp_solve_5.5/lpsolve55/bin/ux64\ncd /home/allardpm/Programs/cfm-id-code/cfm/bin\n./cfm-predict /home/allardpm/cfm/cfm_input/splitted/lotus_to_frag_00097.txt 0.001 /home/allardpm/Programs/cfm-id-code/cfm-pretrained-models/[M+H]+/param_output.log /home/allardpm/Programs/cfm-id-code/cfm-pretrained-models/[M+H]+/param_config.txt 1 cfm_output/ &#x26; >/dev/nul\n</code></pre>\n<p>We move every body to a subfolder</p>\n<p>find ./ -name '*.log' -exec mv {} ./all_log \\;</p>","noteIndex":{"id":"gvOH1py1NfW3ihejtp1nt","title":"Root","desc":"","updated":1629628449617,"created":1629628449617,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"35415410233b3af68001893c83fd0c46","links":[{"type":"wiki","from":{"fname":"root","id":"gvOH1py1NfW3ihejtp1nt","vaultName":"vault"},"value":"user.oolonek","alias":"@oolonek","position":{"start":{"line":5,"column":7,"offset":225},"end":{"line":5,"column":15,"offset":233},"indent":[]},"xvault":false,"to":{"fname":"user.oolonek"}}],"anchors":{"welcome-to-dendron":{"type":"header","text":"Welcome to Dendron","value":"welcome-to-dendron","line":7,"column":0,"depth":1}},"children":["kPtYPP8JzWBTzWz6JpnkS","3LmAI71UuDJHeWZiY9h96","TyTThFOL2RNC8FAIj5bZN","e4C8xkTTKKue3fz5ywgBH","u88hb42Nk8jvzQwtMfM3z","rInb8zzM4kEHelz4CeWDa","hUOQrqfgNFdSu7GD8fP2c","J9JmfJgjDT8Oz6WilFnKw","Iu50F9KOgYp0CDpwKBlx6","xZShWyRUMIXQaN30pKmCM","f1fsD9inrKMVapeKNhEhT","VhvHTRFNvIEee7odQvekB","D2j8S1AufMK6GbZTZ9BJz","HMvEFZAnQOxD77TnbVwGV","NYpAWkhSLKKkHIbDIbshA","0MSZusMXhweDvHD3Iggww","q5kFqQrTnytdWSux3nwOk","1PGMuBcw56lKG0Xu5sxIX","f4P2xBJLTHpQpJYiJh7BV","7KJGsaBJWOOHaHqElRaJq","BunyVngKi3As0C0CO5xhy","iRR8MxJPGIvfKl5pcOirA","3qcjidzC0tkyobYKlrWYc","uviazqrM9NUAMm9dWYVa7","7WpN3kiuBsunRJ17P3mGr","9j2pl0fgjc9tperwhyk7z9m","53WWGL5wGfRDGtBEJoqBd","EoQW6Rm5LYkkCxMgDVXHd","k7IyxWpd9nYqWlhZ96CAG","maJAMIUSNCqgSTXrQ7fu5","rrfMr3vOgkyJv21N8x99X"],"parent":null,"data":{},"body":"# Welcome to Dendron\n\nThis is the root of your dendron vault. If you decide to publish your entire vault, this will be your landing page. You are free to customize any part of this page except the frontmatter on top. \n\nKudos @oolonek, you did great job! \nWhen using https://oolonek.github.io/dendron-ws-private/, here is what I got:\n\n<img width=\"1676\" alt=\"Capture d’écran 2021-08-22 à 13 19 54\" src=\"https://user-images.githubusercontent.com/44283913/130353241-43ba98eb-d947-473c-be08-d924f0ef585b.png\">\n\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":4,"useFMTitle":true,"useNoteTitleForLink":true,"mermaid":true,"useKatex":true,"dev":{"enablePreviewV2":true},"site":{"copyAssets":true,"siteHierarchies":["root"],"siteRootDir":"docs","siteUrl":"https://oolonek.github.io","gh_edit_link":true,"gh_edit_link_text":"Click here to edit this page on Github !","gh_edit_repository":"https://github.com/oolonek/dendron-ws-public","gh_edit_branch":"main","gh_edit_view_mode":"edit","assetsPrefix":"/dendron-ws-public","usePrettyRefs":true,"siteLastModified":true,"title":"GrndStt's Dendron","description":"Personal knowledge space","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"usePrettyLinks":true,"siteNotesDir":"notes","siteFaviconPath":"favicon.ico","gh_root":"docs/","writeStubs":true,"siteIndex":"root"},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"dendronVersion":"0.77.1","vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false,"enableSmartRefs":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Dendron","description":"Personal Knowledge Space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true}}},"__N_SSG":true}
{"keys":[{"path":["title"],"id":"title","weight":1,"src":"title"},{"path":["body"],"id":"body","weight":1,"src":"body"}],"records":[{"i":0,"$":{"0":{"v":"This page has not yet sprouted","n":0.408},"1":{"v":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","n":0.189}}},{"i":1,"$":{"0":{"v":"Root","n":1},"1":{"v":"# Welcome to Dendron\n\nThis is the root of your dendron vault. If you decide to publish your entire vault, this will be your landing page. You are free to customize any part of this page except the frontmatter on top. \n\nKudos @oolonek, you did great job! \nWhen using https://oolonek.github.io/dendron-ws-private/, here is what I got:\n\n<img width=\"1676\" alt=\"Capture d’écran 2021-08-22 à 13 19 54\" src=\"https://user-images.githubusercontent.com/44283913/130353241-43ba98eb-d947-473c-be08-d924f0ef585b.png\">\n\n","n":0.126}}},{"i":2,"$":{"0":{"v":"Daily","n":1}}},{"i":3,"$":{"0":{"v":"Journal","n":1}}},{"i":4,"$":{"0":{"v":"2021","n":1}}},{"i":5,"$":{"0":{"v":"12","n":1}}},{"i":6,"$":{"0":{"v":"2021-12-17","n":1},"1":{"v":"\n# Friday 17 December 2021\n\n\nWhat did I do today ?\n\n\n1. woke up a bit late\n2. received the 150 * 90 cm blackboard for the lab\n3. chatted with Manu about the spectral search within KG and collab with Jakub\n4. chatted with Manu about concrete application cases and wider scope of LOTUS (required in the review process)\n5. thought about an organization system to share tasks between Manu and me (for now we thought about https://github.com/orgs/mapp-metabolomics-unit/projects/2)\n6. fetched pears amaples for Agroscope project\n7. reserved space for MAPP metabolomics in -80\n8. indicated to [[projects.didier-reinhardt]] the best sample prep protocl (second one: sinple MeOH extraction)\n9. 2 hours of college meeting\n10. checked in with L Weisskopf. Discussed about a new title for the SBL.00060 course.\n    * Métabolisme spécialisé\n    * Métabolisme spécialisé, écologie chinmique et santé hunaine\n13. 3-4 hours of LOTUS revisions with JLW and AR\n* added ideas of point 4. to the end of discussion\n15. tentative injection of Sreffen Van Reusst samples on the GCQToF. Epic fail. Inlet pressure to low.GC beeping. No way to get correct pressure and thus to inject. Abandonned\n","n":0.075}}},{"i":7,"$":{"0":{"v":"2020","n":1}}},{"i":8,"$":{"0":{"v":"12","n":1}}},{"i":9,"$":{"0":{"v":"11","n":1}}},{"i":10,"$":{"0":{"v":"10","n":1}}},{"i":11,"$":{"0":{"v":"0","n":1}}},{"i":12,"$":{"0":{"v":"0","n":1}}},{"i":13,"$":{"0":{"v":"07","n":1}}},{"i":14,"$":{"0":{"v":"06","n":1}}},{"i":15,"$":{"0":{"v":"05","n":1}}},{"i":16,"$":{"0":{"v":"03","n":1}}},{"i":17,"$":{"0":{"v":"Tech","n":1}}},{"i":18,"$":{"0":{"v":"Dumbphone","n":1},"1":{"v":"https://scottiestech.info/2019/09/17/4g-dumbphones-why-you-should-get-one-with-kaios/\n\n\n","n":1}}},{"i":19,"$":{"0":{"v":"Writing","n":1}}},{"i":20,"$":{"0":{"v":"Scientific_paper","n":1},"1":{"v":"\n# Scientific Papers\n\nScientific papers are for sharing your own original research work with other scientists or for reviewing the research conducted by others. As such, they are critical to the evolution of modern science, in which the work of one scientist builds upon that of others. To reach their goal, papers must aim to inform, not impress. They must be highly readable — that is, clear, accurate, and concise. They are more likely to be cited by other scientists if they are helpful rather than cryptic or self-centered.\n\nScientific papers typically have two audiences: first, the referees, who help the journal editor decide whether a paper is suitable for publication; and second, the journal readers themselves, who may be more or less knowledgeable about the topic addressed in the paper. To be accepted by referees and cited by readers, papers must do more than simply present a chronological account of the research work. Rather, they must convince their audience that the research presented is important, valid, and relevant to other scientists in the same field. To this end, they must emphasize both the motivation for the work and the outcome of it, and they must include just enough evidence to establish the validity of this outcome.\n\nPapers that report experimental work are often structured chronologically in five sections: first, Introduction; then Materials and Methods, Results, and Discussion (together, these three sections make up the paper's body); and finally, Conclusion.\n\nThe Introduction section clarifies the motivation for the work presented and prepares readers for the structure of the paper.\nThe Materials and Methods section provides sufficient detail for other scientists to reproduce the experiments presented in the paper. In some journals, this information is placed in an appendix, because it is not what most readers want to know first.\nThe Results and Discussion sections present and discuss the research results, respectively. They are often usefully combined into one section, however, because readers can seldom make sense of results alone without accompanying interpretation — they need to be told what the results mean.\nThe Conclusion section presents the outcome of the work by interpreting the findings at a higher level of abstraction than the Discussion and by relating these findings to the motivation stated in the Introduction.\n(Papers reporting something other than experiments, such as a new method or technology, typically have different sections in their body, but they include the same Introduction and Conclusion sections as described above.)\n\nAlthough the above structure reflects the progression of most research projects, effective papers typically break the chronology in at least three ways to present their content in the order in which the audience will most likely want to read it. First and foremost, they summarize the motivation for, and the outcome of, the work in an abstract, located before the Introduction. In a sense, they reveal the beginning and end of the story — briefly — before providing the full story. Second, they move the more detailed, less important parts of the body to the end of the paper in one or more appendices so that these parts do not stand in the readers' way. Finally, they structure the content in the body in theorem-proof fashion, stating first what readers must remember (for example, as the first sentence of a paragraph) and then presenting evidence to support this statement.\n\n## The introduction\n\n This is a chapter from Jean-luc Doumont's book, Trees, maps and theorems.\n View Full-Size Image An effective introduction for a paper\n\nThe introduction reproduced here exhibits the four components that readers find useful as they begin to read a paper.\nIn the Introduction section, state the motivation for the work presented in your paper and prepare readers for the structure of the paper. Write four components, probably (but not necessarily) in four paragraphs: context, need, task, and object of the document.\n* First, provide some context to orient those readers who are less familiar with your topic and to establish the importance of your work.\n* Second, state the need for your work, as an opposition between what the scientific community currently has and what it wants.\n* Third, indicate what you have done in an effort to address the need (this is the task).\n* Finally, preview the remainder of the paper to mentally prepare readers for its structure, in the object of the document.\n\n### Context and need\n\nAt the beginning of the Introduction section, the context and need work together as a funnel: They start broad and progressively narrow down to the issue addressed in the paper. To spark interest among your audience — referees and journal readers alike — provide a compelling motivation for the work presented in your paper: The fact that a phenomenon has never been studied before is not, in and of itself, a reason to study that phenomenon.\n\nWrite the context in a way that appeals to a broad range of readers and leads into the need. Do not include context for the sake of including context: Rather, provide only what will help readers better understand the need and, especially, its importance. Consider anchoring the context in time, using phrases such as recently, in the past 10 years, or since the early 1990s. You may also want to anchor your context in space (either geographically or within a given research field).\n\nConvey the need for the work as an opposition between actual and desired situations. Start by stating the actual situation (what we have) as a direct continuation of the context. If you feel you must explain recent achievements in much detail — say, in more than one or two paragraphs — consider moving the details to a section titled State of the art (or something similar) after the Introduction, but do provide a brief idea of the actual situation in the Introduction. Next, state the desired situation (what we want). Emphasize the contrast between the actual and desired situations with such words as but, however, or unfortunately.\n\nOne elegant way to express the desired part of the need is to combine it with the task in a single sentence. This sentence expresses first the objective, then the action undertaken to reach this objective, thus creating a strong and elegant connection between need and task. Here are three examples of such a combination:\n\n* To confirm this assumption, we studied the effects of a range of inhibitors of connexin channels . . . on . . .\n\n* To assess whether such multiple-coil sensors perform better than single-signal ones, we tested two of them — the DuoPXK and the GEMM3 — in a field where . . .\n\n* To form a better view of the global distribution and infectiousness of this pathogen, we examined 1645 postmetamorphic and adult amphibians collected from 27 countries between 1984 and 2006 for the presence of . . .\n\n### Task and object\nAn Introduction is usually clearer and more logical when it separates what the authors have done (the task) from what the paper itself attempts or covers (the object of the document). In other words, the task clarifies your contribution as a scientist, whereas the object of the document prepares readers for the structure of the paper, thus allowing focused or selective reading.\n\nFor the task,\n\n* use whoever did the work (normally, you and your colleagues) as the subject of the sentence: we or perhaps the authors;\n* use a verb expressing a research action: measured, calculated, etc.;\n* set that verb in the past tense.\n\nThe three examples below are well-formed tasks.\n\n* To confirm this assumption, we studied the effects of a range of inhibitors of connexin channels, such as the connexin mimetic peptides Gap26 and Gap27 and anti-peptide antibodies, on calcium signaling in cardiac cells and HeLa cells expressing connexins.\n\n* During controlled experiments, we investigated the influence of the HMP boundary conditions on liver flows.\n\n* To tackle this problem, we developed a new software verification technique called oblivious hashing, which calculates the hash values based on the actual execution of the program.\n\nThe list below provides examples of verbs that express research actions:\n\napply \nWe applied Laklöter's principle to . . . \nassess\tWe assessed the effects of larger doses of . . .\ncalculate \nWe calculated the photoluminescence spectrum of . . . \ncompare\tWe compared the effects of . . . to those of . . .\ncompute\tWe computed the velocity predicted by . . .\nderive\tWe derived a new set of rules for . . .\ndesign\tWe designed a series of experiments to . . .\ndetermine\tWe determined the complete nucleotide sequence of . . . \ndevelop\tWe developed a new algorithm to . . .\nevaluate\tWe evaluated the efficacy and biocompatibility of . . .\nexplore\tWe explored the relationship between . . .\nimplement\tWe implemented a genetic algorithm for . . .\ninvestigate\tWe investigated the behavior of . . .\nmeasure\tWe measured the concentration of cadmium in . . .\nmodel\tWe modeled the diffraction behavior of . . .\nFor the object of the document,\n\nuse the document itself as the subject of the sentence: this paper, this letter, etc.;\nuse a verb expressing a communication action: presents, summarizes, etc.;\nset the verb in the present tense.\nThe three examples below are suitable objects of the document for the three tasks shown above, respectively.\n\nThis paper clarifies the role of CxHc on calcium oscillations in neonatal cardiac myocytes and calcium transients induced by ATP in HL-cells originated from cardiac atrium and in HeLa cells expressing connexin 43 or 26.\n\nThis paper presents the flow effects induced by increasing the hepatic-artery pressure and by obstructing the vena cava inferior.\n\nThis paper discusses the theory behind oblivious hashing and shows how this approach can be applied for local software tamper resistance and remote code authentication.\n\nThe list below provides examples of verbs that express communication actions:\n\nclarify \nThis paper clarifies the role of soils in . . .\ndescribe\tThis paper describes the mechanism by which . . .\ndetail\tThis paper details the algorithm used for . . .\ndiscuss\tThis paper discusses the influence of acidity on . . .\nexplain\tThis paper explains how the new encoding scheme . . .\noffer\tThis paper offers four recommendations for . . .\npresent\tThis paper presents the results of . . .\nproposes\tThis paper proposes a set of guidelines for . . .\nprovide\tThis paper provides the complete framework and . . .\nreport\tThis paper reports on our progress so far . . .\nsummarize\tThis paper summarizes our results for 27 patients with . . .\nThe body\nEven the most logical structure is of little use if readers do not see and understand it as they progress through a paper. Thus, as you organize the body of your paper into sections and perhaps subsections, remember to prepare your readers for the structure ahead at all levels. You already do so for the overall structure of the body (the sections) in the object of the document at the end of the Introduction. You can similarly prepare your readers for an upcoming division into subsections by introducing a global paragraph between the heading of a section and the heading of its first subsection. This paragraph can contain any information relating to the section as a whole rather than particular subsections, but it should at least announce the subsections, whether explicitly or implicitly. An explicit preview would be phrased much like the object of the document: \"This section first . . . , then . . . , and finally . . . \"\n\nAlthough papers can be organized into sections in many ways, those reporting experimental work typically include Materials and Methods, Results, and Discussion in their body. In any case, the paragraphs in these sections should begin with a topic sentence to prepare readers for their contents, allow selective reading, and — ideally — get a message across.\n\n## Materials and methods\n This is a chapter from Jean-luc Doumont's book, Trees, maps and theorems.\n View Full-Size Image A paragraph of materials and methods\nThis paragraph of materials and methods expresses the main idea first, in a topic sentence, so readers immediately know what it is about.\nMost Materials and Methods sections are boring to read, yet they need not be. To make this section interesting, explain the choices you made in your experimental procedure: What justifies using a given compound, concentration, or dimension? What is special, unexpected, or different in your approach? Mention these things early in your paragraph, ideally in the first sentence. If you use a standard or usual procedure, mention that upfront, too. Do not make readers guess: Make sure the paragraph's first sentence gives them a clear idea of what the entire paragraph is about. If you feel you cannot or need not do more than list items, consider using a table or perhaps a schematic diagram rather than a paragraph of text.\n\n## Results and discussion\n This is a chapter from Jean-luc Doumont's book, Trees, maps and theorems.\n View Full-Size Image A paragraph of results and discussion\nThis paragraph of results and discussion (above) can easily be rewritten (below) to convey the message first, not last.\nThe traditional Results and Discussion sections are best combined because results make little sense to most readers without interpretation.\nWhen reporting and discussing your results, do not force your readers to go through everything you went through in chronological order. Instead, state the message of each paragraph upfront: Convey in the first sentence what you want readers to remember from the paragraph as a whole. Focus on what happened, not on the fact that you observed it. Then develop your message in the remainder of the paragraph, including only that information you think you need to convince your audience.\n\n## The conclusion\n This is a chapter from Jean-luc Doumont's book, Trees, maps and theorems.\n View Full-Size Image An effective conclusion from a paper\nThis paragraph of results and discussion (above) can easily be rewritten (below) to convey the message first, not last.\nIn the Conclusion section, state the most important outcome of your work. Do not simply summarize the points already made in the body — instead, interpret your findings at a higher level of abstraction. Show whether, or to what extent, you have succeeded in addressing the need stated in the Introduction. At the same time, do not focus on yourself (for example, by restating everything you did). Rather, show what your findings mean to readers. Make the Conclusion interesting and memorable for them.\nAt the end of your Conclusion, consider including perspectives — that is, an idea of what could or should still be done in relation to the issue addressed in the paper. If you include perspectives, clarify whether you are referring to firm plans for yourself and your colleagues (\"In the coming months, we will . . . \") or to an invitation to readers (\"One remaining question is . . . \").\n\nIf your paper includes a well-structured Introduction and an effective abstract, you need not repeat any of the Introduction in the Conclusion. In particular, do not restate what you have done or what the paper does. Instead, focus on what you have found and, especially, on what your findings mean. Do not be afraid to write a short Conclusion section: If you can conclude in just a few sentences given the rich discussion in the body of the paper, then do so. (In other words, resist the temptation to repeat material from the Introduction just to make the Conclusion longer under the false belief that a longer Conclusion will seem more impressive.)\n\n## The abstract\n This is a chapter from Jean-luc Doumont's book, Trees, maps and theorems.\n View Full-Size Image An effective abstract\nIn just under 200 words, the abstract reproduced here conveys the motivation for and the outcome of the work with some accuracy but without intimidating readers by its length.\nThe readers of a scientific paper read the abstract for two purposes: to decide whether they want to (acquire and) read the full paper, and to prepare themselves for the details presented in that paper. An effective abstract helps readers achieve these two purposes. In particular, because it is typically read before the full paper, the abstract should present what the readers are primarily interested in; that is, what they want to know first of all and most of all.\nTypically, readers are primarily interested in the information presented in a paper's Introduction and Conclusion sections. Primarily, they want to know the motivation for the work presented and the outcome of this work. Then (and only then) the most specialized among them might want to know the details of the work. Thus, an effective abstract focuses on motivation and outcome; in doing so, it parallels the paper's Introduction and Conclusion.\n\nAccordingly, you can think of an abstract as having two distinct parts — motivation and outcome — even if it is typeset as a single paragraph. For the first part, follow the same structure as the Introduction section of the paper: State the context, the need, the task, and the object of the document. For the second part, mention your findings (the what) and, especially, your conclusion (the so what — that is, the interpretation of your findings); if appropriate, end with perspectives, as in the Conclusion section of your paper.\n\nAlthough the structure of the abstract parallels the Introduction and Conclusion sections, it differs from these sections in the audience it addresses. The abstract is read by many different readers, from the most specialized to the least specialized among the target audience. In a sense, it should be the least specialized part of the paper. Any scientist reading it should be able to understand why the work was carried out and why it is important (context and need), what the authors did (task) and what the paper reports about this work (object of the document), what the authors found (findings), what these findings mean (the conclusion), and possibly what the next steps are (perspectives). In contrast, the full paper is typically read by specialists only; its Introduction and Conclusion are more detailed (that is, longer and more specialized) than the abstract.\n\nAn effective abstract stands on its own — it can be understood fully even when made available without the full paper. To this end, avoid referring to figures or the bibliography in the abstract. Also, introduce any acronyms the first time you use them in the abstract (if needed), and do so again in the full paper (see Mechanics: Using abbreviations).\n\n\n\n-----\n\n## Snippet\n\nUse the ctno snippet (type ctno and tab or auto complete to have a predefined structure)\n\n# Title\n\n## Context (of the paper/doc/note/paragraph)\nFirst, provide some context to orient those readers who are less familiar with your topic and to establish the importance of your work.\n## Need (of the paper/doc/note/paragraph)\nSecond, state the need for your work, as an opposition between what the scientific community currently has and what it wants.\n## Task (of the paper/doc/note/paragraph)\nThird, indicate what you have done in an effort to address the need (this is the task).\n## Object (of the paper/doc/note/paragraph)\nFinally, preview the remainder of the paper to mentally prepare readers for its structure, in the object of the document.\n","n":0.018}}},{"i":21,"$":{"0":{"v":"Notes","n":1},"1":{"v":"\n\n# Taking notes vs. making notes\n\n[[nesslabs]]\n\nhttps://nesslabs.com/from-note-taking-to-note-making?ck_subscriber_id=1121227337&utm_source=convertkit&utm_medium=email&utm_campaign=Creating+Habits+%F0%9F%A7%A4%20-%205117179\n\n\nhttps://www.scotthyoung.com/blog/2021/01/11/how-to-take-notes/\n\n","n":0.408}}},{"i":22,"$":{"0":{"v":"Smart_notes","n":1},"1":{"v":"\n## Principles of Smart Notes \n\nhttps://takesmartnotes.com/\n\n## The four underlying principles\n\n1. Writing is the only thing that matters\n2. Simplicity is paramount\n3. Nobody ever starts from scratch\n4. Let the work carry you forward\n\n---\n\n\n\nhttps://jamesclear.com/deliberate-practice-theory #prodporn\n","n":0.177}}},{"i":23,"$":{"0":{"v":"Wikidata","n":1}}},{"i":24,"$":{"0":{"v":"Sparql","n":1},"1":{"v":"\n# SPARQL queries\n\n\n## All organisms containing compound for which a given MeSh id has been reported.\n\nChange MeSH Id according to https://meshb.nlm.nih.gov/search\n\nhttps://w.wiki/vo9\n\n### displayed as a treemap\n\nhttps://w.wiki/zkK\n\n\n## compounds in organisms who have a parent taxon with a given taxon name\n\nhttps://w.wiki/vo$\n\n## compounds in organisms who have a parent taxon with a given taxon name - grouped and counted \n\nhttps://w.wiki/368M\n\n## compounds in organisms who have a parent taxon with a given taxon name - with mf and accurate mass\n\n\nhttps://w.wiki/36Ki\n\n\n\n## compounds displaying a found in a taxon property\n\nhttps://w.wiki/q$H\n\n## idsm powered !!!\n\n\nhttps://w.wiki/xMJ\n\n[[mail_jakub|scratch.2021.02.02.150258.mail_jakub]] \n\n## genus counting indole substrutcures\n\nThis SPAQRL query is based on a proposition of Jakub Galgonek <jakub.galgonek@uochb.cas.cz> (https://idsm.elixir-czech.cz/) and adapted by Pierre-Marie Allard (pierre-marie.allard@unige.ch)\nIt returns an order list of organisms known to produce chemical compounds having an indolic moiety.\nThe organisms are aggregated at the parent taxon level, and the list is ordered by number of compound occurence in the parent t\n\nhttps://w.wiki/xMN\n\n\n## all molecules isolated by author X\n\nhttps://w.wiki/32D6\nhttps://w.wiki/32$m\n\n\n## count of the authors having isolated a given scaffold\n\nhttps://w.wiki/32DF\n\n## compare authors by count of compound\n\nhttps://w.wiki/32Vb\nhttps://w.wiki/32Vk (bar-chart)\n\n\n## compare authors by count of compound (substructure-refinable)\n\nhttps://w.wiki/32Vd\n\n## compare authors by count of compound (structuresimilarity-refinable)\n\nhttps://w.wiki/32Vg (indolic)\nhttps://w.wiki/32Vj (bubblechart - indolic)\nhttps://w.wiki/32Vi (bubblechart - tropanic)\n\n## count of authors isolating substances with a given role\n\nhttps://w.wiki/32Vr\n\n## all distinct article/substances/org for a given biological role\n\nhttps://w.wiki/32Vu\n\n## all disticnt antibiotics\n\nhttps://w.wiki/32Vv\n\n\n## drug-prot interaction \n\n```SPARQL\nSELECT DISTINCT ?parent_taxon ?parent_taxon_name ?compound ?interaction ?compoundLabel ?geneLabel ?biological_processLabel ?diseaseLabel WHERE {\n  #?compound wdt:P2868 ?mesh.\n  #?mesh wdt:P486 \"D000962\".\n  ?compound wdt:P235 ?inchikey.\n  {\n    ?compound p:P703 ?statement.\n    ?statement ps:P703 ?taxon.\n    ?taxon wdt:P171 ?parent_taxon.\n    OPTIONAL { ?taxon wdt:P171 ?parent_taxon. }\n    OPTIONAL { ?parent_taxon wdt:P225 ?parent_taxon_name. }\n    {\n      ?statement prov:wasDerivedFrom ?ref.\n      ?ref pr:P248 ?reference.\n      ?reference wdt:P356 ?reference_doi;\n        wdt:P1476 ?reference_title.\n    }\n   #?compound p:P129 ?interaction.\n   #?interaction wdt: wd:Q21119831.\n    \n    ?compound wdt:P129 ?gene_product .   # drug interacts with a gene_product\n    ?gene wdt:P688 ?gene_product .  # gene_product (usually a protein) is a product of a gene (a region of DNA)\n    ?disease  wdt:P2293 ?gene .    # genetic association between disease and gene\n    ?disease wdt:P279*  wd:Q12078 .  # limit to cancers wd:Q12078 (the * operator runs up a transitive relation..)\n    ?gene_product wdt:P682 ?biological_process . #add information about the GO biological processes that the gene is related to \n\n    ?biological_process (wdt:P361|wdt:P279)* wd:Q14599311.\n  }\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n}\n  \nGROUP BY ?parent_taxon ?parent_taxon_name ?compound ?interaction ?compoundLabel ?geneLabel ?biological_processLabel ?diseaseLabel\n#ORDER BY DESC (?count)\n```\n\n\n## Generic LOTUS queries\n\nhttps://w.wiki/$Q$\nhttps://w.wiki/$R3\nhttps://w.wiki/$RD apparently working !\nhttps://w.wiki/$RR with wd: for structure and org\nhttps://w.wiki/$RU wd: for everyone ...still ok\nhttps://w.wiki/$SF full monty\n\n## Sachem non-permanent endpoint\n\nhttps://idsm.elixir-czech.cz:2443/sachem/#/search\n\n\n## Sachem grand parents\nhttps://w.wiki/32Wz\n\n## Retrun compound present in invasive species\n\nhttps://w.wiki/32fa\nhttps://w.wiki/32fc\n\n## check taxon for a givin INChikey (regex)\n\nhttps://w.wiki/32j3\n\n## chemotax graph queries\n\nhttps://w.wiki/32q9\nhttps://w.wiki/32qC\n\n\nhttps://w.wiki/32qN\n\n\n# to tweet \n\nAll the compounds found in the Streptomyces avermitilis taxon and the references documenting this link. \nhttps://w.wiki/33V$\n\nWe can remove the references to get all unique compounds found in the Streptomyces coelicolor\n\nhttps://w.wiki/33WG\n\n\n\nAll the biological taxa where the chemical compound erysodine is found in.\nhttps://w.wiki/33WA\n\n\n# all compounds produced by a given taxon or group of taxa (including children taxa) : \n\nhttps://w.wiki/4CMd\n\nwith ref\n\nhttps://w.wiki/4CMg\n\n\n\n# all compounds produced by a given taxon or group of taxa (including children taxa) which have a described bioactivity : \n\nhttps://w.wiki/3YMo\n\nresumed as treemap https://w.wiki/3YMt\n\nfor archive on zenodo https://w.wiki/4N8G\nresults https://w.wiki/4N8J\n\n\n# molecules found within vegetables\n\nhttps://w.wiki/4EAh\n\n# molecules found within toxic plants\n\n\nhttps://w.wiki/4EAw\n\n#  mlecules in IUCN threatned species\n\nhttps://w.wiki/4EGg\n\nhttps://w.wiki/4EHQ\n\n\n\n# looking for molecules present in old species according to life span\n\nhttps://w.wiki/4EH8\nhttps://w.wiki/4EHB\n\nwith preclass\n\nhttps://w.wiki/4EHD\n\nand prepreclass \n\nat all levels\nhttps://w.wiki/4EHH\n\nat a single level\n\nhttps://w.wiki/4EHJ\n\n\nclassed by chem classes\nhttps://w.wiki/4EHP\n\n\n\n\n# Messing around with pathways\n\nhttps://w.wiki/4EK7\n\noriginal query \n\nhttps://w.wiki/4EK9\n\n\n# highest mountains in Switzerland \n\nhttps://w.wiki/4EKE\n\n\n# all biologist with a twitter account\n\n\nhttps://w.wiki/4EKW\n\nstrictly biologists\nhttps://w.wiki/4EKM\n\neducated in Switzerland \n\nhttps://w.wiki/4EKk\n\n# example for prsenattion UniFr\n\nhttps://w.wiki/4EMf \nAll compounds + ref for S. coelicolor\n\nhttps://w.wiki/4EMo (bioact listed)\n\n#  Compounds from species wuth given IUCN status and lifespan\nhttps://w.wiki/4EMw\n\n# compounds in taxa and children filtered by SMILES pattern regex\n\nhttps://w.wiki/4JWv\n\n# Melochia genus query\n\nhttps://w.wiki/4VYy\n\n\n# IDSM queries \n\nPREFIX sachem: <http://bioinfo.uochb.cas.cz/rdf/v1.0/sachem#>\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\nPREFIX bd: <http://www.bigdata.com/rdf#>\nPREFIX wd: <http://www.wikidata.org/entity/>\nPREFIX wdt: <http://www.wikidata.org/prop/direct/>\nPREFIX wdtn: <http://www.wikidata.org/prop/direct-normalized/>\nPREFIX p: <http://www.wikidata.org/prop/>\nPREFIX prov: <http://www.w3.org/ns/prov#>\nPREFIX ps: <http://www.wikidata.org/prop/statement/>\nPREFIX pr: <http://www.wikidata.org/prop/reference/>\nPREFIX endpoint: <https://idsm.elixir-czech.cz/sparql/endpoint/>\n\n\n\n#title: Which are the available referenced structure-organism pairs on Wikidata? (example limited to 1000 results)\nSELECT DISTINCT ?structure ?structure_inchikey ?taxon ?taxon_name ?reference ?reference_doi WHERE {\n  ?structure wdt:P235 ?structure_inchikey;       # get the inchikey\n    p:P703[                                      # statement found in taxon\n     ps:P703 ?taxon;                             # get the taxon\n     (prov:wasDerivedFrom/pr:P248) ?reference ]. # get the reference\n  ?taxon wdt:P225 ?taxon_name.                   # get the taxon scientific name\n  ?reference wdt:P356 ?reference_doi.            # get the reference DOI\n}\nLIMIT 10\n\n\n\n\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\nPREFIX sachem: <http://bioinfo.uochb.cas.cz/rdf/v1.0/sachem#>\nPREFIX endpoint: <https://idsm.elixir-czech.cz/sparql/endpoint/>\n\nSELECT * WHERE {\n  SERVICE endpoint:chebi {\n    ?COMPOUND sachem:substructureSearch\n        [ sachem:query \"CC(=O)Oc1ccccc1C(O)=O\" ]\n  }\n  ?COMPOUND rdfs:label ?o\n}\n\n","n":0.038}}},{"i":25,"$":{"0":{"v":"Scripts","n":1},"1":{"v":"\nHow cool would this be to have a script allowing to automatically fetch the wikidata link and id of any selected word.\nThis would clearly facilitate the addition of  wd links in manuscripts and documents. Such script could facilitate the use of wd while exploring a given topic. Ideally a small snapshot of the wd article could be displayed.\nI have no idea of how doable this is.\nApperas cool to me at the moment (2021-03-13 00:17) might be full BS.\n\n- [ ] check for similar plugins using google or wikipedia \nMake a small project out of this ? \nTo discuss with Daniel.\n\n\n----------\nSome related stuff\n\nhttps://chrome.google.com/webstore/detail/right-click-search-wikipe/eikmpmafdimllogceehaijmnlndineje\n\nhttps://chrome.google.com/webstore/detail/wikidata-search/ingjkjibhnkhomomlmlabndfmiaejkpn\n\nhttps://chrome.google.com/webstore/detail/entity-explosion/bbcffeclligkmfiocanodamdjclgejcn\n\n(the two previous ones are not functional on chromium ...)\n\n\nwikidata\nhttp://hints.macworld.com/article.php?story=20070528090709539\n\n\nNot exactly what we want here but could worth looking at it in more details\n(VScode plugin)https://github.com/blokhinnv/wikidataqidlabels\n\nQ1 (https://www.wikidata.org/wiki/Q1) Amazing stuff !\n\nHave a look into this API https://www.wikidata.org/w/api.php?action=help&modules=wbsearchentities\n\n\nhttps://www.digitalocean.com/community/tutorials/how-to-create-your-first-visual-studio-code-extension\nhttps://medium.com/@sanik.bajracharya/vscode-how-to-create-your-own-extension-pack-483385644c29\n","n":0.086}}},{"i":26,"$":{"0":{"v":"Scholia","n":1},"1":{"v":"\n# Scholia\n\nhttps://github.com/fnielsen/scholia\n\nScholia is a python package and webapp for interaction with scholarly information in Wikidata.\n\nhttps://scholia.toolforge.org/\n\n## Interest of Scholia as a curation page for LOTUS data\n\nCan deal with chemical object \n\nhttps://scholia.toolforge.org/inchikey/QOVGHDRCAGYGEB-FFZYJECLSA-N\n\n\n## Contribution \n\nhttps://github.com/fnielsen/scholia/blob/master/CONTRIBUTING.rst\n\n\n\n## Egon's footnote \n\nHave you heard about Wikidata already? \"Use Scholia and Wikidata to find scientific literature\" is a new tutorial from my colleague Lauren Dupuis. https://laurendupuis.github.io/Scholia_tutorial/\n\n## Daniels mail\n\nRegarding the use of Scholia for visualizing structure-taxon relationships, I think this is very possible - we already have aspects for chemicals and for taxa, e.g. as per\nhttps://scholia.toolforge.org/taxon/Q157892\nor\nhttps://scholia.toolforge.org/chemical/Q121802 .\n\nWith regards to forks, the most prominent example is probably\nhttps://ordia.toolforge.org/ ,\nwhich visualizes linguistic information based on the lexeme namespace in Wikidata.\n\nAnother thing to think about would be genome browsers like\nhttp://wikigenomes.org/\nor\nhttps://chlambase.org/ .\n\n\nadding additional SPARQL queries to existing Scholia pages is relatively straightforward (the main issue here is performance), so things like adding \"found in taxon\"-based queries to Scholia pages about compounds or taxa and perhaps also pathways could be solved quickly.\n\nWhat might be even more interesting - but would require a bit more work - would be what we call subaspects, i.e. pages that combine two main classes, like https://scholia.toolforge.org/location/Q1748/topic/Q2539 .\n\nWith that in mind, we could think of things like\nhttps://scholia.toolforge.org/compound/QID1/taxon/QID2\nor\nhttps://scholia.toolforge.org/taxon/QID3/compound/QID4 .\n\nThe work on such subaspects has been described in\nhttps://www.wikidata.org/wiki/Q50813856 for the example of geodata,\nwhich would probably be a good starting point when considering the effort involved.\n\n\n\n## Other links\n\nhttps://cthoyt.com/2021/01/23/updating-the-wikidata-integrator.html\n\nA protocol for adding knowledge to Wikidata, a case report.\nhttps://www.biorxiv.org/content/10.1101/2020.04.05.026336v2.full.pdf\n\n","n":0.066}}},{"i":27,"$":{"0":{"v":"Prefixes","n":1},"1":{"v":"# Wikidata prefixes\n\nhttps://www.wikidata.org/wiki/EntitySchema:E49\n\n\n# list of prefixes for import\nPREFIX bd: <http://www.bigdata.com/rdf#>\nPREFIX cc: <http://creativecommons.org/ns#>\nPREFIX dct: <http://purl.org/dc/terms/>\nPREFIX geo: <http://www.opengis.net/ont/geosparql#>\nPREFIX ontolex: <http://www.w3.org/ns/lemon/ontolex#>\nPREFIX owl: <http://www.w3.org/2002/07/owl#>\nPREFIX p: <http://www.wikidata.org/prop/>\nPREFIX pq: <http://www.wikidata.org/prop/qualifier/>\nPREFIX pqn: <http://www.wikidata.org/prop/qualifier/value-normalized/>\nPREFIX pqv: <http://www.wikidata.org/prop/qualifier/value/>\nPREFIX pr: <http://www.wikidata.org/prop/reference/>\nPREFIX prn: <http://www.wikidata.org/prop/reference/value-normalized/>\nPREFIX prov: <http://www.w3.org/ns/prov#>\nPREFIX prv: <http://www.wikidata.org/prop/reference/value/>\nPREFIX ps: <http://www.wikidata.org/prop/statement/>\nPREFIX psn: <http://www.wikidata.org/prop/statement/value-normalized/>\nPREFIX psv: <http://www.wikidata.org/prop/statement/value/>\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\nPREFIX schema: <http://schema.org/>\nPREFIX skos: <http://www.w3.org/2004/02/skos/core#>\nPREFIX wd: <http://www.wikidata.org/entity/>\nPREFIX wdata: <http://www.wikidata.org/wiki/Special:EntityData/>\nPREFIX wdno: <http://www.wikidata.org/prop/novalue/>\nPREFIX wdref: <http://www.wikidata.org/reference/>\nPREFIX wds: <http://www.wikidata.org/entity/statement/>\nPREFIX wdt: <http://www.wikidata.org/prop/direct/>\nPREFIX wdtn: <http://www.wikidata.org/prop/direct-normalized/>\nPREFIX wdv: <http://www.wikidata.org/value/>\nPREFIX wikibase: <http://wikiba.se/ontology#>\nPREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n","n":0.12}}},{"i":28,"$":{"0":{"v":"Create_item","n":1},"1":{"v":"\n\n[TOC]\n# Manual addition of a documented structure-organism pair to Wikidata\n\n## Select a documented structure-organism pair\n\nThroughout this demonstration, we are going to use the following example:\n> [trigocherrin A](https://pubchem.ncbi.nlm.nih.gov/compound/101556657) is found in [_Trigonostemon cherrieri_](http://gni.globalnames.org/name_strings?search_term=trigonostemon+cherrieri&commit=Search), as stated in [Trigocherrin A, the first natural chlorinated daphnane diterpene orthoester from Trigonostemon cherrieri](https://doi.org/10.1021/OL2030907).\n\n## Fetch the information for the documented structure-organism pair\n\n### Structure\n\nSearch PubChem for your compound, here [trigocherrin A](https://pubchem.ncbi.nlm.nih.gov/#query=%22trigocherrin%20A%22). This leads to [https://pubchem.ncbi.nlm.nih.gov/compound/101556657](https://pubchem.ncbi.nlm.nih.gov/compound/101556657).\n\n![](/assets/images/2021-02-25-14-15-54.png)\n\nFrom there, you can fetch the compound's name, InChIKey and InChI as well as its Canonical and Isomeric SMILES.\nHere we keep, respectively:\n\n```\n* trigocherrin A\n* QOVGHDRCAGYGEB-FFZYJECLSA-N\n* InChI=1S/C38H36Cl2O12/c1-18(2)35(44)27-19(3)37-25-16-24(31(39)40)28(48-32(43)22-12-8-6-9-13-22)36(25,45)33(47-21(5)42)34(17-46-20(4)41)29(49-34)26(37)30(35)51-38(50-27,52-37)23-14-10-7-11-15-23/h6-16,19,26-30,33,44-45H,1,17H2,2-5H3/t19-,26+,27?,28+,29+,30-,33-,34+,35+,36-,37+,38?/m1/s1\n* CC1C2C(C3C4C1(C5=CC(=C(Cl)Cl)C(C5(C(C6(C4O6)COC(=O)C)OC(=O)C)O)OC(=O)C7=CC=CC=C7)OC(O2)(O3)C8=CC=CC=C8)(C(=C)C)O\n* C[C@@H]1C2[C@]([C@H]3[C@H]4[C@]1(C5=CC(=C(Cl)Cl)[C@@H]([C@]5([C@@H]([C@@]6([C@H]4O6)COC(=O)C)OC(=O)C)O)OC(=O)C7=CC=CC=C7)OC(O3)(O2)C8=CC=CC=C8)(C(=C)C)O\n```\n\n### Organism\n\nYou can check if your organism name is correctly spelled using the Global Names resolver service: [http://gni.globalnames.org/name_strings?search_term=trigonostemon+cherrieri&commit=Search](http://gni.globalnames.org/name_strings?search_term=trigonostemon+cherrieri&commit=Search).\n\n![](/assets/images/2021-02-27-18-40-20.png)\n\nAlternatively, you can use [gnfinder](https://github.com/gnames/gnfinder) in your command line interface to check for the spelling of your organism string.\n \n```\necho \"Trigonostemion cherrieri\" | gnfinder find -c -l eng\n\n{\n  \"metadata\": {\n    \"date\": \"2021-02-27T18:44:41.640982+01:00\",\n    \"gnfinderVersion\": \"v0.11.1\",\n    \"withBayes\": true,\n    \"tokensAround\": 0,\n    \"language\": \"eng\",\n    \"detectLanguage\": false,\n    \"totalWords\": 2,\n    \"totalCandidates\": 1,\n    \"totalNames\": 1\n  },\n  \"names\": [\n    {\n      \"cardinality\": 2,\n      \"verbatim\": \"Trigonostemion cherrieri\",\n      \"name\": \"Trigonostemion cherrieri\",\n      \"odds\": 77581.46698350731,\n      \"start\": 0,\n      \"end\": 24,\n      \"annotationNomenType\": \"NO_ANNOT\",\n      \"annotation\": \"\",\n      \"verification\": {\n        \"bestResult\": {\n          \"dataSourceId\": 1,\n          \"dataSourceTitle\": \"Catalogue of Life\",\n          \"taxonId\": \"1575885\",\n          \"matchedName\": \"Trigonostemon cherrieri Veillon\",\n          \"matchedCardinality\": 2,\n          \"matchedCanonicalSimple\": \"Trigonostemon cherrieri\",\n          \"matchedCanonicalFull\": \"Trigonostemon cherrieri\",\n          \"classificationPath\": \"Plantae|Tracheophyta|Magnoliopsida|Malpighiales|Euphorbiaceae|Trigonostemon|Trigonostemon cherrieri\",\n          \"classificationRank\": \"kingdom|phylum|class|order|family|genus|species\",\n          \"classificationIds\": \"3939764|3942634|3942724|3942777|3942795|4210752|1575885\",\n          \"editDistance\": 1,\n          \"stemEditDistance\": 1,\n          \"matchType\": \"FuzzyCanonicalMatch\"\n        },\n        \"dataSourcesNum\": 13,\n        \"dataSourceQuality\": \"HasCuratedSources\",\n        \"retries\": 1\n      }\n    }\n  ]\n}\n```\n\nFor misspellings like _Trigonstemion cherrieri_, gnfinder can help resolve them, in this case to _Trigonostemon cherrieri_.\n\n\n### Reference\n\nMake sure that you have the correct [Digital Object Identifier (DOI)](https://www.doi.org/doi_handbook/Glossary.html#doi) for it.\nFor \"[Trigocherrin A, the first natural chlorinated daphnane diterpene orthoester from Trigonostemon cherrieri](https://doi.org/10.1021/OL2030907)\", this is  **10.1021/ol2030907**. Note that DOIs are uppercase-normalized in Wikidata.\n\n## Check for the presence of your compound in Wikidata <a name=\"check_compound\"></a>\n\nUsing the compound's InChIKey (i.e. ```QOVGHDRCAGYGEB-FFZYJECLSA-N``` for trigocherrin A), run a SPARQL query to check if your compound is present in Wikidata or not:\n\n\n```SPARQL\nSELECT ?item ?itemLabel WHERE {\n  VALUES ?classes {\n    wd:Q11173 # chemical compound\n    wd:Q59199015 # group of stereoisomers\n    wd:Q79529 # chemical substance\n    wd:Q17339814 # group of chemical substances\n    wd:Q47154513 # structural class of chemical compounds\n  }\n  ?item wdt:P31 ?classes. # instance of\n  ?item wdt:P235 'QOVGHDRCAGYGEB-FFZYJECLSA-N'\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n}\n```\n[Try this query](https://w.wiki/32zU). You can adapt it by replacing the InChIKey with the one for your compound.\n\nAlternatively you can use the following Scholia link (replace by your compounds InChIKey) [https://scholia.toolforge.org/inchikey/QOVGHDRCAGYGEB-FFZYJECLSA-N](https://scholia.toolforge.org/inchikey/QOVGHDRCAGYGEB-FFZYJECLSA-N) \n\nIf your compound is already present on Wikidata, you can directly skip to the [Add the biological source information](#add_bio) section below.\n\n## Add your data manually to Wikidata <a name=\"add_your_data_manually\"></a>\n\nFirst, if you do not have a Wikidata account already, it is advisable that you create one via [https://www.wikidata.org/wiki/Special:CreateAccount](https://www.wikidata.org/wiki/Special:CreateAccount). While an account is not strictly required for manual edits, having one will be useful if you want to contribute more than once, and it helps in getting your contributions recognized. Note that Wikidata accounts are integrated with accounts across the Wikimedia ecosystem, so if you already have an account on, say, any Wikipedia or on Wikispecies, then you can use the same credentials on Wikidata.\n\nIf you are unfamiliar with how Wikidata works, you can start by reading the Wikidata introduction page [https://www.wikidata.org/wiki/Wikidata:Introduction](https://www.wikidata.org/wiki/Wikidata:Introduction) and have a look at the Wikidata Tours page [https://www.wikidata.org/wiki/Wikidata:Tours](https://www.wikidata.org/wiki/Wikidata:Tours).\n\nNow that you are all set up, you can go to Wikidata's page for creating new items, [https://www.wikidata.org/wiki/Special:NewItem](https://www.wikidata.org/wiki/Special:NewItem):\n\n\n![](/assets/images/2021-02-25-14-18-03.png)\n\nAn empty page with a new Wikidata identifier is created \n\n![](/assets/images/2021-02-25-14-18-50.png)\n\n### Add the chemical compound information <a name=\"add_chemical\"></a>\n\nCreate a new statement for ```is an instance of```\n\n![](/assets/images/2021-02-25-14-20-08.png)\n\nand select chemical compound (i.e. [Q11173](https://www.wikidata.org/wiki/Q11173)):\n\n![](/assets/images/2021-02-25-14-20-58.png)\n\nClick ```publish``` to save your changes and make them public.\n\nSince you created a new item about an instance of a chemical compound, the user interface will automatically propose to you a set of additional statements commonly found on items about chemical compounds.\n\n![](/assets/images/2021-02-25-14-22-44.png)\n\nYou can then go on and fill these in.\n\nHere, we start with the InChIKey. \nNote the little flag which will automatically tell you if you have some problems with the recently created statements.\n\n![](/assets/images/2021-02-25-14-24-34.png)\n\nHere, Wikidata tells us that if we add an InChiKey, we will need to also add an InChI. Logical, but good to have a reminder !\n\nLet's go ahead and add the InChI string.\n\nLikewise, the addition of an isomeric SMILES string will require us to add a Canonical SMILES.\n\nNote that you might have to copy and paste the SMILES string from PubChem to a plain text editor and then back to Wikidata because of some formatting issues when copy pasting directly from PubChem.\n\n```\nC[C@@H]1C2[C@]([C@H]3[C@H]4[C@]1(C5=CC(=C(Cl)Cl)[C@@H]([C@]5([C@@H]([C@@]6([C@H]4O6)COC(=O)C)OC(=O)C)O)OC(=O)C7=CC=CC=C7)OC(O3)(O2)C8=CC=CC=C8)(C(=C)C)O\n\nCC1C2C(C3C4C1(C5=CC(=C(Cl)Cl)C(C5(C(C6(C4O6)COC(=O)C)OC(=O)C)O)OC(=O)C7=CC=CC=C7)OC(O2)(O3)C8=CC=CC=C8)(C(=C)C)O\n```\n\n### Add the biological source information <a name=\"add_bio\"></a>\n\nNow let's add the ```found in taxon``` property ([P703](https://www.wikidata.org/wiki/Property:P703)).\n\nJust click on ```Add a new statement``` and type in the first letters of the property you want to add:\n\n![](/assets/images/2021-02-25-14-31-56.png)\n\nAgain, type in the first letters of the taxon, and if the organism is present, it will autocomplete. Here is how this looks like for _Trigonostemon cherrieri_:\n\n![](/assets/images/2021-02-25-14-33-14.png)\n\nClick ```publish``` to save your changes and make them public.\n\n\nIf your target taxon is not yet present on Wikidata and you are sure you have a valid taxon name that is spelled correctly, then you can go to [https://www.wikidata.org/wiki/Special:NewItem](https://www.wikidata.org/wiki/Special:NewItem), as described in the [Add your data manually to Wikidata](#add_your_data_manually) section. For items about taxa, the ```instance of``` statement should have a value ```taxon``` (i.e. [Q16521](https://www.wikidata.org/wiki/Q16521)). As for chemical compounds, the user interface will then suggest to you further statements to add. For taxa, these include taxon name, parent taxon and taxon rank.\n\n\n### Add the reference documenting the structure-organism pair <a name=\"add_ref\"></a>\n\nFinally, since we report documented structure-organisms pairs, we need to add the reference for this newly created ```compound found in taxon``` relationship.\nThis happens on the item about the compound, just below the ```found in taxon``` statement. Click on the ```0 references``` link and then on ```add reference```:\n\n![](/assets/images/2021-02-25-14-35-33.png)\n\nHere, we use the ```stated in``` property ([P248](https://www.wikidata.org/wiki/Property:P248)):\n\n![](/assets/images/2021-02-25-14-36-33.png)\n\nNow, type in the first letters or word of the scientific publication documenting the natural product occurence, autocompletion happens again. Note that multiple publications might have the same title, and that there could be minor differences in punctuation or special characters between the information you and Wikidata have about the same reference. If you are not sure whether your target reference is already in Wikidata, you can use its DOI to check, as outlined in the [Check whether your target reference is already on Wikidata](#check_ref) section.\n\n![](/assets/images/2021-02-25-14-38-54.png)\n\nClick ```publish``` to save your changes and make them public.\n\n![](/assets/images/2021-02-25-14-39-48.png)\n\n### Check whether your target reference is already on Wikidata <a name=\"check_ref\"></a>\n\nIf you are not sure whether your target reference is already in Wikidata, you can use its DOI to check. For our DOI ```10.1021/ol2030907```, the URL [https://scholia.toolforge.org/doi/___10.1021/ol2030907___](https://scholia.toolforge.org/doi/10.1021/ol2030907) will lead you to a [Scholia](https://www.wikidata.org/wiki/Wikidata:Scholia) page about this publication: [https://scholia.toolforge.org/work/Q83059010](https://scholia.toolforge.org/work/Q83059010). Scholia visualizes information from Wikidata, so if it has an entry for your target reference, then so does Wikidata, and both of them will use the same identifier (in this case [Q83059010](https://www.wikidata.org/wiki/Q83059010)). If you prefer to resolve your DOI to Wikidata directly, you can do so by using the uppercase-normalized DOI in the following URL pattern: [https://hub.toolforge.org/P356:**10.1021/OL2030907**](https://hub.toolforge.org/P356:10.1021/OL2030907), which will lead you to the respective Wikidata page, in this case [Q83059010](https://www.wikidata.org/wiki/Q83059010).\n\nIf you think that no Wikidata entry exists for your target reference, you can use the DOI in the URL pattern [https://sourcemd.toolforge.org/index_old.php?id=**10.1021/ol2030907**&doit=Check+source](https://sourcemd.toolforge.org/index_old.php?id=10.1021/ol2030907&doit=Check+source), which will trigger a check with both Crossref and Wikidata, and if no Wikidata entry can be found, the metadata from Crossref will be fetched and presented to you for creating the respective Wikidata item semi-automatically. Using such semi-automated workflows does require and account that is a minimum number of days old and has made a minimum number of edits on Wikidata.\n\nIf you are interested the annotation of article with topics in Scholia here is a tutorial [https://laurendupuis.github.io/Scholia_tutorial/](https://laurendupuis.github.io/Scholia_tutorial/)\n\n\n## Voila !\n\nYou have added your first documented structure-organism relationship to Wikidata and made a valuable contribution to the community.\nYou can add further statements, e.g. ```molecular formula```, or ```SPLASH code``` for linking to spectral data.\n\nThe Wikidata entry [https://www.wikidata.org/wiki/Q105674316](https://www.wikidata.org/wiki/Q105674316) has been started using these instructions.\n\nYou can run a SPARQL query and check that everything went smoothly by modifying the InChiKey line in the following [SPARQL query](https://w.wiki/32zb):\n\n```SPARQL\nSELECT ?item ?itemLabel ?taxonLabel ?artLabel WHERE {\n  VALUES ?classes {\n    wd:Q11173 # chemical compound\n    wd:Q59199015 # group of stereoisomers\n    wd:Q79529 # chemical substance\n    wd:Q17339814 # group of chemical substances\n    wd:Q47154513 # structural class of chemical compounds\n  }\n  ?item wdt:P31 ?classes. # instance of\n  ?item wdt:P235 'QOVGHDRCAGYGEB-FFZYJECLSA-N' # InChiKey\n  {\n    ?item p:P1582 ?stmt. # natural product of taxon\n    ?stmt ps:P1582 ?taxon. # natural product of taxon\n    OPTIONAL {\n      ?stmt prov:wasDerivedFrom ?ref. \n      ?ref pr:P248 ?art. # stated in\n    }\n  }\n  UNION\n  {\n    ?item p:P703 ?stmt. # found in taxon\n    ?stmt ps:P703 ?taxon. # found in taxon\n    OPTIONAL {\n      ?stmt prov:wasDerivedFrom ?ref.\n      ?ref pr:P248 ?art. # stated in\n    }\n  }\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n}\n```\n","n":0.026}}},{"i":29,"$":{"0":{"v":"Apps","n":1},"1":{"v":"# Topic tagger\n\nhttps://lubianat.shinyapps.io/topictagger/\n\n# bot tutorial\n\nhttps://heardlibrary.github.io/digital-scholarship/host/wikidata/bot/\n\n","n":0.447}}},{"i":30,"$":{"0":{"v":"Welcome","n":1},"1":{"v":"\n👆 Type a keyword or a section you are looking for up there 👆\n## What's after wilderness  🏔️ 🦖\n\nThis note initially came after the dendron introduction [[dendron]] ... but let's put it as a welcome word !\n\n### What is this ?\n\nYou might find  a lot of stuff on this personal dendron website. It has for objective to be used as a dump for ideas, todo lists, read lists, ... [fill the dots] or an electronic lab notebook. You can see it as a digital experiment aiming to gather :\n\n- [ ] academic research material of exploratory projects around natural products, biodiversity & ecology - instead of presenting final object we will rather follow an [anti-marketing approach](https://notes.andymatuschak.org/z4bK6LaSBRetDzuYkeCs3A8mJ8DufTbK4o6FS)\n\nYou can see it as: \n\n- [ ] a garage, lab and a workshop with [open doors](https://notes.andymatuschak.org/z21cgR9K3UcQ5a7yPsj2RUim3oM2TzdBByZu). See related notes here [[garage]]\n\n### Why ?\n\nIt is a first attempt to commit to :\n\n- [ ] a public [[pledge]] (inspired by Daniel Mietchen).\n\n### And then what ?\n\nPass at the workshop and grab a coffee ☕ or whatever you like. Let's chat ! Help me grow this dendron, let's add leaves 🍃 or prune ✂️ branches together 🤝 ! \nTo add comments and suggestions two possibilities :\n\n  - raise an issue here : https://github.com/oolonek/dendron/issues\n  - 👇 Directly edit this file on github using the link below 👇\n\n","n":0.068}}},{"i":31,"$":{"0":{"v":"Viewlist","n":1},"1":{"v":"\n\nFriday 24 September 2021\n\nhttps://www.youtube.com/watch?v=3wMKoSRbGVs\n\n\nLex Fridman\n1,28 M d’abonnés\nDouglas Lenat is the founder of Cyc, a 37 year project aiming to solve common-sense knowledge and reasoning in AI. Please support this podcast by checking out our sponsors:\n- Squarespace: https://lexfridman.com/squarespace and use code LEX to get 10% off\n- BiOptimizers: http://www.magbreakthrough.com/lex to get 10% off\n- Stamps.com: https://stamps.com and use code LEX to get free postage & scale\n- LMNT: https://drinkLMNT.com/lex to get free sample pack\n- ExpressVPN: https://expressvpn.com/lexpod and use code LexPod to get 3 months free\n\nEPISODE LINKS:\nDouglas's Twitter: https://twitter.com/cycorpai\nCyc's Website: https://cyc.com\n\nPODCAST INFO:\nPodcast website: https://lexfridman.com/podcast\nApple Podcasts: https://apple.co/2lwqZIr\nSpotify: https://spoti.fi/2nEwCF8\nRSS: https://lexfridman.com/feed/podcast/\nFull episodes playlist: https://www.youtube.com/playlist?list...\nClips playlist: https://www.youtube.com/playlist?list...\n\nOUTLINE:\n0:00 - Introduction\n1:11 - What is Cyc?\n9:17 - How to form a knowledge base of the universe\n19:43 - How to train an AI knowledge base\n24:04 - Global consistency versus local consistency\n48:25 - Automated reasoning\n54:05 - Direct uses of AI and machine learning\n1:06:43 - The semantic web\n1:17:16 - Tools to help Cyc interpret data \n1:26:26 - The most beautiful idea about Cyc\n1:32:25 - Love and consciousness in AI\n1:39:24 - The greatness of Marvin Minsky \n1:44:18 - Is Cyc just a beautiful dream?\n1:49:03 - What is OpenCyc and how was it born?\n1:54:53 - The open source community and OpenCyc\n2:05:20 - The inference problem\n2:07:03 - Cyc's programming language\n2:14:37 - Ontological engineering\n2:22:02 - Do machines think?\n2:30:47 - Death and consciousness\n2:40:48 - What would you say to AI?\n2:45:24 - Advice to young people \n2:47:20 - Mortality\n\nSOCIAL:\n- Twitter: https://twitter.com/lexfridman\n- LinkedIn: https://www.linkedin.com/in/lexfridman\n- Facebook: https://www.facebook.com/lexfridman\n- Instagram: https://www.instagram.com/lexfridman\n- Medium: https://medium.com/@lexfridman\n- Reddit: https://reddit.com/r/lexfridman\n- Support on Patreon\n\n\n\nJeudi 19 Août 2021\n\nOn the EarthBioGenome initiative https://www.youtube.com/watch?v=gptP4FZHZrE&list=PLpCH1XIO3lYtRELTupGHOfrbylNlPhPKR\n\n\nhttps://www.earthbiogenome.org/\n\n\n2021-02-08 08:29\nhttps://www.youtube.com/watch?v=kqSzLo9fenk\n\nA friendly introduction to Bayes Theorem and Hidden Markov Models\nhttps://github.com/luisguiserrano/hmm\n\nSuch approaches seem perfectly adapted to noisy datasets such as mass spec data from which we would like to fish signal related to bioactive analytes.\nWe have some priors bioactivity of the extracts, previously reported scaffolds on the target\nWe could propagate information about seed compounds trough spectral similarity, seeing cos score aa a coarse probability of the molecule showing the same properties then the seed.\nCheck for existing implementations of Bayesian approach in drug discovery or in the exploration of mass spectral data set.\n\nOther stuff there https://serrano.academy\n\n\n\n2021-01-20 13:31\n\nhttps://www.buzzsprout.com/1244474/7197082\n\n- A quick thought experiment : \"Imagine yourself and your banc account in 20 years ... What if it didn't change ? Would you see this as a failure ?\" \n\n- investigate \"commodities\" ... could well be the root of the problem. We want to be confortable. We are dissatisfied. If you work on contentment and help people to encounter contentment and satisfaction in any situation you abolish the whole problem. See Ushiyama and Sawaki\n- manufacture of dissapointment\n- check what is \"feminist economists\" not clear\n- 2nd taught experiment \"the speed of a car\" by Ivan Illitch >> 16 km/h\n\n[[#idea|tag.idea]] should we advocate and work toward a degrowth approach in academics. publish less.\n\n\n2021-01-18 22:43\n# Dr Louis Fouché : Pourquoi le monde s'effondre-t-il ? (Conférence) \n\n- [x] ~~to listen~~ 2021-01-20 13:01\n\nhttps://www.invidiou.site/watch?v=5D3kypgbFKs \n\n- notion d'ubris (la démesure) <<< tjs puni par la nemesis>>>\n- notion de panmetron (la mesure en tout)\n- lowtech in health\n- health is behind enterprise lagging 20 years (nvc implementation etc.)\n- checker la \"perte des savoirs\" de B. Stiegler\n- lowtech lab\n\n\n\n# Juho Rousu: \"Predicting structured data\"\n\n- [ ] to listen\n\n2021-01-12 17:45\n\n25 min\n\nhttps://www.youtube.com/watch?v=ORI5KStKaWk\n","n":0.044}}},{"i":32,"$":{"0":{"v":"Tools","n":1}}},{"i":33,"$":{"0":{"v":"Web","n":1},"1":{"v":"\n[TOC]\n\n\n# Web hosting of a single page \n2021-01-28 10:29\n## Context\nI need to share html rendered md notes coming from dendrons private daily journal notes. I use these as an electronic lab notebook and sometime want to share them to collaborators instead of preparing a ppt or keynote slide presentation.\n## Need\nWhat I currently have is the daily journal notes as .md files. I can render them as .html using MPE. Make a TOC as a sidebar (just add [TOC] at the head of the file), display images, mermaid diagrams etc. They can be automatically published in the github pages. This is OK for dendron notes that I want to publish. However I need to find a solution to efficiently share private notes as html files.\n\nThe remote notes :\n\n- [ ] should be accessible by a simple link, no download required\n- [ ] should rendered the exact same way as the dendrons published notes\n- [ ] should be versionable by git or similar\n- [ ] should be automatically updated upon local changes\n- [ ] should be self encapsulated (if i have them hosted on a git the user whith the link to note C should not be able to jump to upper levels or see note A)\n\n\n## Task (of the note/paragraph/text/paper/project)\n\nThis is what I did up to now and what I plan to do to tackle this\n\n- [x] ~~recreated this ctno snippet~~\n\n- [x] ~~created this note~~\n\n- [ ] check for hosting solutions\n\n    - [x] ~~dropbox~~\n\n    Not good anymore as the discontinued the direct disply of html files. Would have been a perfect solution.\n    https://superuser.com/questions/764641/how-to-serve-html-off-my-dropbox\n\n    - [x] ~~https://www.fast.io/~~ (appears to be discontinued as of 2021-01-16)\n    - [ ] http://pomf.se/\n    - [ ] https://www.netlify.com/\n    - [ ] https://wowchemy.com/\n        - [ ] https://www.jameswright.xyz/post/deploy-hugo-academic-using-githubio/\n\n## Object (of the note/paragraph/text/paper/project)\nThis is a self contained ctno snippet. It does not aim to introduce anything other than itself.\nThat was the object. //TODO Snippets. Work on different and more adapted snippets (self sufficient, introductory etc ...)\n\n\n## Hugo\n\n\nhttps://www.ctomlinson.net/post/building-a-website-with-hugo-academic/\n\n","n":0.055}}},{"i":34,"$":{"0":{"v":"Visualization","n":1},"1":{"v":"\n# Links\n\nA set of links and ressources on data viz found when researching Vega engines\n\nhttps://observablehq.com/\n\nhttps://vega.github.io/voyager/\n\nhttps://octo.github.com/projects/flat-data\n\n\nhttps://streamlit.io/\n\n\n","n":0.258}}},{"i":35,"$":{"0":{"v":"Plotly","n":1},"1":{"v":"\n# plotly html integration\n\nhttps://ig248.gitlab.io/post/2018-11-05-plotly-sample/  (merci Jo)\n\nafter a bunch of slightly outdate tutorial I found this one wich worked in my case\n\nhttps://medium.com/analytics-vidhya/how-to-export-a-plotly-chart-as-html-3b5df568df4a\n\n \n just embbed like this\n\n```html\n<div class=\"container-fluid\" style=\"margin-top:40px\">\n  <iframe src=\"sariette_pos_pos_organisms_sunburst.html\" width=\"100%\" height=\"600\" style=\"border:none;\"></iframe>\n</div>\n```\n\n\n\n# customization of fig (margin/titles and other nasty stuff)\n\n\n\n```python\n# %%\n# using px express to plot some quick and dirty sunbursts (https://plotly.com/python/sunburst-charts/)\n# customize fonts in titles following https://stackoverflow.com/a/57926862\n# customize margins following https://stackoverflow.com/a/63162535\n\nimport plotly.express as px\n\n\nfig = px.sunburst(df4cyto_flat, path=['Superclass_cf_DNP_consensus', 'Class_cf_DNP_consensus', 'Subclass_cf_DNP_consensus', 'Parent_Level_1_cf_DNP_consensus'],\n                  )\nfig.update_layout(\n    #font_family=\"Courier New\",\n    title_font_family=\"Courier New\",\n    title_font_color=\"black\",\n    title_font_size=14,\n    legend_title_font_color=\"black\",\n    title_text=\"<b> Overview of the consensus chemical annotions <br> as the superclass, class, subclass and parent_1 level for <br>\" + project_name + \"</b>\",\n    title_x=0.5\n)\n\nfig.update_layout(\n    title={\n        'text': \"<b> Overview of the consensus chemical annotions <br> as the superclass, class, subclass and parent_1 level for <br>\" + '<span style=\"font-size: 20px;\">' + project_name + '</span>' + \"</b>\",\n        'y':0.96,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\n\nfig.update_layout(margin=dict(l=50, r=50, t=100, b=50)\n#,paper_bgcolor=\"Black\"\n)\n\nfig.show()\nfig.write_html(sunburst_chem_results_path)\n```\n\n## On the display via github\n\nhttps://community.plotly.com/t/how-to-display-plotly-graph-on-github-pages/44398/2\n\n\nhttps://automating-gis-processes.github.io/2016/Lesson5-share-on-github.html\n\nhttps://mertbakir.gitlab.io/hugo/plotly-with-hugo/\n\nWhen displaying iframe in hugo pages be sure to have \n\nhttps://stackoverflow.com/a/66741389\n\n\n\n\n# Monday 06 December 2021\n\nGetting plotly to work within a jupoyter nb file on github https://binnisb.github.io/blog/datascience/2020/04/02/Plotly-in-lab.html\n\n","n":0.076}}},{"i":36,"$":{"0":{"v":"Geodata","n":1},"1":{"v":"\n# Geo Data visu\n\nLooking to display and share .gpx data \n\nhttps://marketplace.visualstudio.com/items?itemName=RandomFractalsInc.geo-data-viewer\n\nIt is apparently possible to add .csv data to an existing .gpx map\nhttps://docs.kepler.gl/docs/user-guides/b-kepler-gl-workflow/a-add-data-to-the-map#csv\n\nI used https://geogeek.xyz/wp-content/uploads/2017/08/coordinate_converter.xlsx to convert UTM coord to decimal lon lat. Not ideal but did the job.\n\nYou can then add and combine .gpx or csv of lat long in the geo-data-viewer and export the .html.\nWhen you open this one it will be opened in the kepler website. There you can export as shareable html (dont forget to add your personal token)\nHere is an example [finca](../../../../../Users/pma/Dropbox/dendron/vault/assets/private.assets/terreno_pma_kepler.gl.html)\n","n":0.107}}},{"i":37,"$":{"0":{"v":"Sql","n":1},"1":{"v":"\n# MySQL\n\ncreating a mysql instance for MyLabBook test\n\nhttps://medium.com/macoclock/mysql-on-mac-getting-started-cecb65b78e\n\nfrom cli\n\nhttps://www.a2hosting.com/kb/developer-corner/mysql/managing-mysql-databases-and-users-from-the-command-line\n\nif you have issue to log https://stackoverflow.com/questions/4359131/brew-install-mysql-on-macos\n\n\nGRANT ALL PRIVILEGES ON *.* TO 'pma'@'localhost' IDENTIFIED BY 'password';\n","n":0.204}}},{"i":38,"$":{"0":{"v":"Pg","n":1},"1":{"v":"# Installing PG on Ubuntu \n\n\nFollowing https://computingforgeeks.com/install-postgresql-12-on-ubuntu/\n\n","n":0.378}}},{"i":39,"$":{"0":{"v":"Organization","n":1},"1":{"v":"\n### Some thoughts or notes organization approaches\n\nhttps://fortelabs.co/blog/para/\n\n## The 2 minutes rule \n\nhttps://jamesclear.com/how-to-stop-procrastinating\n\n\n# Task management\n\n[[Taskwarrior|tools.organization.taskwarrior]]\n\n\n# Nomadic Research Lab\n\nhttps://microship.com/\n","n":0.243}}},{"i":40,"$":{"0":{"v":"Time","n":1},"1":{"v":"\nTuesday 03 August 2021\n\n> Most of us use our calendars all wrong: we don't schedule work; we schedule interruptions. Meetings get scheduled. Phone calls get scheduled. Doctor appointments get scheduled. You know what often doesn't get scheduled? Real work. All those other things are distractions. Often, they're other people's work. But they get dedicated blocks of time, and your real work becomes an orphan.\n\nPeek into time blocking.\n\nAs Roman Stoic philosopher Seneca once wrote:\n\n> “People are frugal in guarding their personal property; but as soon as it comes to squandering time, they are most wasteful of the one thing in which it is right to be stingy.”\n\n----\n\n\nHaving a look at the MyTime plugin (https://github.com/codicelq/mytime) because I wanted a time tracking solution and that this is currectly lacking from the excellent Todo+ plugin.\n\nCreated a snippet to directyl add current time \n\n```bash\n    \"now\": {\n        \"prefix\": \"now\",\n        \"scope\": \"markdown,yaml\",\n        \"body\": \"- `$CURRENT_HOUR:$CURRENT_MINUTE` \",\n        \"description\": \"now in hour:min\"\n    }\n```\n\n\n- `20:00` Started work on machine A\n- `20:29` // Went to have a piss\n- `21:26` Started work on machine A\n- `23:26` // Went to have a piss\n- `23:45` Started work on machine B\n\n\n\n| Time span          | Task                      |\n| -----------------: | ------------------------- |\n|          `01:00`   | Started work on machine A |\n|          `00:15`   | Started work on machine B |\n|        **`01:15`** | **Total**                 |\n\n> _Last update 20:29_ / Lines [valid:3, comments:2, invalid:0]\n\n\n| Time span          | Task                      |\n| -----------------: | ------------------------- |\n|          `01:00`   | Started work on machine A |\n|          `00:15`   | Started work on machine B |\n|          `02:30`   | Went to have a piss       |\n|        **`03:45`** | **Total**                 |\n\n> _Last update 20:28_ / Lines [valid:5, comments:0, invalid:0]\n\n---\n\nLet's see if this work with intricated sentences or objects \n\n\n\n- `20:00` Started work on machine A\n\nAnd this is the code I used for this time machine \n\n```bash\n    \"now\": {\n        \"prefix\": \"now\",\n        \"scope\": \"markdown,yaml\",\n        \"body\": \"- `$CURRENT_HOUR:$CURRENT_MINUTE` \",\n        \"description\": \"now in hour:min\"\n    }\n```\n- `20:29` // Went to have a piss\n\nIn my amazing bathroom\n\n- `21:26` Started work on machine A\n\nBlah\n\n- `23:26` // Went to have a piss\n\nOutside \n\n- `23:45` Started work on machine B\n\n\n\n| Time span          | Task                      |\n| -----------------: | ------------------------- |\n|          `01:00`   | Started work on machine A |\n|          `00:15`   | Started work on machine B |\n|        **`01:15`** | **Total**                 |\n\n> _Last update 20:34_ / Lines [valid:3, comments:2, invalid:12]\n\n\nWorking !!! That looks like a very nice option \nIts not working in the todo+ files\n\n  Luis_Molina seeds metabo:\n    ✔ grab back latest Mzmine project @started(21-01-03 13:40) @done(21-01-03 13:42) @lasted(2m26s)\n    - make MN:\n      ✔ make MN metadata file @started(21-01-03 13:42) @done(21-01-03 13:47) @lasted(5m16s)\n      ✔ upload stuff to GNPS @started(21-01-03 13:47) @done(21-01-03 15:06) @lasted(1h19m56s)\n      ✔ briefly check MN in cytoscape @15m @started(21-01-03 15:56) @done(21-01-03 16:06) @lasted(10m11s)\n      ✔ Run ISDB @1h @done(21-01-03 18:05)\n        ✔ upload mgf and attributes to x2go @15m @started(21-01-03 16:06) @done(21-01-03 16:37) @lasted(31m29s)\n        ssh allardp@x2go.epgl-geneve.org\n        cd Desktop/FARMAnetwork/RECHERCHE/COMMON\\ FASIE-FATHO/PMA/Ubuntu_VM_img/ISDB_DNP/results/\n        ✔ run isdb via command line (x2go not working)  @30m @started(21-01-03 16:37) @done(21-01-03 16:42) @lasted(5m50s)\n        ✔ get back top 50 locally @10m @started(21-01-03 16:42) @done(21-01-03 16:46) @lasted(4m31s)\n    ✔ run taxo reponderation using Arabidopsis @1h @1h @started(21-01-03 17:47) @done(21-01-03 18:05) @lasted(18m24s)\n        ✔ download latest version @started(21-01-03 14:30) @done(21-01-03 15:06) @lasted(36m54s)\n      ☐ script a metadata formatter that take a sample metadata and feature table and generates a sample metadat grouped feature table (for cytoscape display) @4h\n      stope here  /Users/pma/Dropbox/Research_UNIGE/git_repos/pf_project/src/peaklist_formatter.py\n    ☐ make report @1h\n    ☐ send it @10m\n\n----\n\nWhat if it runned over various days ?? \nDoesn't seem to take days shifts into account.\n\n\n## Sunday 03 January\n\n- `20:38` //_Good morning_\n- `20:39` Bricole_2\n- `22:00` Bricole_1\n## Monday 04 January\n\n- `07:45` //_Let's start_\n- `08:39` Bricole_2\n- `09:43` Bricole_3\n- `21:39` Bricole_1\n\n\n- `21:03` Mail\n\n## Timeis\n\nhttps://time.is/fr/\n\ns\n","n":0.041}}},{"i":41,"$":{"0":{"v":"Taskwarrior","n":1},"1":{"v":"\n# Taskwarrior \n\nhttps://taskwarrior.org/docs/start.html\nhttps://randomgeekery.org/tags/taskwarrior/\n\nRestore a recently deleted task in twarrior\nhttps://taskwarrior.org/support/faq.html#q7\n\n## Taskwarrior-tui \n\nTaskwarrior-tui keybinding\n\nhttps://kdheepak.com/taskwarrior-tui/keybindings/\n\n\n\n\n\n# Timewarrior\n\nhttps://timewarrior.net/docs/tutorial/\n\nintegrated with timewarrior https://jrisch.medium.com/tracking-time-with-taskwarrior-and-timewarrior-6759f3542276\n\nhttps://iturbe.info/2017/10/the-command-line-productivity-triad-vimwiki-taskwarrior-timewarrior/\n\nTo shorten a task\n\ntimew summary :id\ntimew modify end @4 \"2021-04-09\"T14:30:00\n\n\n## alternatives\n\nhttps://traggo.net/\n\n\n\n\n# Calendars\n\nPeak into https://khal.readthedocs.io/en/latest/usage.html\n\nhttps://gitlab.com/BlackEdder/caldavwarrior\n\nLife Calendar Swift coded dont lnow how to install https://github.com/wvdk/Life-Calendar\n\nhttps://github.com/serhii-londar/open-source-mac-os-apps\n\n\nMonday 19 April 2021\n\nTrying to sync calendar app to khal\n\nhttps://forum.magicmirror.builders/topic/1980/synchronizing-private-icloud-calendar-with-magicmirror-a-workaround\n\nhttps://dianne.skoll.ca/projects/remind/\n\nhttps://inthe.am/\n\n\nhttps://useplaintext.email/#why-plaintext\n\n(fell in a rabithole)\n\nTuesday 03 August 2021\n\n🖐️ Fell in another rabithole while trying to set up the calcurse-caldav and vsyncserver apps \nFinally plain iCal app might still me the most convenient solution \n\n\n# Taskserver \n\n\nThe steup guidelines \n\nhttps://gothenburgbitfactory.github.io/taskserver-setup/\n\n\n","n":0.109}}},{"i":42,"$":{"0":{"v":"Pkm","n":1},"1":{"v":"\n# Personal Knowledge Management\n\nhttps://pkm.dendron.so/\n\n\n# Link paper and digital\n\n(ZK imported)\n\nAnd also a first attempt to link paper and digital ZK #6_93_V (or dendron or whatever digital pkm system). So here in dendron tag would be [[6_93_V]]\n\nThe first digit correspond to the notebook number. The second one to the page number. Here Notebook 6 page 93. The letter corresponds to : \n- Live List (L)\n- The Vault (V)\n- Notes (N)\n\nNotebooks are following the strikethru system https://www.kickstarter.com/projects/chriskyle/strikethru-the-to-do-list-notebook-0\nI am on my 8th notebook using the stikethru system so I guess it's a match for me (lets see how it goes with dendron, the time you stick to a tool seems to be a good measure of it's usefulness. Sometimes you get pretty excited about flashy tools with all the bells and whistle be if you drop them after a week, you know they might not worth investing much more time)\n\n- [ ] investigate more on digital / analogue links in various domains (note taking, pkm). Maybe more widely also, explore links between these two whole \"worlds\". Thinking about it it is actually the very core definition of bioinformatics. A discipline which is by essence at the interface of analogue and digital worlds ... \n\n# Obsidian thread\n\nhttps://forum.obsidian.md/t/cataloging-classification-information-science-pkms-and-you/10071\n","n":0.071}}},{"i":43,"$":{"0":{"v":"Focus","n":1},"1":{"v":"\n(ZK imported)\n\nWhen reading an article on the internet it could be useful to have a plugin able to completely remove active links (so they dont atract the attention anymore.)\nThis should greatly enhance the readers attention by giving a \"book like\" feeling.\n\n2021-01-17\n\nAdded since some month the \"Decreased Productivity\" plugin on chromium browser https://chrome.google.com/webstore/detail/decreased-productivity/nlbpiflhmdcklcbihngeffpmoklbiooj\nProduced by https://www.andryou.com/\nIt has a bunch of options, however I found that at the end of the day I am not using it that often. There is still work to do on such plugins to have a better reading experience. \nVery interested in quick and convenient ways to pass from retro-lightened screen > e-ink/paper like reading exp. (apart from printing the pages)\n\nA plugin that I installed more recently but which I use more (because its automatically acting also ) is a tab limitator Nuff Tabs\nhttps://chrome.google.com/webstore/detail/nuff-tabs/kemeihccgedidlokcbfhdekcfojpjjmp\n","n":0.086}}},{"i":44,"$":{"0":{"v":"Eln","n":1},"1":{"v":"\n# https://www.mylabbook.org/index.php\n\nCheck in to drupal\n# Digital Lab Notebook\n \nhttp://culturalheritageimaging.org/Technologies/Digital_Lab_Notebook/index.html\n\n\n\n# Electronic Lab Notebooks Ressources\n\nLooking for strategies to uniquely identify and track samples in the lab.\n\n\nhttps://www.limswiki.org/index.php/Main_Page\n\n\nhttps://leaflims.github.io/docs/index.html\n\nhttp://www.sesame.wisc.edu/sesame_home.html\n\nhttps://muccg.github.io/mastr-ms/\n\n\nhttps://chemotion.net/\n(down to recheck later)\nInstall over here https://github.com/ComPlat/chemotion_ELN\n\n\n## Recipe SENAITE install\n\nhttps://www.senaite.com/docs/installation.html\n\n2021-01-21 18:58\nOn  X2GO server\n\nsudo adduser --home /home/farma.unige.ch/senaite --shell /bin/bash senaite\n\npwd : d-gvapltivsv-BD place entity characteristic \n\n$ wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh\n$ bash /home/senaite/Miniconda2-latest-Linux-x86_64.sh\n$ source /home/senaite/.bashrc\n\nmess \n\nMiniconda2 will now be installed into this location:\n/home/farma.unige.ch/senaite/miniconda2\n\n  - Press ENTER to confirm the location\n  - Press CTRL-C to abort the installation\n  - Or specify a different location below\n\n[/home/farma.unige.ch/senaite/miniconda2] >>> \nPREFIX=/home/farma.unige.ch/senaite/miniconda2\n\n\n(senaite) senaite@FARMA-NONMEM:~/Plone-4.3.19-UnifiedInstaller$ ./install.sh standalone --target=/home/farma.unige.ch/senaite --instance=senaitelims --password=admin\n\n\n\nSENAITE is a beautiful trigonal, oil-green to greenish black crystal, with almost the hardness of a diamond. Although the crystal is described with a complex formula, it still has clear and straight shapes. Therefore, it reflects nicely the complexity of the LIMS, while providing a modern, intuitive and friendly UI/ UX.\n\n\n\n","n":0.084}}},{"i":45,"$":{"0":{"v":"Elabftw","n":1},"1":{"v":"\nTuesday 01 June 2021\n\ninstalling elabftw on metabomaps server\n\nhttps://doc.elabftw.net/install.html\n\n\n","n":0.354}}},{"i":46,"$":{"0":{"v":"Digitalgardens","n":1},"1":{"v":"\n# Digital gardens, forest and more ...\n\nhttps://maggieappleton.com/garden-history\n\nThis image perfectly resumes the idea I have of a public dendron. \n\n![](assets/images/2021-01-04-21-52-56.png)\n","n":0.229}}},{"i":47,"$":{"0":{"v":"Communication","n":1},"1":{"v":"\n# If it will matter after today, stop talking about it in a chat room\n\n[sent by Jonathan Bisson]\n\nOn the pros and cons of chats (slack and other im chatrooms), on one key message : \"If it will matter after today, stop talking about it in a chat room\" \n\nSome alternatives : \n\nDiscourse, Twist, Carrot, Threads, Basecamp, Flarum, or heck even GitHub issues.\n\n\nhttps://critter.blog/2021/01/12/if-it-matters-after-today-stop-talking-about-it-in-a-chat-room/\n\n","n":0.127}}},{"i":48,"$":{"0":{"v":"Gitpages","n":1},"1":{"v":"Sharing a plot from github pages\nhttps://automating-gis-processes.github.io/2016/Lesson5-share-on-github.html\n\n\n","n":0.408}}},{"i":49,"$":{"0":{"v":"Email","n":1},"1":{"v":"\nFun stuff there https://theoatmeal.com/comics/email_monster\n\nIf you are interested in the matter, read the Email Tyranny by John Freeman\n\n\n## Protonmail\n\nOn having a full protonmail enhanced setup https://www.reddit.com/r/ProtonMail/comments/ly8254/sample_strategy_to_make_pm_your_main_email/\n(for now just used via the web app)\n","n":0.177}}},{"i":50,"$":{"0":{"v":"Mongo","n":1},"1":{"v":"\n# Mongo DB related infos\n\nA pres by Matt Swain\nhttps://speakerdeck.com/mcs07/chemical-structure-handling-in-mongodb\n\nhttps://matt-swain.com/blog/2014-06-03-chemical-similarity-search-in-mongodb\n\nAssociated repo https://github.com/mcs07/mongodb-chemistry\nAnd a derived notebook https://mnowotka.github.io/notebooks/mongo.html\n\nhttps://mnowotka.github.io/notebooks/\n\nBunch of chembl related info here also\nhttp://chembl.blogspot.com/ n\n","n":0.213}}},{"i":51,"$":{"0":{"v":"Mnemonics","n":1},"1":{"v":"\n\nA list of Mnemonics related tools \n\nhttps://numinous.productions/ttft/#top\n\n[[mnemonics related side note | scratch.2020-09-24-000451]] \n\n\nA new mnemonic medium \nhttps://quantum.country/qcvc\n\n\n\n## Prompts \n\nHow to write good prompts: using spaced repetition to create understanding\n\nhttps://andymatuschak.org/prompts/ \nLinked to ![[tools.mnemonics.anki]]\n\nOrbit's inspirational description \n\n> _When you read a text that’s written with Orbit, you don’t just read it once and then set it aside, perhaps forever. The review sessions keep you in contact with the ideas, returning you to the material again and again over weeks and months. The ongoing practice changes your relationship to what you read. It gives you a way to bring ideas into your orbit. … When something seems interesting, you can tie a string to it and throw it up in a lazy arc. It’ll swing back around at some point, but you’re not terribly concerned with when. You’ll give its string more or less slack over time. Floating above your head, then, is an ever-shifting constellation of inklings, facts, questions, prompts, obsessions. Every day you stare up at the slice of sky above you and respond to what’s there.\n> _\n\nAn app to create prompted and enhanced text, also by Matuschak https://withorbit.com/\n~~I have read about similar plugin in vscode. Dig this. ~~\nCould be useful mostly for class material. \n\n* https://github.com/frenya/vscode-recall\n* https://github.com/jasonwilliams/anki Directly send test from markdown to Anki !\n\n\n## Wednesday 08 September 2021\n\nYay have a look at this one for spaced repetitions\nhttps://recall.frenya.net/\n\n","n":0.066}}},{"i":52,"$":{"0":{"v":"Anki","n":1},"1":{"v":"\n## Anki\n\nThere is a guy in the dendron community using Anki (https://apps.ankiweb.net/)\n\nhttps://texdeck.net/\n\n//TODO Investigate this \n\n\n## Anki plants\n\nHere is an Anki deck if you are interested in learning more about plants taxonomy.\n\nhttps://ankiweb.net/shared/info/594735105\n\nYou have more than 4800 genus of chemically studied plants to learn !\n\nUse the desktop app with a browser side by side in order to easily fetch info (general aspects, medicinal uses, facts, geography) which will help you memorize the plants.\n\nYou can the get a bunch of stats telling you how bad you are ... Repetition is key. (I have not been looking at these in the last 2 months)\nBut I think that a small period of learning each 2/3 days is great. What I did not cath is a way to get reminder from Anki, since it's objective is to schedule the relearning this could be a useful option. Have to check this.\n\nStats that you can get from the Anki deck soft \n[stats](assets/anki-stats-2021-01-12@21-47-51.pdf)\n","n":0.081}}},{"i":53,"$":{"0":{"v":"Lims","n":1},"1":{"v":"\n\n# LIMS wiki\n\nhttps://www.limswiki.org/index.php/Main_Page\n\n\n[[#lab|tag.lab]]\n[[#organization|tag.organization]]\n","n":0.577}}},{"i":54,"$":{"0":{"v":"Km","n":1},"1":{"v":"\n# DBpedia\n\ncheck in https://fr.wikipedia.org/wiki/DBpedia\n\n\n# Tarql\n\nhttp://tarql.github.io/\n\nSPARQL for Tables: Turn CSV into RDF using SPARQL syntax\n\n\n\n\n\nhttps://knotation.org/\n\nhttp://robot.obolibrary.org/\n\n\n# RDF \n\n## convert csv to RDF \n\nhttps://stackoverflow.com/questions/43524943/creating-rdf-file-using-csv-file-as-input\n\ncheck in RDFlib\n\nhttps://rdflib.readthedocs.io/en/stable/index.html\n\n\n## GraphDB ressources\n\nhttps://graphdb.ontotext.com/free/devhub/ontologies.html?utm_campaign=GraphDB&utm_medium=email&_hsmi=101117907&_hsenc=p2ANqtz-_P3Mf-7bSerJeAWtWCXHAZCx1giPfGzHa47wQ142kn_amyTL8j2BVL7Od06EHFGR9oDXhIsdHaUL4Ln1hALrq7yMChlQ&utm_content=101117907&utm_source=hs_automation\n\n# Semantic markdown\n\nhttp://blog.sparna.fr/2020/02/20/semantic-markdown/\n\n\n# INDRA labs\n\nhttps://indralab.github.io/\n\n\n# Tiago Lubiana\n\nhttps://pointstodots.wordpress.com/2021/05/15/intro/\n\n# Linking different knowledge graphs together\n\nhttp://www.bobdc.com/blog/linkingkgs/\n\n\n# Bob DuCharme\n\nhttp://www.bobdc.com/blog/\n\n","n":0.162}}},{"i":55,"$":{"0":{"v":"Ontotext","n":1}}},{"i":56,"$":{"0":{"v":"Webinar","n":1},"1":{"v":"\nWednesday 02 June 2021\n\n\n\nWelcome to the live webinar \"Knowledge Graph Maps: 20+ Application and 30+ Capabilities\"! You are welcomed to ask questions at any time during the webinar. To do so, use the question box of your GoToWebinar panel and address them all panelists. We will try to answer as many as them during the Q&A session at the end of the webinar. Today's webinar lead will be Atanas Kiryakov, CEO of Ontotext. As a valued GraphDB user, we’d love to have you share your honest thoughts about the product on Gartner Peer Insights Platform. Reviews are anonymous and take 5 - 10 minute to complete via this link: https://go.ontotext.com/graphdb-on-gartner-peer-insights\n\n\n## Resume\n\n> Thank you for registering for \"[Webinar] Knowledge Graph Maps: 20+ Application and 30+ Capabilities\".\n> Ontotext has been at the forefront of this technology for more than 20 years – long before it was named knowledge graphs (KG). At this webinar our CEO Atanas Kiryakov will present two maps, which concentrate our knowledge about the variety of Applications that benefit from KGs and the Capabilities needed to deliver solutions and to operate systems based on KGs.\n> \n> Enterprise Knowledge Graphs serve as hubs for data, metadata and content, offering comprehensive, consistent and unified views to information scattered across different divisions, systems and paradigms.\n> \n> At this webinar Atanas Kiryakov will present:\n> - A map of over 20 KG applications across Data management, Content Management, Knowledge Management, BPM and Automation. All the way from Enterprise\n> - Taxonomies, through Content Enrichment and Master Data Management to Connected Inventories and Digital Twins.\n> - What are knowledge graphs and what is the role of semantic metadata\n> - What are the advantages of the RDF stack of standards for representation and management of knowledge graphs as compared to the Property graph model\n> - A map of over 30 capabilities necessary for a Knowledge Graph management platform\n> - How Ontotext GraphDB and Ontotext Platform address these capabilities\n> - The Ontotext’s partner ecosystem\n> \n> Who is this webinar for:\n> - Enterprise information management professionals\n> - Alliance managers of technology providers and consultants\n> - Enterprise software salespeople\n> \n> Sincerely yours,\n> \n> Ontotext Events Team\n\n\n## Who is Ontotext ?\n\n- KG thought leader\n\n![](/assets/images/2021-06-02-17-07-51.png)\n\nSince the beginning heavy focuss on text analysis (thus the name)\nApparently heavily focussed on treating Entrepise knowledge.\n\n## What is a KG ?\n\n![](/assets/images/2021-06-02-17-12-24.png)\n\n## Why KG? ... so far\n\n![](/assets/images/2021-06-02-17-14-13.png)\n\n## KG are in the hype\n\n![](/assets/images/2021-06-02-17-16-37.png)\n\n\n## Everything is metadata\n\n![](/assets/images/2021-06-02-17-19-43.png)\n\n## Application maps\n\n![](/assets/images/2021-06-02-17-23-44.png)\n\n\n## The RDF representation\n\n![](/assets/images/2021-06-02-17-38-21.png)\n\n## What ontotext does and were it partners\n\n\n(orange is ontotext blue is collabs)\n\n![](/assets/images/2021-06-02-17-40-40.png)\n\n## Partners\n\nDAta Language https://datalanguage.com/\n\nEccenca  mastering complexity https://eccenca.com/\n\n\n## Disclaimer\n\nThese are screenshots of the presentation whish was free to attend and public.\nIf you own them and don't want them online please contact me.\n\n\n\n## Videos\n\n\nOver here https://www.youtube.com/channel/UCXWXQfaPgZ4EQIxO2KucKOQ\n\n","n":0.047}}},{"i":57,"$":{"0":{"v":"Hardware","n":1}}},{"i":58,"$":{"0":{"v":"Laptops","n":1},"1":{"v":"\nhttps://itsfoss.com/get-linux-laptops/\n\nhttps://www.tuxedocomputers.com/en/Linux-Hardware/Linux-Notebooks/15-16-inch/TUXEDO-Book-Pulse-15-Gen1.tuxedo#625,36792;699,35297;717,35315;1545,34086;1845,37944;1896,38187;2108,38766;2126,38783;2127,38784;2155,38775;2297,38365;2307,38737;2308,39199\n","n":1}}},{"i":59,"$":{"0":{"v":"Graphes","n":1},"1":{"v":"\n# Ressources\n\n## Anton Tsitsulin\n\nhttp://tsitsul.in/\n\nhttps://github.com/xgfs\n\nHey! I am a Ph.D. student at the University of Bonn. I am interested in scalable, principled methods for analyzing graph data.\nYou can find more about my work on Google Scholar and personal website. Follow me on Twitter to get the latest updates.\n","n":0.147}}},{"i":60,"$":{"0":{"v":"Grakn","n":1},"1":{"v":"\n# Grakn\n\nGrakn 2.0 is out https://github.com/graknlabs/grakn/releases\nHave a look at this version.\n\nLearn more about fundamentals of hypergraphs and graphs theory. https://en.wikipedia.org/wiki/Hypergraph Ex of hypergraphes (Venn, Upset plots etc .)\n\nPaste here all the old codes used with the previous Grakn version.\nTry to implement Lotus as grakn base.\n\n## Semantic Web Standards and Grakn\n\nhttp://dev.grakn.ai/docs/comparisons/semantic-web-and-grakn\n\n","n":0.141}}},{"i":61,"$":{"0":{"v":"Git","n":1},"1":{"v":"\n\n# Nice intro\n\nLooks good for tuto and convince of git adoption Version Control with Git\n\nhttps://carpentries-incubator.github.io/git-novice-branch-pr/\n# Get info of the git remote\n\n`git config --get remote.origin.url`\n\n# Get history as a graph\n\n```\ngit fetch\ngit log --all --decorate --oneline --graph\n```\n\n\n# Pull\n\nhttps://stackoverflow.com/a/4924044\n\nSo I imagine you want to do something like:\n\n`git pull origin dev`\n\nTo set it up so that it does this by default while you're on the dev branch:\n\n`git branch --set-upstream-to dev origin/dev`\n\n\n# Reset to specific commit and push to master \n\n git reset --hard <commit-hash>\n git push -f origin main\n \n","n":0.108}}},{"i":62,"$":{"0":{"v":"Mainmaster","n":1},"1":{"v":"\nTo address the REALLY annoying master/main issue \n\n\nhttps://www.r-bloggers.com/2020/07/5-steps-to-change-github-default-branch-from-master-to-main/\n\nand eventually you need to \n\ngit pull origin master --allow-unrelated-histories\n\n(https://www.educative.io/edpresso/the-fatal-refusing-to-merge-unrelated-histories-git-error)\n\n\n","n":0.243}}},{"i":63,"$":{"0":{"v":"Gitignore","n":1},"1":{"v":"\ndesc: ''\nhttps://stackoverflow.com/questions/25436312/gitignore-not-working\n\ngit rm -rf --cached .\ngit add .\n➜  vault git:(main) git status --ignored  \n","n":0.267}}},{"i":64,"$":{"0":{"v":"Dendron","n":1}}},{"i":65,"$":{"0":{"v":"Tags","n":1},"1":{"v":"\n#course_material ~~check tag system in dendron ~~\n\nShortcut for tags is # \nso [[#tag|tag.tag]]\n\n\nCheck and explore tags / backlinks system in Dendron\n\n2021-01-10 21:59\n\nSo actually looking at https://dendron.so/notes/8bc9b3f1-8508-4d3a-a2de-be9f12ef1821.html it appears that the way to tag a note is just exactly the same as the way you would link it.\nLets try both with an existing tag/note and an unexisting on.\n\nExisting is [[tools.organization.digitalgardens]] and non existing is [[spatial.exploration]].\n\nPretty version [[#explo|spatial.explo]]\n\n\n ---\n\n //TODO Sublime ZK-like tag system. It would be really nice to have tag proposition and autocompletion\n Suggest or ask in dendron discord. \n\n","n":0.105}}},{"i":66,"$":{"0":{"v":"Spellcheck","n":1},"1":{"v":"\nThe shortcut for quick suggestions using the Code Spell Checker plugin is Cmd + .\n(or clicking on the light bulb which is often far away ....)\n","n":0.196}}},{"i":67,"$":{"0":{"v":"Screenshot","n":1},"1":{"v":"\nTo directly paste a screen shot (Mac)\n\nUse the Ctrl + Shift + Cmd + 4 combination and then Cmd + shift + P : Paste from the Dendron Paste Image menu (or opt + cmd + V)\n\n\n![](/assets/images/2021-01-02-16-44-09.png)\n","n":0.164}}},{"i":68,"$":{"0":{"v":"Multivault","n":1},"1":{"v":"\n\nTrying to implement a multivault setup after all because I would like to mange publishing and keep specific research project private or at least controled by pwd. For acces to specific collaborators wile other should be public.\n\nLet's try this.\n\nStarting here ... fell in a rabit hole.\nThe whole multivault and selective publication looks really tough ... for me at least.\nI remember now why I turned away from it several times.\n\nhttps://github.com/matteobrusa/Password-protection-for-static-pages\n\n\nSample multivault by kenvin\n\nhttps://github.com/dendronhq/sample-multivault-workspace\n\n\n\nTuesday 29 June 2021\n\nDigging this again.\n\nFollowing https://wiki.dendron.so/notes/45cfb9f2-46cf-4f67-a41e-834818fbd06e.html\n\n\nThe `Dendorn: Initialize MultiVault Workspace` is not available \nSo apparently this command is not existing anymore https://discord.com/channels/717965437182410783/735365126227493004/790801646581055508\n\nSo in fact its Vault add  from a preexisting vault\n\n\ntesting croos vault links\n\nhttps://wiki.dendron.so/notes/3472226a-ff3c-432d-bf5d-10926f39f6c2.html#cross-vault-links\n\n\nApparently they do not work when published\n\n\n\nSamedi 21 Août 2021\n\nthe multivault folder lives here '~/multivault_dendron/'\n\nDimanche 22 Août 2021\n\nnew vscode window\ncmd+shit+p \ndendron new workspace \n/Users/pma/dendron-ws-private\nblank\nthe default vault name is vault\n<!-- we rename it directly to make things clear ^pXHF3aqJs96A\nhttps://wiki.dendron.so/notes/401c5889-20ae-4b3a-8468-269def4b4865.html#renaming-a-vault -->\n\ngo to github a create a new private repo\nhttps://github.com/oolonek/dendron-ws-private.git\n\nat the ws level\ngit init\ngit add . \ngit commit -m 'initial commit'\ngit remote add origin https://github.com/oolonek/dendron-ws-private.git\ngit push -u origin main\n(complains)\ngit pull origin main  \ngit config pull.rebase true\ngit pull origin main  \ngit push -u origin main\n\nrepeat steps for ws-public\nhttps://github.com/oolonek/dendron-ws-public\n\nnow we publish both dendron\nhttps://wiki.dendron.so/notes/230d0ccf-5758-4a8f-b39b-3b68e1482e2b.html\n\nActually dont follow all the steps.\nWe head directly for github action powered publication.\n\nSo just change your dendron.yml  by adding\n\n    siteUrl: https://oolonek.github.io\n    assetsPrefix: dendron-ws-public\n\nThen we follow\n\nhttps://wiki.dendron.so/notes/877f4347-f013-43ba-aec4-87412b2e1bec.html\n\nto create the package.json at the ws roots we follow this.\n\nCreate a package.json at the root of your workspace\n\nnpm init -y\nnpm install @dendronhq/dendron-cli@latest\nnpm install @dendronhq/dendron-11ty@latest\n\n\n\n\nWe modify the dendron.yml to have the gh edit link\n\n    gh_edit_link: true\n    gh_edit_link_text: Click here to edit this page on Github !\n    gh_edit_repository: 'https://github.com/oolonek/dendron-ws-public'\n    gh_edit_branch: main\n    gh_edit_view_mode: edit\n    assetsPrefix: dendron-ws-public\n\nWe repeat for the private repo \n\n\nAll seems to be set up correctly\n[[\n\n|mapp.fundings.swissbiodata]]\nNow we will vault add the dendron-ws-public as a remote vault in the private ws\n\nthis should be done at the vault level (in the dendron-private-vault)\nWe cmd+shit+p vault add and enter https://github.com/oolonek/dendron-ws-public.git \nand two time enter this allows us to have the vault name changed to dendron-ws-public\n\n\n\nSaturday 28 August 2021\n\n\ntest duplicated note and multivault handlinh of duplicated content.\n\n[[dendron.multivault]]\n\n","n":0.054}}},{"i":69,"$":{"0":{"v":"Frontmatter","n":1},"1":{"v":"\nTo have the md preview export as html and the toc displayed add the folloing line to the Dendron notes\n\nhtml:\n  embed_local_images: true\n  embed_svg: true\n  offline: true\n  toc: true\nprint_background: false\nexport_on_save:\n  html: true\ntoc:\n  depth_from: 1\n  depth_to: 6\n  ordered: false\n---\n\n[TOC]\n\n","n":0.164}}},{"i":70,"$":{"0":{"v":"Chemistry","n":1},"1":{"v":"\nPossible to display chemical structure using the MathPix MD plugin https://github.com/mathpix/vscode-mathpix-markdown \n\n- Abscisic acid (ABA)\n\n```smiles\nOC(=O)\\C=C(\\C)/C=C/[C@@]1(O)C(C)=CC(=O)CC1(C)C\n```\n\n\n![](/assets/images/2021-01-02-16-42-20.png)\n\n\n(edit) at 2021-01-02 17:15 So the smiles code chunck will not get compiled by the 11tfty \n\n````\n`RenderError` was thrown\n> Unknown language: `smiles` is not registered\n        at node (root) (/home/runner/work/dendron/dendron/node_modules/unist-util-visit-parents/index.js:67:75)\n\n````\n\nSee https://github.com/oolonek/dendron/runs/1636940880\n\n\n\n\n","n":0.151}}},{"i":71,"$":{"0":{"v":"Biblio","n":1},"1":{"v":"# Bib integration in dendron\n\nMessing around with pandoc citer and trying to integrate bibliography management in dendron\n\nThe markender extension (<https://github.com/mjwsteenbergen/markender>) is causing conflict with pandoc citer for the autocompletion.\nDeactivate Markender\n\nConflict thrown  [[projects.tramadol]] \n\nError: Command failed: pandoc --from=markdown-raw_tex+tex_math_single_backslash --to=html --katex --filter pandoc-citeproc\nError reading bibliography /Users/pma/Documents/library_formatted.bib (line 60541, column 1):\nunexpected end of input\nexpecting \"}\", \"\\\\\" or \"{\"\nError running filter pandoc-citeproc:\nFilter returned error status 1\n\nNow trying to troubleshoot the file using bibdesk\n\n## Bib file formatting\n\nBib file formatting is required to avoid the previous error. This error is somehow misleading because it indicates that the error comes from the end of the file ... and it's not the case, rather a curly brace somewhere which is not closed.\n\nFrom the automatically sync .bib of Mendeley, make a copy and ctrl+F replace all { by \\\\'{ and all all } by \\\\'}\nThis should make the trick.\n\nSee [[cli.sed_bash]] for the recipee.\n\nAnd here goes a Note reference \n\n((ref: [[cli.sed_bash]]))\n\n//DONE check Amoeba splitting of notes (here is a typical application case ... Automatization and sed lines should go in separate notes as these can be used for other purposes than just the .bib reformating) 2021-01-02 17:30 checking .... and just splitted the above sed commands\n\n//TODO understand the way to have the bibliography display on the published version of dendron. Not the case at the moment see [[projects.tramadol]]\n\n//TODO set bibliography globally\n\n\n","n":0.067}}},{"i":72,"$":{"0":{"v":"Tests","n":1},"1":{"v":"\n# Bib integration tests in dendron\n\nThe .bib is loaded if the path to th .bib is in the header (check in the .md file)\n\n\nactive citation @Gerwick2012a\n\nhardcoded copy pasted citation Gerwick and Moore (2012)\n\n\nGerwick, William H, and Bradley S Moore. 2012. “Lessons from the past and charting the future of marine natural products drug discovery and chemical biology.” Chemistry & Biology 19 (1): 85–98. https://doi.org/10.1016/j.chembiol.2011.12.014.\n\n\nThe citation can be previewed only if Markdown Preview Enhanced is loaded. However the links can then not be viewed by Dendron Markdown Preview. Kevin is working on it https://discord.com/channels/717965437182410783/735365126227493004/794977929406185502\n\nMeanwhile a solution is to copy paste the citation from the preview to the .md.\n\nI now hae to check if links are displayed and active when published.\nLocally, hey are active in the .md\n\n\n[[projects.tramadol.data]]\n\nThis is how the preview looks like:\n\n![](/assets/images/2021-01-12-12-46-02.png)\n\n# References\n\nHere should appear the refs\n\n\n@Blunt2009\n\n\n\n```\n<p>[[projects.tramadol.data]]</p>\n<p>This is how the preview looks like:</p>\n<p><img src=\"/assets/images/2021-01-12-12-46-02.png\" /></p>\n<h1 id=\"references\">References</h1>\n<p>Here should appear the refs</p>\n<p><span class=\"citation\" data-cites=\"Blunt2009\">@Blunt2009</span></p>\n\n```\n@Blunt2009\n\n\n### 2021-01-12 15:32\n\nJust found a pandoc guru https://niszet.hatenablog.com/ and posted an issue on his git repo https://github.com/niszet/pandocplay/issues/5\n\nPandoc play might be a way to go to have these citation displayed in line.\n\nI use it with the folowing option : \n\n`\"Pandocplay.Pandoc.args\": \" -s --bibliography '/Users/pma/Documents/library_red.bib'\"\n`\nBeware of the space character before the s !\n\n\n\n\n\n## example of outputs \n\n\n@Brown2012a\n\n@oolonek\n\n@Brown2012a\n\n\n@Gerwick2012a\n\n\n@Blunt2009\n\n```\n---\nbibliography: /Users/pma/Documents/library_red.bib\n---\n\n@Brown2012a\n\n@Gerwick2012a\n\n@Blunt2009\n\n```\n\n@jimenez-lunaDrugDiscoveryExplainable2020```\n\n\n<!DOCTYPE html>\n<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"\" xml:lang=\"\">\n<head>\n  <meta charset=\"utf-8\" />\n  <meta name=\"generator\" content=\"pandoc\" />\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\" />\n  <title>runpandoctmp</title>\n  <style>\n    code{white-space: pre-wrap;}\n    span.smallcaps{font-variant: small-caps;}\n    span.underline{text-decoration: underline;}\n    div.column{display: inline-block; vertical-align: top; width: 50%;}\n    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}\n    ul.task-list{list-style: none;}\n    .display.math{display: block; text-align: center; margin: 0.5rem auto;}\n  </style>\n  <!--[if lt IE 9]>\n    <script src=\"//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js\"></script>\n  <![endif]-->\n</head>\n<body>\n<p><span class=\"citation\" data-cites=\"Brown2012a\">Brown and Okuno (2012)</span></p>\n<p><span class=\"citation\" data-cites=\"Gerwick2012a\">Gerwick and Moore (2012)</span></p>\n<p><span class=\"citation\" data-cites=\"Blunt2009\">Blunt et al. (2009)</span></p>\n<p><span class=\"citation\" data-cites=\"jimenez-lunaDrugDiscoveryExplainable2020\">(<span class=\"citeproc-not-found\" data-reference-id=\"jimenez-lunaDrugDiscoveryExplainable2020\"><strong>???</strong></span>)</span></p>\n<div id=\"refs\" class=\"references hanging-indent\" role=\"doc-bibliography\">\n<div id=\"ref-Blunt2009\">\n<p>Blunt, John W, Brent R Copp, Wan-Ping Hu, Murray H G Munro, Peter T Northcote, and Michèle R Prinsep. 2009. “Marine natural products.” <em>Natural Product Reports</em> 26 (2): 170–244. <a href=\"https://doi.org/10.1039/b805113p\">https://doi.org/10.1039/b805113p</a>.</p>\n</div>\n<div id=\"ref-Brown2012a\">\n<p>Brown, J. B., and Yasushi Okuno. 2012. “Systems Biology and Systems Chemistry: New Directions for Drug Discovery.” <em>Chemistry &amp; Biology</em> 19 (1): 23–28. <a href=\"https://doi.org/10.1016/j.chembiol.2011.12.012\">https://doi.org/10.1016/j.chembiol.2011.12.012</a>.</p>\n</div>\n<div id=\"ref-Gerwick2012a\">\n<p>Gerwick, William H, and Bradley S Moore. 2012. “Lessons from the past and charting the future of marine natural products drug discovery and chemical biology.” <em>Chemistry &amp; Biology</em> 19 (1): 85–98. <a href=\"https://doi.org/10.1016/j.chembiol.2011.12.014\">https://doi.org/10.1016/j.chembiol.2011.12.014</a>.</p>\n</div>\n</div>\n</body>\n</html>\n\n```\n\n","n":0.052}}},{"i":73,"$":{"0":{"v":"Further","n":1},"1":{"v":"\n@Brown2012a\n\n\n\n\n\n\n\n@article{allard2020comparative,\n  title = {Comparative Molecular Networking Analysis of a {{Rauwolfia}} Plant Powder and Biological Matrices in a Fatal Ingestion Case},\n  author = {Allard, Sophie and Le Daré, Brendan and Allard, Pierre-Marie and Morel, Isabelle and Gicquel, Thomas},\n  date = {2020},\n  journaltitle = {Forensic Toxicology},\n  volume = {38},\n  number = {2},\n  pages = {447--454},\n  publisher = {{Springer Singapore}}\n}\n```\n@article{allard2020comparative, title = {Comparative Molecular\nNetworking Analysis of a {{Rauwolfia}} Plant Powder and Biological\nMatrices in a Fatal Ingestion Case}, author = {Allard, Sophie and Le\nDaré, Brendan and Allard, Pierre-Marie and Morel, Isabelle and Gicquel,\nThomas}, date = {2020}, journaltitle = {Forensic Toxicology}, volume =\n{38}, number = {2}, pages = {447--454}, publisher = {{Springer\nSingapore}} }\n\n```\n\n\n@article{Blunt2012a,\n  title = {Marine Natural Products.},\n  author = {Blunt, John W. and Copp, Brent R. and Keyzers, Robert A. and Munro, Murray H.G. G. and Prinsep, Michèle R Michele R Michèle R. and Northcote, Peter T. and Prinsep, Michèle R Michele R Michèle R. and Hu, Wan-Ping and Munro, Murray H.G. G. and Northcote, Peter T. and Prinsep, Michèle R Michele R Michèle R. and Keyzers, Robert A. and Munro, Murray H.G. G. and Prinsep, Michèle R Michele R Michèle R. and Northcote, Peter T. and Prinsep, Michèle R Michele R Michèle R. and Keyzers, Robert A. and Munro, Murray H.G. G. and Prinsep, Michèle R Michele R Michèle R. and Hu, Wan-Ping and Munro, Murray H.G. G. and Northcote, Peter T. and Prinsep, Michèle R Michele R Michèle R. and Keyzers, Robert A. and Munro, Murray H.G. G. and Prinsep, Michèle R Michele R Michèle R. and Northcote, Peter T. and Prinsep, Michèle R Michele R Michèle R.},\n  date = {2012-02},\n  journaltitle = {Natural product reports},\n  volume = {29},\n  number = {1},\n  eprint = {22193773},\n  eprinttype = {pmid},\n  pages = {144--222},\n  issn = {0265-0568},\n  doi = {10.1039/c2np00090c},\n  url = {http://www.ncbi.nlm.nih.gov/pubmed/16453031 http://www.ncbi.nlm.nih.gov/pubmed/20111802 http://www.ncbi.nlm.nih.gov/pubmed/22193773 http://www.ncbi.nlm.nih.gov/pubmed/17268607 http://xlink.rsc.org/?DOI=b207130b http://www.ncbi.nlm.nih.gov/pubmed/21152619},\n  abstract = {Covering: 2015. Previous review: Nat. Prod. Rep., 2016, 33, 382-431 This review covers the literature published in 2015 for marine natural products (MNPs), with 1220 citations (792 for the period January to December 2015) referring to compounds isolated from marine microorganisms and phytoplankton, green, brown and red algae, sponges, cnidarians, bryozoans, molluscs, tunicates, echinoderms, mangroves and other intertidal plants and microorganisms. The emphasis is on new compounds (1340 in 429 papers for 2015), together with the relevant biological activities, source organisms and country of origin. Reviews, biosynthetic studies, first syntheses, and syntheses that lead to the revision of structures or stereochemistries, have been included.},\n  keywords = {Animals,Biological Agents,Biological Agents: chemistry,Biological Agents: classification,Biological Products,Biological Products: chemical synthesis,Biological Products: chemistry,Biological Products: classification,Biological Products: isolation & purification,Biological Products: pharmacology,Bryozoa,Bryozoa: chemistry,Cnidaria,Cnidaria: chemistry,Echinodermata,Echinodermata: chemistry,Eukaryota,Eukaryota: chemistry,Marine Biology,Molecular Structure,Mollusca,Mollusca: chemistry,Phytoplankton,Phytoplankton: chemistry,Porifera,Porifera: chemistry,Urochordata,Urochordata: chemistry,Verbenaceae,Verbenaceae: chemistry},\n  file = {/Users/pma/Zotero/storage/YNDFGNQV/Marine natural products2012.pdf}\n}\n\n@incollection{Wolfender2019a,\n  title = {Metabolomics Strategies for the Dereplication of Polyphenols and Other Metabolites in Complex Natural Extracts},\n  booktitle = {Recent Advances in Polyphenol Research},\n  author = {Wolfender, Jean-Luc and Allard, Pierre-Marie and Kubo, Miwa and Queiroz, Emerson Ferreira},\n  date = {2019-01},\n  volume = {6},\n  pages = {183--205},\n  publisher = {{John Wiley \\& Sons, Ltd}},\n  location = {{Chichester, UK}},\n  doi = {10.1002/9781119427896.ch7},\n  url = {http://doi.wiley.com/10.1002/9781119427896.ch7},\n  abstract = {PDF | Metabolomics emerged in the early 2000s and was defined in the field of natural products (NPs) research as ‘large‐scale phytochemistry in the functional genomics era'. Since then, metabolomics, which aims at the comprehensive analysis of the metabolome of various organisms,...},\n  file = {/Users/pma/Zotero/storage/FWA6PYDA/Metabolomics Strategies for the Dereplication of Polyphenols and Other Metabolites in Complex Natural Extracts.pdf}\n}\n\n\nTesting referenccite + https://ctroupin.github.io/posts/2019-12-19-bibtex-markdown/\n\n\n","n":0.042}}},{"i":74,"$":{"0":{"v":"Code","n":1}}},{"i":75,"$":{"0":{"v":"Ts","n":1},"1":{"v":"\n## Typescript\n\nRead about it here https://www.typescriptlang.org/docs/handbook/typescript-from-scratch.html\n\n","n":0.408}}},{"i":76,"$":{"0":{"v":"Python","n":1}}},{"i":77,"$":{"0":{"v":"Tests","n":1},"1":{"v":"\nSaturday 11 December 2021\n\nhttps://realpython.com/python-testing/\n\n","n":0.5}}},{"i":78,"$":{"0":{"v":"Ressources","n":1},"1":{"v":"\n# Introducing \"Dead Simple Python\"\n\n13 part detailed but concise Python tutorial\n\nhttps://dev.to/codemouse92/introducing-dead-simple-python-563o\n\n\n","n":0.302}}},{"i":79,"$":{"0":{"v":"Pandas","n":1},"1":{"v":"\n## Subset a df according to string present in columns name\n\n```python\ndf.loc[:, df.columns.str.startswith('alp')]\n```\n\n```python\ndf.loc[:, df.columns.str.contains('alp')]\n```\n## Select a df according to column positions\n\nHere from column seven till the end \n\n```python\ndf.iloc[:, 7:]\n```\n\n\n## Rename columns\n\n```python\ndf.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)\n```\n## Rename columns or index\n\n```python\ndf_new = df.rename(columns={'A': 'Col_1'}, index={'ONE': 'Row_1'})\n```\n\nDidnt work for me\n\ndf_merged_selected.index.rename('Row ID', inplace = True)\n does\n## Rename columns by position\n\n```python\ndf.rename(columns={ df.columns[1]: \"your value\" }, inplace = True)\n```\n\n## Check df datatype\n\n```python\ndf.dtypes\n```\n\n## Convert to a specific type\n\n```python\ndf.year.astype(int)\n```\n\n# From continuous to categorical \n\n```python\npd.cut(df.Age,bins=[0,2,17,65,99],labels=['Toddler/Baby','Child','Adult','Elderly'])\n```\n\n\n# Merge two df based on index\n\n```python\npd.merge(df1, df2, left_index=True, right_index=True)\n```\n\n# replace specific string in values\n\n```python\ndf['Column2'] = df.Column2.str.replace('b,?' , '')\n```\n\n# drop column according to regex\n\n```python\ndf = df[df.columns.drop(list(df.filter(regex='Test')))]\n```\n\n# drop columns according to list\n\n\n```python\n# %%\ncolsToDrop = [     'BARCODE',            'PLATESET',                'WELL',\n            'SUBSTANCE_NAME',        'Full_Species',               'Genus',\n                  'Sp_alone',             'Species',             'Famille']\n\ndf_merged_selected=df_merged.drop(colsToDrop, axis=1)\ndf_merged_selected\n\n```\n\n\n# If Na replace with value of the same row but another column\n\nhttps://stackoverflow.com/a/29177664\n\n```python\ndf.Temp_Rating.fillna(df.Farheit, inplace=True)\ndel df['Farheit']\ndf.columns = 'File heat Observations'.split()\n\n```\n\n# Extract digits from a string \n\nhttps://stackoverflow.com/a/37683738\n\n\n```python\ndf.A.str.extract('(\\d+)')\n```\n\n# Create multiples columns values conditionally using np.where\nhttps://stackoverflow.com/a/19913845\n\n```python\ndf = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})\nconditions = [\n    (df['Set'] == 'Z') & (df['Type'] == 'A'),\n    (df['Set'] == 'Z') & (df['Type'] == 'B'),\n    (df['Type'] == 'B')]\nchoices = ['yellow', 'blue', 'purple']\ndf['color'] = np.select(conditions, choices, default='black')\nprint(df)\n\n```\n# drop duplicates according to multiple coloumns\n\nDataFrame.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html\n\ndf.drop_duplicates(subset=['a', 'b'], keep='first', inplace=True, ignore_index=False)\n","n":0.072}}},{"i":80,"$":{"0":{"v":"Packages","n":1}}},{"i":81,"$":{"0":{"v":"Import","n":1},"1":{"v":"\n## Complete Guide to Imports in Python: Absolute, Relative, and More\nHow to plan your code so imports are clear and clean \n\nhttps://www.pythonforthelab.com/blog/complete-guide-to-imports-in-python-absolute-relative-and-more/\n","n":0.213}}},{"i":82,"$":{"0":{"v":"Oop","n":1},"1":{"v":"# Object Oriented Programming\n\n\nVery instructive video on the basics of OOP.\nWhat is a Class, what is a method ?\nHow they can be of interest for : \n- encapsulation (need to see this part again)\n- inheritance\n- polymorphism\n\nGreat teacher. Look for additional tuto.\n\n\nhttps://www.youtube.com/watch?v=MikphENIrOo\n\n\n## DataClass\n\nhttps://www.geeksforgeeks.org/data-classes-in-python-an-introduction/\n\n\n\n","n":0.154}}},{"i":83,"$":{"0":{"v":"Mamba","n":1},"1":{"v":"\n# Create environment\n\nmamba create -n taxonomical-preparator\n\n","n":0.408}}},{"i":84,"$":{"0":{"v":"Conda","n":1}}},{"i":85,"$":{"0":{"v":"Environments","n":1},"1":{"v":"\n@\n","n":1}}},{"i":86,"$":{"0":{"v":"Update","n":1},"1":{"v":"\nTo update a conda environment given a .yml file\n\nhttps://stackoverflow.com/a/43873901\n\n```bash\nconda activate myenv\nconda env update --file environment.yml\n```\n\nOr without the need to activate the environment (thanks @NumesSanguis):\n\n```bash\nconda env update --name myenv --file environment.yml\n````\n","n":0.183}}},{"i":87,"$":{"0":{"v":"Export","n":1},"1":{"v":"# To create a loose conda environment see details over there\n\n<https://repo2docker.readthedocs.io/en/latest/howto/export_environment.html>\n\n`conda env export --from-history -f environment.yml`\n\nTo create and env from this .yml file run [[tools.code.python.conda.environments.creation]]\n\n\n\n```bash\n```\n\n- `11:49` \n\n2021-01-11 11:49\n\n\n","n":0.189}}},{"i":88,"$":{"0":{"v":"Delete","n":1},"1":{"v":"\n# Delete\n\n`conda env remove -n ENV_NAME`\n","n":0.408}}},{"i":89,"$":{"0":{"v":"Creation","n":1},"1":{"v":"\n\nYou can create an env from a given .yml file using \n\n```bash\nconda env create -f environment.yml\n```\n\nOr directly like this \n\n```bash\nconda create --name myenv\n```\n\nWith a given python version \n\n```bash\nconda create -n \"chemical_diversity_explorer_dev\" python=3.7\n```\n","n":0.177}}},{"i":90,"$":{"0":{"v":"Activation","n":1},"1":{"v":"\n\n## Conda env activation \n\nsource ~/anaconda3/etc/profile.d/conda.sh\n\nconda activate my_env\nconda activate opennbdb_dev_env\n\n\nWhen this error occurs:\n\nCommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\nTo initialize your shell, run\n\nsource ~/anaconda3/etc/profile.d/conda.sh\n\n\n## ipykernel problems\n\npip install --upgrade pyzmq jupyterlab jupyter --force-reinstall\n\nhttps://github.com/jupyter/notebook/issues/3435#issuecomment-566146547\n\n\n","n":0.164}}},{"i":91,"$":{"0":{"v":"Cheatsheet","n":1},"1":{"v":"\n[Conda_Cheat_Sheet](../../../Dropbox/Papers/Bioinformatics/conda-cheatsheet.pdf)\n","n":1}}},{"i":92,"$":{"0":{"v":"CLI","n":1},"1":{"v":"\n# How to Code with Me - Making a CLI\n\nhttps://cthoyt.com/2020/06/11/click.html\n\n","n":0.316}}},{"i":93,"$":{"0":{"v":"Classes","n":1},"1":{"v":"https://nickmccullum.com/how-to-write-python-classes/\n\n\n","n":1}}},{"i":94,"$":{"0":{"v":"Js","n":1},"1":{"v":"\n## Javascript\n\nhttps://developer.mozilla.org/fr/docs/Web/JavaScript/Guide\n\nhttps://www.codecademy.com/learn/introduction-to-javascript\n\n","n":0.707}}},{"i":95,"$":{"0":{"v":"CLI","n":1},"1":{"v":" ---\nid: 85f109b5-4c48-4a6a-8447-24d1228f0ba8\ntitle: CLI\ndesc: ''\nupdated: 1610889677922\ncreated: 1610889677922\nstub: false\n---\n\n","n":0.378}}},{"i":96,"$":{"0":{"v":"Rsync","n":1},"1":{"v":"\nNote : pasted from ZK sublime ()\n\nSub [[202002291826]] terminal and unix shortcuts\n\n\n# local > x2go \n\n```bash\nrsync -rvz -e 'ssh -p 80' --progress ./ allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/pybatchclassyfire/\nrsync -rvz -e 'ssh -p 80' --progress ./ allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/\npybatchclassyfire/\nrsync -rvz -e 'ssh' --progress ./ allardp@10.25.88.39:/home/EPGL.UNIGE.LOCAL/allardp/\nrsync -rvz -e 'ssh' --progress ./ allardp@10.25.88.39:/home/EPGL.UNIGE.LOCAL/allardp/opennaturalproductsdb/data/interim/tables/3_curated/\n\nrsync -rvz -e 'ssh' --progress ./ allardp@x2go.epgl-geneve.org:/home/farma.unige.ch/allardp/Desktop/FARMAnetwork/RECHERCHE/COMMON\\ FASIE-FATHO/PMA/Ubuntu_VM_img/ISDB_DNP/results\nrsync -rvz -e 'ssh' --progress ./ allardp@x2go.epgl-geneve.org:/home/farma.unige.ch/allardp/Desktop/FARMAnetwork/RECHERCHE/COMMON\\ FASIE-FATHO/PF_project\nrsync -rvz -e 'ssh' --progress ./ allardp@x2go.epgl-geneve.org:/home/farma.unige.ch/allardp/is_fragmentation/lotus_data\n```\n\n# local > baobab\n\n```bash\nrsync -rvz -e 'ssh' --progress ./opennpdb_tofrag allardp@baobab2.unige.ch:/home/allardp/data_to_frag/opennpdb/\nrsync -rvz -e 'ssh' --progress ./ allardp@baobab2.unige.ch:/home/allardp/bash_files/opennpdb_bash\n\nrsync -rvz -e 'ssh' --progress ./ allardp@baobab2.hpc.unige.ch:/home/allardp/bash_files/lotus_bash\nrsync -rvz -e 'ssh' --progress ./ allardp@baobab2.hpc.unige.ch:/home/allardp/data_to_frag/lotus/\n\n\nrsync -rvz -e 'ssh' --progress ./ allardp@baobab2.hpc.unige.ch:/home/allardp/is_fragmentation/lotus_data/\n\n```\n\n# local > beast\n\n```bash\nrsync -rvz -e 'ssh' --progress ./ allardpm@biolpc045600:/home/allardpm/data_to_frag/opennpdb/\nrsync -rvz -e 'ssh' --progress ./ allardpm@biolpc045600:/home/allardpm/cfm/bash_files\n```\n\n\n\n# beast > local\n\n```bash\nrsync -rvz -e 'ssh' --progress allardpm@biolpc045600:/home/allardpm/sandbox/GNPS_output_Qemistree_set/*.qza ./ \n\n# to fetch all file with a given extension. See https://stackoverflow.com/a/11111793 for details\n\nrsync -rvz -e 'ssh' --include=\"*/\" --include=\"*.qza\" --exclude=\"*\" --progress allardpm@biolpc045600:/home/allardpm/sandbox/GNPS_output_Qemistree_set/ ./\n```\n\n\n# x2go > local \n\n```bash\nrsync -rvz -e 'ssh -p 80' --progress allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/is_fragmentation/coconut_data/coconut_ISDB_pos.mgf /Users/pma/Dropbox/People/Swap_MS/ISDB_Coconut\nrsync -rvz -e 'ssh -p 80' --progress allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/opennaturalproductsdb/1_databases/PLANTCYC/2_chemo/2_rdkit/PLANTCYC_chemo_rdkit_new_pm.tsv ./\nrsync -rvz -e 'ssh -p 80' --progress allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/opennaturalproductsdb/1_databases/PLANTCYC/2_chemo/2_rdkit/PLANTCYC_chemo_rdkit_sanitized_pm.tsv ./\nrsync -rvz -e 'ssh -p 80' --progress allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/opennaturalproductsdb/outputs/tables/3_curated/curated_tablesampled1000.tsv ./\nrsync -rvz -e 'ssh -p 80' --progress allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/opennaturalproductsdb/outputs/tables/3_curated/curatedTable5000_shuffled_headed ./\nrsync -rvz -e 'ssh -p 80' --progress allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/qiime2_cscs_explo_remote/pfabre/cscs_PCoA.qzv ./\nrsync -rvz -e 'ssh' --progress allardp@10.25.88.39:/home/EPGL.UNIGE.LOCAL/allardp/opennaturalproductsdb/data/interim/tables/1_translated/structure/unique.tsv ./\n\nrsync -rvz -e 'ssh' --progress allardp@10.25.88.39:/home/EPGL.UNIGE.LOCAL/allardp/opennaturalproductsdb/data/interim/tables_min/3_curated/smiles.gz ./\n\nrsync -rvz -e 'ssh' --progress --include '*.txt' allardp@10.25.88.39:/home/EPGL.UNIGE.LOCAL/allardp/opennaturalproductsdb/data/interim/tables/3_curated/ ./\n\nrsync -rvz -e 'ssh -p 80' --progress allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/Desktop/FARMAnetwork/RECHERCHE/COMMON\\ FASIE-FATHO/Workshop_Material/Data_annotation_Workshop_2019/190225_FullDNP_prot_deprot.csv ./\n\n\nrsync -rvz -e 'ssh' --progress \"allardp@x2go.epgl-geneve.org:/home/farma.unige.ch/allardp/Desktop/FARMAnetwork/RECHERCHE/COMMON\\ FASIE-FATHO/PMA/Ubuntu_VM_img/ISDB_DNP/results/fbmn_lena_metabo_results_DNP_top50.out\" ./ \n\nrsync -rvz -e 'ssh' --progress \"allardp@x2go.epgl-geneve.org:/home/farma.unige.ch/allardp/lotusProcessor/data/interim/tables/4_analysed/platinum.tsv.gz\" ./ \n\nrsync -rvz -e 'ssh' --progress \"allardp@x2go.epgl-geneve.org:/home/farma.unige.ch/allardp/lotusProcessor/data/processed/lotus.sqlite\" ./ \n\nrsync -rvz -e 'ssh' --progress \"allardp@x2go.epgl-geneve.org:/home/farma.unige.ch/allardp/Documents/Toy_Dataset_MN/GNPS_output_Toy_Dataset_MN/cscs_PCoA.qzv\" ./ \n\n\nrsync -rvz -e 'ssh' --progress \"allardp@x2go.epgl-geneve.org:/home/farma.unige.ch/allardp/Documents/PF_GNP3/GNPS_output_PF_GNP3/feature_table_for_biom.tsv\" ./ \n\n\n\n\n\n```\n\n\n# baobab > local \n\n```bash\nrsync -rvz -e 'ssh' --progress allardp@baobab2.unige.ch:/home/allardp/CFM_results/npatlas ./results\nrsync -rvz -e 'ssh' --progress allardp@baobab2.unige.ch:/home/allardp/CFM_results/npatlas ./results\nrsync -rvz -e 'ssh' --progress allardp@baobab2.unige.ch:/home/allardp/CFM_results/coconut ./ --apend\n```\n\n# metabomaps > local \n\n\n\nrsync -rvz -e 'ssh' --progress --rsync-path=\"sudo rsync\" ~/Downloads/wetransfer-27d788/210523_lotus_map4_2D.js pma@metabomaps.nprod.net:/srv/metabo-store/tmap\n","n":0.058}}},{"i":97,"$":{"0":{"v":"Bash","n":1},"1":{"v":"\n# Rename files\n\n```bash\nfor f in *.png; do echo mv \"$f\" \"${f/_*_/_}\"; done\n```\n\nRemove echo \n\nhttps://stackoverflow.com/a/24103055\n\n[[#tremendous|tag.tremendous]]\n\n# List all files and folder in a graphical tree in terminal\n\nYou need to \n`brew install tree`\n\nThen you can `tree` or `tree -lart`\n# List all files and their full path\n\nls -d -1 \"$PWD/\"*.*\n\n\n# bash upgrade on mac\n\nhttps://itnext.io/upgrading-bash-on-macos-7138bd1066ba\n\nHad some problem when running the build.sh script of manubot.\nBecause of this error \n\nbuild/build.sh: line 50: ${BUILD_PDF,,}: bad substitution\nTurns out that ,, are not \n\nhttps://stackoverflow.com/a/47815884\n\n","n":0.116}}},{"i":98,"$":{"0":{"v":"Chemoinformatics","n":1},"1":{"v":"\nCheck SELFIES, a 100% robust molecular string representation, in the context of general molecular graph representations.\n\nhttps://aspuru.substack.com/p/molecular-graph-representations-and\n\n\n","n":0.25}}},{"i":99,"$":{"0":{"v":"Qiime","n":1},"1":{"v":"\n## Core concepts \n\nhttps://docs.qiime2.org/2020.8/concepts\n\n\n## Semantic types\n\nhttps://docs.qiime2.org/2020.8/semantic-types/\n\n\n## Glossary\n\nhttps://docs.qiime2.org/2020.8/glossary/\n\n\n## Running Qiime\n\n`conda activate qiime2-2020.8`\n\n`qiime`\n\n\n## lets try to make a heatmap\n\nqiime feature-table heatmap \\\n--i-table table-with-phyla.qza \\\n--o-visualization heatmap.qzv\n\n## importing and exporting tables\n\nThis passes by the BIOM format https://forum.qiime2.org/t/exporting-and-modifying-biom-tables-e-g-adding-taxonomy-annotations/3630\n\n\n  \n","n":0.171}}},{"i":100,"$":{"0":{"v":"Empress","n":1}}},{"i":101,"$":{"0":{"v":"Mandelbrot","n":1},"1":{"v":"\n# A Qiime recipee for Empress display of the pf_project\n\n## Required inputs\n\n- [ ] a feature table (mzmine output)\n- [ ] a sample metadata table\n- [ ] a feature metadata table\n\nBeware of the confusion between samples and features. In Qiime features refer to OTU and thus have an assigned taxonomy. I our case we have the taxonomy assigned to the samples.\n\n\n\n\n# First we deal with the tree file\n\nqiime tools import \\\n  --input-path otol_tree_rooted.tre \\\n  --output-path otol_tree_rooted.qza \\\n  --type 'Phylogeny[Rooted]'\n\n# the we deal with the feature table \n\n## First we use biom to convert the tsv to the biom format \nbiom convert \\\n-i feature_table.tsv \\\n-o feature_table.biom \\\n--table-type=\"OTU table\" \\\n--to-hdf5\n\n## Conversion to qiime featureTable\n\nqiime tools import \\\n--type 'FeatureTable[Frequency]' \\\n--input-path feature_table.biom \\\n--output-path feature_table.qza\n\n## We EMPRESS the whole shit\n  \nqiime empress community-plot \\\n  --i-tree otol_tree_rooted.qza \\\n  --i-feature-table feature_table.qza \\\n  --m-sample-metadata-file sample_metadata.tsv \\\n  --m-feature-metadata-file feature_taxa.tsv \\\n  --o-visualization empress-tree.qzv \\\n  --p-filter-missing-features \\\n  --p-ignore-missing-samples\n\n\nSadly we get the follwoing message\n\nPlugin error from empress:\n\n  At least one non-root branch of the tree must have a positive length.\n\n\nWe thus try to compute branch lenght in R using the ape package\n\n# we infer branch lenght\n\ntaxa_tree <-compute.brlen(taxa_tree)\ntaxa_tree <- read.tree('Dropbox/Research_UNIGE/git_repos/qiime-empress-formatter/src/python/otol_tree.tre')\n\n# we root the tree\n\n# wd_tree_len_rooted <- root(wd_tree_len, outgroup = \"Methanobacterium\", resolve.root = TRUE)\n\nis.rooted(taxa_tree)\n\n\nwrite.tree(taxa_tree, '~/tmp/empress-tutorial/ecometabo_toyset/ecometabo_taxa_tree_rooted.tree')\n\nwrite.tree(taxa_tree, 'Dropbox/Research_UNIGE/git_repos/qiime-empress-formatter/src/python/otol_tree_rooted.tre')\n\n\n# Lets add some metadata for the feature table viz\n\nqiime feature-table summarize \\\n  --i-table feature_table.qza \\\n  --o-visualization feature_table_viz.qzv \\\n  --m-sample-metadata-file sample_metadata.tsv\n\n## metadata viz\n\nqiime metadata tabulate \\\n  --m-input-file sample_metadata.tsv \\\n  --o-visualization sample_metadata.qzv\n\n## lets try some metadat based filtering of the feature table\n\nqiime feature-table filter-samples \\\n  --i-table feature_table.qza \\\n  --m-metadata-file sample_metadata.tsv \\\n  --p-where \"[Taxonomical_Score_ISDB]>0\" \\\n  --o-filtered-table taxscore-filtered-feature_table.qza\n\n\nqiime feature-table filter-samples \\\n  --i-table feature-contingency-filtered-table.qza \\\n  --m-metadata-file sample_metadata.tsv \\\n  --p-where \"[Consensus_class_ci_cf]!='nan'\" \\\n  --o-filtered-table nan-filtered-table.qza\n\n\nqiime empress community-plot \\\n  --i-tree otol_tree_rooted.qza \\\n  --i-feature-table taxscore-filtered-feature_table.qza \\\n  --m-sample-metadata-file sample_metadata.tsv \\\n  --m-feature-metadata-file feature_taxa.tsv \\\n  --m-feature-metadata-file metadata_otoled.tsv \\\n  --o-visualization empress-tree.qzv \\\n  --p-filter-missing-features \\\n  --p-ignore-missing-samples\n\n\n","n":0.058}}},{"i":102,"$":{"0":{"v":"Cscs","n":1},"1":{"v":"\n# qiime CSCS cookbook\n\n# bioinfo_qiime2_cscs_workflow\ntags = #bioinfo #recipee #tutorial #qiime\n\nList of commands and recippe for a qiime2 cscs project\n\nqiime2\n<https://docs.qiime2.org/2020.2/getting-started/>\n\nqiime cscs \n<https://github.com/madeleineernst/q2-cscs#2-compute-the-chemical-structural-and-compositional-dissimilarity-for-a-real-world-dataset>\n\n\ndownload the GNPS job\n\nMind the DownloadResult?task= string !!!\n\n`curl -d \"\" 'https://gnps.ucsd.edu/ProteoSAFe/DownloadResult?task=5729dd0f7a47475abc879e164c237f56&view=download_cluster_buckettable' -o GNPS_output.zip`\n\nfetch the metadata table :\n\n`cp GNPS_output/quantification_table_reformatted/d6548148e7e040bb8d573bc6d4954d4b.csv GNPS_buckettable.csv`\n\n\neventually remove some columns see [[20200611160123]] terminal_directly_cut_csv_column\n\n`cut --complement -f 2,3 -d, GNPS_buckettable.csv > GNPS_buckettable_tomod.csv`\n\nthen convert from csv to tsv see [[20200611161504]] terminal_convert_csv_to_tsv\n\n`cat GNPS_buckettable_tomod.csv | tr \",\" \"\\\\t\" > GNPS_buckettable.tsv`\n\nyou can now convert to BIOM format \n\n`biom convert -i GNPS_buckettable.tsv -o GNPS_buckettable.biom --table-type=\"OTU table\" --to-hdf5\n\nrun using cpus \n\n\ntime qiime cscs cscs --p-css-edges GNPS_edges.tsv --i-features GNPS_buckettable.qza --p-cosine-threshold 0.7 --p-normalization --p-cpus 40 --o-distance-matrix cscs_distance_matrix.qza\n\n\n\n###########\nBrutal command line history\n\n2664  source activate qiime2-2020.2\n 2665  qiime cscs cscs --p-css-edges small_GNPS_edges.tsv --i-features small_GNPS_buckettable.qza --p-cosine-threshold 0.5 --p-normalization --o-distance-matrix small_cscs_distance_matrix.qza\n 2666  ls\n 2667  wget https://raw.githubusercontent.com/madeleineernst/q2-cscs/master/tests/data/small_GNPS_buckettable.qza\n 2668  wget https://raw.githubusercontent.com/madeleineernst/q2-cscs/master/tests/data/small_GNPS_edges.tsv\n 2669  qiime cscs cscs --p-css-edges small_GNPS_edges.tsv --i-features small_GNPS_buckettable.qza --p-cosine-threshold 0.5 --p-normalization --o-distance-matrix small_cscs_distance_matrix.qza\n 2670  qiime tools view cscs_PCoA.qzv\n 2671  qiime tools view cscs_PCoA.qza\n 2672  ls -larts\n 2673  biom convert -i GNPS_buckettable.tsv -o GNPS_buckettable.biom --table-type=\"OTU table\" --to-hdf5\n 2674  qiime tools import --type 'FeatureTable[Frequency]' --input-path GNPS_buckettable.biom --output-path GNPS_buckettable.qza\n 2675  qiime cscs cscs --p-css-edges GNPS_edges.tsv --i-features GNPS_buckettable.qza --p-cosine-threshold 0.5 --p-normalization --o-distance-matrix cscs_distance_matrix.qza\n 2676  qiime cscs cscs\n 2677  qiime cscs cscs --p-css-edges GNPS_edges.tsv --i-features GNPS_buckettable.qza --p-cosine-threshold 0.5 --p-normalization --p-cpus 4 --o-distance-matrix cscs_distance_matrix.qza\n 2678  htop\n 2679  qiime diversity pcoa --i-distance-matrix cscs_distance_matrix.qza --o-pcoa cscs_PCoA.qza\n 2680  qiime emperor plot --i-pcoa cscs_PCoA.qza --m-metadata-file MappingFile_UrineSamples.txt --o-visualization cscs_PCoA.qzv\n 2681  qiime tools view cscs_PCoA.qzv\n 2682  qiime diversity beta --i-table GNPS_buckettable.qza  --p-metric braycurtis --o-distance-matrix braycurtis_GNPS_buckettable.qza\n 2683  qiime diversity pcoa --i-distance-matrix braycurtis_GNPS_buckettable.qza --o-pcoa braycurtis_PCoA.qza\n 2684  qiime emperor plot --i-pcoa braycurtis_PCoA.qza --m-metadata-file MappingFile_UrineSamples.txt --o-visualization braycurtis_PCoA.qzv\n 2685  qiime tools view braycurtis_PCoA.qzv\n 2686  qiime diversity mantel --i-dm1 cscs_distance_matrix.qza --i-dm2 braycurtis_GNPS_buckettable.qza --o-visualization mantel.qzv\n 2687  qiime diversity procrustes-analysis --i-reference braycurtis_PCoA.qza --i-other cscs_PCoA.qza --output-dir ./procrustes-out\n 2688  qiime emperor procrustes-plot --i-reference-pcoa procrustes-out/transformed_reference.qza --i-other-pcoa procrustes-out/transformed_other.qza --m-metadata-file MappingFile_UrineSamples.txt --o-visualization procrustes-out/plot.qzv\n 2689  qiime tools view procrustes-out/plot.qzv\n 2690  ls -lart\n 2691  cd erythroxylum\n 2692  ls\n 2693  biom convert -i GNPS_buckettable.tsv -o GNPS_buckettable.biom --table-type=\"OTU table\" --to-hdf5\n 2694  qiime tools import --type 'FeatureTable[Frequency]' --input-path GNPS_buckettable.biom --output-path GNPS_buckettable.qza\n 2695  qiime cscs cscs --p-css-edges GNPS_edges.tsv --i-features GNPS_buckettable.qza --p-cosine-threshold 0.7 --p-normalization -p-cpus 6 --o-distance-matrix cscs_distance_matrix.qza\n 2696  qiime cscs cscs --p-css-edges GNPS_edges.tsv --i-features GNPS_buckettable.qza --p-cosine-threshold 0.7 --p-normalization --p-cpus 6 --o-distance-matrix cscs_distance_matrix.qza\n 2697  ssh x2go.epgl-geneve.org -p 80\n 2698  ssh allardp@x2go.epgl-geneve.org -p 80\n 2699  cd Dropbox/Research_UNIGE/git_repos\n 2700  git clone https://github.com/madeleineernst/pyMolNetEnhancer.git\n 2701  qiime diversity pcoa --i-distance-matrix cscs_distance_matrix.qza --o-pcoa cscs_PCoA.qza\n 2702  ls\n 2703  cd GNPS_output\n 2704  ls\n 2705  cd metadata_table\n 2706  ls\n 2707  nano metadata_table-00000.txt\n 2708  cd ..\n 2709  qiime emperor plot --i-pcoa cscs_PCoA.qza --m-metadata-file GNPS_output/metadata_table/metadata_table-00000.txt --o-visualization cscs_PCoA.qzv\n 2710  nano GNPS_output/metadata_table/metadata_table-00000.txt\n 2711  qiime emperor plot --i-pcoa cscs_PCoA.qza --m-metadata-file GNPS_output/metadata_table/metadata_table-00000.txt --o-visualization cscs_PCoA.qzv\n 2712  ls\n 2713  nano GNPS_output/metadata_table/metadata_table-00000.txt\n 2714  qiime emperor plot --i-pcoa cscs_PCoA.qza --m-metadata-file GNPS_output/metadata_table/metadata_table-00000.txt --o-visualization cscs_PCoA.qzv\n 2715  nano GNPS_output/metadata_table/metadata_table-00000.txt\n 2716  qiime emperor plot --i-pcoa cscs_PCoA.qza --m-metadata-file GNPS_output/metadata_table/metadata_table-00000.txt --o-visualization cscs_PCoA.qzv\n 2717  qiime emperor plot\n 2718  qiime emperor plot --i-pcoa cscs_PCoA.qza --m-metadata-file GNPS_output/metadata_table/metadata_table-00000.txt --p-ignore-missing-samples --o-visualization cscs_PCoA.qzv\n 2719  qiime tools view cscs_PCoA.qzv\n 2720  qiime diversity beta --i-table GNPS_buckettable.qza  --p-metric braycurtis --o-distance-matrix braycurtis_GNPS_buckettable.qza\n 2721  qiime diversity pcoa --i-distance-matrix braycurtis_GNPS_buckettable.qza --o-pcoa braycurtis_PCoA.qza\n 2722  qiime emperor plot --i-pcoa braycurtis_PCoA.qza --m-metadata-file MappingFile_UrineSamples.txt --o-visualization braycurtis_PCoA.qzv\n 2723  qiime emperor plot --i-pcoa braycurtis_PCoA.qza --m-metadata-file GNPS_output/metadata_table/metadata_table-00000.txt --o-visualization braycurtis_PCoA.qzv\n 2724  qiime emperor plot --i-pcoa braycurtis_PCoA.qza --m-metadata-file GNPS_output/metadata_table/metadata_table-00000.txt --p-ignore-missing-samples --o-visualization braycurtis_PCoA.qzv\n 2725  qiime diversity mantel --i-dm1 cscs_distance_matrix.qza --i-dm2 braycurtis_GNPS_buckettable.qza --o-visualization mantel.qzv\n 2726  qiime diversity procrustes-analysis --i-reference braycurtis_PCoA.qza --i-other cscs_PCoA.qza --output-dir ./procrustes-out\n 2727  qiime emperor procrustes-plot --i-reference-pcoa procrustes-out/transformed_reference.qza --i-other-pcoa procrustes-out/transformed_other.qza --m-metadata-file GNPS_output/metadata_table/metadata_table-00000.txt --p-ignore-missing-samples --o-visualization procrustes-out/plot.qzv\n 2728  qiime tools view procrustes-out/plot.qzv\n 2729  ssh allardp@x2go.epgl-geneve.org -p 80\n 2730  ls -lkart\n 2731  ls -lart\n 2732  qiime diversity\n 2733  qiime diversity beta-rarefaction\n 2734  ls\n 2735  qiime tools view cscs_PCoA.qza\n 2736  qiime tools view cscs_PCoA.qzv\n 2737  qiime tools view procrustes-out/plot.qzv\n 2738* ls\n 2739* rsync -rvz -e 'ssh -p 80' --progress ./*.mp4 allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/\n 2740* htop\n 2741* rsync -rvz -e 'ssh -p 80' --progress ./*.mp4 allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/\n\n\n\n\n ###################################################################################\n ###################################################################################\n# Clean Recipee PFproject\n ###################################################################################\n ###################################################################################\n\n\nWe need three inputs\n1 - a feature table\n2 - a edges table\n3 - a metadata table\n\nSee qiime2 website for specification of the files. <https://docs.qiime2.org/2020.2/tutorials/metadata/>\n\n\nAfter installing enter the dedicated env\n\nsource activate qiime2-2020.2\n\n\nOn x2go you might need to resolve your issue by exporting the\nfollowing environment variables:\n\n    export LC_ALL=C.UTF-8\n    export LANG=C.UTF-8\n\n## Convert your mass spectral feature table to the .qza format\n\nFirst, convert the .tsv feature table (GNPS_buckettable.tsv) to a .biom feature table (GNPS_buckettable.biom):\n\n`biom convert -i PF_selected_feature_table.tsv -o PF_selected_feature_table.biom --table-type=\"OTU table\" --to-hdf5`\n\nThen convert the .biom feature table (GNPS_buckettable.biom) to a .qza feature table (GNPS_buckettable.qza):\n\n`qiime tools import --type 'FeatureTable[Frequency]' --input-path PF_selected_feature_table.biom --output-path PF_selected_feature_table.qza`\n\n## Compute the chemical structural and compositional dissimilarity metric for all pairs of samples in your feature table\n\nTo compute the chemical structural and compositional dissimilarity metric for all pairs of samples in your feature table type:\n\nNote : here we had an extra columns in the tsv so we can drop it directly form the command line \nby \ncut --complement -f 1 PF_selected_edeges.tsv > PF_selected_edeges_ready.tsv\n\n\n`nohup time qiime cscs cscs --p-css-edges PF_selected_edeges.tsv --i-features PF_selected_feature_table.qza --p-cosine-threshold 0.7 --p-normalization --p-cpus 40 --o-distance-matrix cscs_distance_matrix.qza`\n\n\n## Update on Dec 2020\n\nMessing around with qiime but keeping the recipe\n\n### Feature table creation \n\n`biom convert \\-i /Users/pma/Dropbox/Research_UNIGE/git_repos/pf_project/data/output/PF_selected_feature_table.tsv  -o PF_selected_feature_table.biom --table-type=\"OTU table\" --to-hdf5`\n\n### if you need to go from biom to tsv \n\nbiom convert -i table.biom -o table.from_biom.txt --to-tsv\n\n\n### Conversion to qiime featureTable\n\nqiime tools import --type 'FeatureTable[Frequency]' --input-path PF_selected_feature_table.biom --output-path PF_selected_feature_table.qza\n\n### Summarizing \nqiime feature-table summarize \\\n--i-table PF_selected_feature_table.qza \\\n--o-visualization table_summarized.qzv\n\n### and having a look at the results\n\nqiime tools view table_summarized.qzv\n\n### Now we'll filter for features present in too many samples\n\nqiime feature-table filter-features \\\n  --i-table PF_selected_feature_table.qza \\\n  --p-max-frequency 500 \\\n  --o-filtered-table feature-frequency-filtered-table.qza\n\n### In fact here e would rather like a contingency filtered table \n\n\nqiime feature-table filter-features \\\n  --i-table PF_selected_feature_table.qza \\\n  --p-max-samples 500 \\\n  --o-filtered-table sample-contingency-filtered-table.qza\n\n  \n## lets try to make a heatmap out of the previous filtered table\n\nqiime feature-table heatmap \\\n--i-table sample-contingency-filtered-table.qza \\\n--o-visualization heatmap.qzv\n\n## lets work on phylogeny import\n\nqiime tools import \\\n  --input-path pf_collec_newick.tre \\\n  --output-path pf_collec_newick.qza \\\n  --type 'Phylogeny[Unrooted]'\n\n\n# Lets add some metadata for the feature table viz\n\nqiime feature-table summarize \\\n  --i-table PF_selected_feature_table.qza \\\n  --o-visualization table.qzv \\\n  --m-sample-metadata-file pf_metatable_qiimed.tsv\n\n\n# alpha rarefaction\n\nqiime diversity alpha-rarefaction \\\n  --i-table PF_selected_feature_table.qza \\\n  --i-phylogeny pf_collec_newick.qza \\\n  --p-max-depth 4000 \\\n  --m-metadata-file pf_metatable_qiimed.tsv \\\n  --o-visualization alpha-rarefaction.qzv\n\n\n##metadata viz\n\nqiime metadata tabulate \\\n  --m-input-file pf_collec_newick_rooted.qza \\\n  --o-visualization tabulated-feature-metadata.qzv\n\n\n\n  ## EMPRESS\n\n  \necometabo_toyset qiime empress community-plot \\\n  --i-tree phylogeny.qza \\\n  --i-feature-table feature_table.qza \\\n  --m-sample-metadata-file feature_metadata.tsv \\\n  --m-feature-metadata-file feature_taxa.tsv \\\n  --o-visualization empress-tree2.qzv \\\n  --p-filter-missing-features \\\n  --p-ignore-missing-samples\n\n\n\n## QEMISTREE\n\nbiom convert -i mzmine_local_quant_formatted.tsv  -o mzmine_local_feature_table.biom --table-type=\"OTU table\" --to-hdf5\n\nqiime tools import --input-path mzmine_local_feature_table.biom --output-path feature-table.qza --type \"FeatureTable[Frequency]\"\n\nqiime tools import --input-path sirius_local.mgf --output-path sirius.mgf.qza --type MassSpectrometryFeatures\n\nqiime qemistree compute-fragmentation-trees --p-sirius-path 'sirius-osx64-headless-4.0.1/bin/' \\\n  --i-features sirius.mgf.qza \\\n  --p-ppm-max 15 \\\n  --p-profile orbitrap \\\n  --p-ionization-mode positive \\\n  --p-java-flags \"-Djava.io.tmpdir=~/tmp/ -Xms16G -Xmx32G\" \\\n  --o-fragmentation-trees fragmentation_trees.qza\n\n  qiime qemistree rerank-molecular-formulas --p-sirius-path 'sirius-osx64-headless-4.0.1/bin/' \\\n  --i-features sirius.mgf.qza \\\n  --i-fragmentation-trees fragmentation_trees.qza \\\n  --p-zodiac-threshold 0.95 \\\n  --p-java-flags \"-Djava.io.tmpdir=~/tmp/ -Xms16G -Xmx32G\" \\\n  --o-molecular-formulas molecular_formulas.qza\n  \nqiime qemistree predict-fingerprints --p-sirius-path 'sirius-osx64-headless-4.0.1/bin/' \\\n  --i-molecular-formulas molecular_formulas.qza \\\n  --p-ppm-max 20 \\\n  --p-java-flags \"-Djava.io.tmpdir=~/tmp/ -Xms16G -Xmx32G\" \\\n  --o-predicted-fingerprints fingerprints.qza\n\nqiime qemistree make-hierarchy \\\n  --i-csi-results fingerprints.qza \\\n  --i-feature-tables feature-table.qza \\\n  --o-tree qemistree.qza \\\n  --o-feature-table feature-table-hashed.qza \\\n  --o-feature-data feature-data.qza\n\nqiime qemistree get-classyfire-taxonomy \\\n  --i-feature-data feature-data.qza \\\n  --o-classified-feature-data classified-merged-feature-data.qza\n\n\nqiime empress community-plot \\\n    --i-tree qemistree-tree.qza \\\n    --i-feature-table feature-table-hashed.qza \\\n    --m-sample-metadata-file sample-metadata.tsv \\\n    --m-feature-metadata-file feature-data.qza \\\n    --o-visualization empress-tree.qzv\n\n","n":0.029}}},{"i":103,"$":{"0":{"v":"Pf","n":1},"1":{"v":"\nTuesday 16 March 2021\n\nRecipee for the PF MN CSCS calculations\n\nFirst it appears that conda is not present\n\nThis https://askubuntu.com/a/1062621 solved the problem\nexport PATH=~/anaconda3/bin:$PATH\n\n\nNeed to reinstall the latest qiime version sudo wget https://data.qiime2.org/distro/core/qiime2-2021.2-py36-linux-conda.yml\n\nsource activate qiime2-2021.2\n\nwget / curl not working (proxy reason most likely on x2go)\n\n\nWe use the peak_list_formatter_cscs.py to get GNPS job and propelry format the quantification tables\n\n`biom convert -i for_biom.tsv -o for_biom.biom --table-type=\"OTU table\" --to-hdf5`\n\n\n\nThen convert the .biom feature table to a .qza feature table :\n\n`qiime tools import --type 'FeatureTable[Frequency]' --input-path for_biom.biom --output-path feature_table.qza`\n\nTo compute the chemical structural and compositional dissimilarity metric for all pairs of samples in your feature table type:\n\n`nohup time qiime cscs cscs --p-css-edges networkedges_selfloop --i-features quantification_table --p-cosine-threshold 0.7 --p-normalization --p-cpus 40 --o-distance-matrix cscs_distance_matrix.qza`\n\n'time qiime cscs cscs --p-css-edges networkedges_selfloop/31a1340378cd46d7b9f5ebf8afbb2565..selfloop --i-features feature_table.qza --p-cosine-threshold 0.7 --p-normalization --p-cpus 40 --o-distance-matrix cscs_distance_matrix.qza'\n\n\n'nohup bash -c 'time qiime cscs cscs --p-css-edges networkedges_selfloop/31a1340378cd46d7b9f5ebf8afbb2565..selfloop --i-features feature_table.qza --p-cosine-threshold 0.7 --p-normalization --p-cpus 40 --o-distance-matrix cscs_distance_matrix.qza''\n\n\n'nohup bash -c 'time qiime cscs cscs --p-css-edges networkedges_selfloop/31a1340378cd46d7b9f5ebf8afbb2565..selfloop --i-features feature_table.qza --p-cosine-threshold 0.7 --p-normalization --p-no-weighted --p-cpus 40 --o-distance-matrix cscs_distance_matrix_unweighed.qza''\n\nnohup bash -c 'time qiime cscs cscs --p-css-edges networkedges_selfloop/3466497461974198a9ab8c9463d05b53..selfloop --i-features feature_table.qza --p-cosine-threshold 0.7 --p-normalization --p-no-weighted --p-cpus 40 --o-distance-matrix cscs_distance_matrix_unweighed.qza'\n\nnohup bash -c 'time qiime cscs cscs --p-css-edges networkedges_selfloop/3466497461974198a9ab8c9463d05b53..selfloop --i-features feature_table.qza --p-cosine-threshold 0.7 --p-normalization --p-cpus 40 --o-distance-matrix cscs_distance_matrix.qza'\n\n\nVisualize the chemical structural and compositional dissimilarity in interactive PCoA space\nTo create PCos from the chemical structural and compositional dissimilarity matrix type:\n\n`qiime diversity pcoa --i-distance-matrix cscs_distance_matrix.qza --o-pcoa cscs_PCoA.qza`\n\nTo create an interactive ordination plot of the above created PCoA with integrated sample metadata, prepare a metadata file. You can find a metadata file for this example dataset within the Example folder. Make sure that the Sample IDs provided in the metadata file correspond to the Sample IDs in your distance_matrix.qza file. Then type:\n\nUploading previously generated metadata\nrsync -rvz -e 'ssh' --progress ./PF_metadata_qiime.tsv allardp@x2go.epgl-geneve.org:\n\n`qiime emperor plot --i-pcoa cscs_PCoA.qza --m-metadata-file PF_metadata_qiime.tsv --o-visualization cscs_PCoA.qzv`\n\nTo visualize the interactive PCoA type:\n\n`qiime tools view cscs_PCoA.qzv`\n\n\n  --p-normalization / --p-no-normalization\n                         Perform Total Ion Current Normalization (TIC) on the\n                         feature table                         [default: True]\n  --p-weighted / --p-no-weighted\n                         Weight CSCS by feature intensity      [default: True]\n\n\n## Qemistree dataset\n\nhttps://gnps.ucsd.edu/ProteoSAFe/status.jsp?task=044e981ff0d84246ae5c91ef3db643a8\n\n\n## Update\n\nMonday 29 November 2021\n\nReiterating qiime-cscs calculations for the MEMO paper.\nInstalling qiime on the beast cluster\n\nWhen trying to install using the latest qiime version (qiime2-2021.11) the qiime2-cscs plugin (https://github.com/madeleineernst/q2-cscs) doesn't appears\nI thus switch back to qiime2-2021.2\n\nI used this script to fetch and format data from switch https://github.com/mandelbrot-project/qiime-empress-formatter/blob/main/src/python/peak_list_formatter_cscs_memo.py\n\nFrom now restarting with the recipee above (will modify or update when needed)\n\nWe then convert using biom \n\n(Note that BIOM needs to be installed in an env with conda > 3.8)\n\n`biom convert -i feature_table_for_biom.tsv -o biom_feature_table.biom --table-type=\"OTU table\" --to-hdf5`\n\nI get a \n\n'biom.exception.TableException: Duplicate observation IDs'\n\nApparently this error came from the fact that the feature-id were kept as index but not exported in the tsv table.\nMake sure they are.\n\nI then activate the qiime2-2021.2 env\n\n`qiime tools import --type 'FeatureTable[Frequency]' --input-path biom_feature_table.biom --output-path feature_table.qza`\n\nWe now launch the command and explicitly specify all options\n\n`nohup bash -c 'time qiime cscs cscs --p-css-edges networkedges_selfloop/31a1340378cd46d7b9f5ebf8afbb2565..selfloop --i-features feature_table.qza --p-cosine-threshold 0.7 --p-normalization --p-weighted --p-cpus 40 --o-distance-matrix pf_gnps3_cscs_distance_matrix_weighted.qza'`\n\n\n`nohup bash -c 'time qiime cscs cscs --p-css-edges networkedges_selfloop/31a1340378cd46d7b9f5ebf8afbb2565..selfloop --i-features feature_table.qza --p-cosine-threshold 0.7 --p-normalization --p-no-weighted --p-cpus 40 --o-distance-matrix pf_gnps3_cscs_distance_matrix_unweighted.qza'`\n\nHere I get an error \n\n\n```\nPlugin error from cscs:\n\n  'function' object has no attribute 'ids'\n\nDebug info has been saved to /tmp/qiime2-q2cli-err-d8fmgz9a.log\n\nreal    0m23.731s\nuser    0m8.089s\nsys     0m3.754s\n\n```\n\n\n\nAnd this changed the file \n\nnano ./anaconda3/envs/qiime2-2021.2/lib/python3.6/site-packages/q2_cscs/q2_cscs.py\n\nby adding () to pa\n\n    if normalization:\n        features = features.norm(axis='sample', inplace=False)\n    if weighted == False:\n        features = features.pa()\n\n\nTo get the tsv \n\nThe resulting qza artifacts can then be renamed to .zip and extracted to fetch the corresponding distance matrix in tsv format.\n\nqiime diversity pcoa --i-distance-matrix qeemistree_set_cscs_distance_matrix_norm_weighted.qza --o-pcoa PCOA_qeemistree_set_cscs_distance_matrix_norm_weighted.qza\n\n\nqiime emperor plot --i-pcoa PCOA_qeemistree_set_cscs_distance_matrix_norm_weighted.qza --m-metadata-file metadata_table/metadata_table-00000.tsv --p-ignore-missing-samples --o-visualization PCOA_qeemistree_set_cscs_distance_matrix_norm_weighted_viz.qzv\n\nqiime emperor plot --i-pcoa PCOA_qeemistree_set_cscs_distance_matrix_norm_unweighted.qza --m-metadata-file metadata_table-00000.tsv --p-ignore-missing-samples --o-visualization PCOA_qeemistree_set_cscs_distance_matrix_norm_unweighted_viz.qzv\n\nqiime emperor plot --i-pcoa PCOA_qeemistree_set_cscs_distance_matrix_nonorm_weighted.qza --m-metadata-file metadata_table-00000.tsv --p-ignore-missing-samples --o-visualization PCOA_qeemistree_set_cscs_distance_matrix_nonorm_weighted_viz.qzv\n\nqiime emperor plot --i-pcoa PCOA_qeemistree_set_cscs_distance_matrix_nonorm_unweighted.qza --m-metadata-file metadata_table-00000.tsv --p-ignore-missing-samples --o-visualization PCOA_qeemistree_set_cscs_distance_matrix_nonorm_unweighted_viz.qzv\n","n":0.04}}},{"i":104,"$":{"0":{"v":"Mol2name","n":1},"1":{"v":"\nhttp://infochim.u-strasbg.fr/webserv/marvin/help/calculations/s2n.html\n\n## Individual molecules\n\nYou can name molecules by using the Naming menu entry of Tools menu in MarvinView, or Structure > Structure to Name > Generate Name in MarvinSketch.\nIn MarvinSketch, the name can be added to the canvas by using the Structure to Name > Place IUPAC Name entry in the Structure menu. The name will be displayed below the molecule, and updated in real-time when the molecule is modified.\n\n## Batch naming\n\nNaming of a large number of molecules contained in a file can be achieved in two ways: with MarvinView, and on the command line, with molconvert. In both cases, all formats supported by Marvin are acceptable as input.\nWith MarvinView, open the file containing the structures to be names. Then select the menu File/Save As, and choose \"IUPAC Name files\" in the \"Files of type\" drop-down box. Choose a name for the file, and click on the Save button. The file will contain the names of the structures, one per line.\n\nAlternatively, on the command line, you can use the following command:\n\n`molconvert name inputs.mol -o names.txt`\n\nThe file names.txt will contain the names of the molecules in the input file, with one name per line.\n\nIt is possible to use a format option to chose a nomenclature style:\n\ni (default) uses the IUPAC rules for preferred names;\nt uses a more traditional style.\n\nFor instance, to generate traditional names, use the following:\n\n`molconvert name:t inputs.mol -o names.txt`\n\nGenerate all common names for a structure:\n\n`molconvert \"name:common,all\" -s tylenol`\n\nGenerate the most popular common name for a structure (It fails if none is known.):\n\n`molconvert name:common -s viagra`\n\nAdding names as an additional field to a SDfile can be achieved with the cxcalc tool.\n\n`cxcalc -S name input.sdf -o named.sdf`\n\n## API\n\nFor information about how names can be generated from Java programs, see the developer documentation.\n\n## References\n\nIUPAC Provisional Recommendations for the Nomenclature of Organic Chemistry\n\n\n","n":0.058}}},{"i":105,"$":{"0":{"v":"Isfrag","n":1},"1":{"v":"\nPasting an old recipee from ZettelKasten\n\n\n\nLinked to [[202002251433]] in silico fragmentation worflow.\n\nChildren workflow on the beast MAPP \n\n\nSide notes : try to write everything as scripts so that they can be launched without a GUI (ex on X2Go or directly Boabab).\n\n\n# Tutorial for NPatlas in silico fragmentation data treatment\n\n\n## Prior to fragmentation \n\n### Prepare space delimited input file\n\nComplete metadate file is converted to list of Unique ID and smiles space separated (for cfm id input)\n\npython frag_list_preparator.py ../npatlas_data/np_atlas_2019_12.tsv ../npatlas_data/np_atlas_2019_12_for_frag.tsv NPAID SMILES\n\npython frag_list_preparator.py ../open_np_db_data/open_NP_db.tsv ../open_np_db_data/open_NP_db_tofrag.txt shortinchikey shortinchikey smiles\n\n### Split the file\n\n(Works on Linux based shells)\n\nsplit -a 5 -l 500 -d ../open_np_db_data/open_NP_db_tofrag.txt ../open_np_db_data/opennpdb_tofrag/opennpdb_\nsplit -a 5 -l 500 -d ./lotus_data/lotus_data_for_frag.txt ./lotus_data/lotus_data_for_frag/lotus_data_\n\nsplit -a 5 -l 500 -d ./ ./lotus_data/lotus_data_for_frag/lotus_data_\nsplit -a 5 -l 500 -d cfm/cfm_input/platinum_tofrag.tsv cfm/cfm_input/splitted/lotus_to_frag_\n\nThis one allows to preserve extensions and is build on number of desired chunks without splitting lines\nsplit -a 5 -n l/199 -d --additional-suffix=.txt  cfm_input/sub_platinum_tofrag.tsv cfm_input/splitted/lotus_to_frag_\n\n### When using the docker cli files need to have an extension (or taken as folder ?)\n\nfor f in *; do mv \"$f\" \"$f.txt\"; done\n\nif you made a mistacke \n\nfind / -type f -name '*.txt' -exec sh -c 'mv -- \"$0\" \"${0%.txt}\"' {} \\;\n\n### Prepare mutilple bash file to launch on baobab\n\n(strangely enough the .sh incrementer script return an error on Linux, runned OK on MacOS command line )\n\nNote: apparently sbatch as been replaced by srun on the boabab server side. Be sure to update the scripts accordingly\n\n\n\n## Fetching cfm-predict results\n\nDownload cfm-predict fragmentation results from the baob server using rsync command\n\nrsync -rvz -e 'ssh' --progress allardp@baobab2.unige.ch:/home/allardp/CFM_results/npatlas ./results\nrsync -rvz -e 'ssh' --progress allardp@baobab2.unige.ch:/home/allardp/CFM_results/coconut/ .\n\nfind ./ -type f -name '*.mgf' | wc  \n\n\nallows to count all file in a folder \nHere 25090 files for NPatalas\n\nCoconut 384222 .log files\n\n\n 384150 mgf files\n\n\n## We might eventually need to move all files from subfolders recursively to a superior folder\n\nfind ./bacasable -type f -print0 | xargs -0 mv -t ./bacasable\n\n\n\nfind ./results_coconut -type f -print0 | xargs -0 mv -t ./results_coconut\n\n\n## Pruning the raw log files\n\nThe output of cfm-predict consist of .log file containing mass spectra, where each fragments are individually labelled and eventually linked to a substrcture. Such information might be usefull later but for now we only want to keep the raw ms data\n\n(need to define a help function here)\n\npython raw_log_treater_npatlas.py ../npatlas_data/results_npatlas/npatlas/ .log\npython raw_log_treater.py ../coconut_data/results_coconut/ .log\n\n\n\nAt this step .log file should be pruned and contains only digits (m/z and intensities)\n\n\nfor coconut Parsing directory../coconut_data/results_coconut/ with file extension :.log\n\n'mass' ../coconut_data/results_coconut/CNP0402147.log\n'mass' ../coconut_data/results_coconut/CNP0153817.log\n'mass' ../coconut_data/results_coconut/CNP0155980.log\n'mass' ../coconut_data/results_coconut/CNP0086807.log\n'mass' ../coconut_data/results_coconut/CNP0199206.log\n'mass' ../coconut_data/results_coconut/CNP0334817.log\n'mass' ../coconut_data/results_coconut/CNP0366374.log\n'mass' ../coconut_data/results_coconut/CNP0232712.log\n'mass' ../coconut_data/results_coconut/CNP0370068.log\n'mass' ../coconut_data/results_coconut/CNP0055178.log\n'mass' ../coconut_data/results_coconut/CNP0228597.log\n'mass' ../coconut_data/results_coconut/CNP0119974.log\n'mass' ../coconut_data/results_coconut/CNP0132139.log\n'mass' ../coconut_data/results_coconut/CNP0145457.log\n'mass' ../coconut_data/results_coconut/CNP0230801.log\n'mass' ../coconut_data/results_coconut/CNP0310370.log\n'mass' ../coconut_data/results_coconut/CNP0149436.log\n'mass' ../coconut_data/results_coconut/CNP0396848.log\n'mass' ../coconut_data/results_coconut/CNP0401434.log\n'mass' ../coconut_data/results_coconut/CNP0101561.log\n'mass' ../coconut_data/results_coconut/CNP0390928.log\n'mass' ../coconut_data/results_coconut/CNP0405256.log\n'mass' ../coconut_data/results_coconut/CNP0395006.log\n'mass' ../coconut_data/results_coconut/CNP0159145.log\n'mass' ../coconut_data/results_coconut/CNP0131085.log\n'mass' ../coconut_data/results_coconut/CNP0230696.log\n'mass' ../coconut_data/results_coconut/CNP0014450.log\n'mass' ../coconut_data/results_coconut/CNP0214739.log\n'mass' ../coconut_data/results_coconut/CNP0302005.log\n'mass' ../coconut_data/results_coconut/CNP0279314.log\n'mass' ../coconut_data/results_coconut/CNP0177036.log\n'mass' ../coconut_data/results_coconut/CNP0274256.log\n'mass' ../coconut_data/results_coconut/CNP0403745.log\n'mass' ../coconut_data/results_coconut/CNP0039287.log\n'mass' ../coconut_data/results_coconut/CNP0238803.log\n'mass' ../coconut_data/results_coconut/CNP0014261.log\n'mass' ../coconut_data/results_coconut/CNP0077076.log\n'mass' ../coconut_data/results_coconut/CNP0125300.log\n'mass' ../coconut_data/results_coconut/CNP0228582.log\n'mass' ../coconut_data/results_coconut/CNP0393136.log\n'mass' ../coconut_data/results_coconut/CNP0338003.log\n'mass' ../coconut_data/results_coconut/CNP0070182.log\n'mass' ../coconut_data/results_coconut/CNP0230961.log\n'mass' ../coconut_data/results_coconut/CNP0001326.log\n'mass' ../coconut_data/results_coconut/CNP0088652.log\n'mass' ../coconut_data/results_coconut/CNP0045797.log\n'mass' ../coconut_data/results_coconut/CNP0175458.log\n'mass' ../coconut_data/results_coconut/CNP0300969.log\n'mass' ../coconut_data/results_coconut/CNP0030335.log\n'mass' ../coconut_data/results_coconut/CNP0126194.log\n'mass' ../coconut_data/results_coconut/CNP0334816.log\n'mass' ../coconut_data/results_coconut/CNP0290616.log\n'mass' ../coconut_data/results_coconut/CNP0386127.log\n'mass' ../coconut_data/results_coconut/CNP0406328.log\n'mass' ../coconut_data/results_coconut/CNP0127289.log\n'mass' ../coconut_data/results_coconut/CNP0032755.log\n'mass' ../coconut_data/results_coconut/CNP0258640.log\n'mass' ../coconut_data/results_coconut/CNP0199475.log\n'mass' ../coconut_data/results_coconut/CNP0350989.log\n'mass' ../coconut_data/results_coconut/CNP0333350.log\n'mass' ../coconut_data/results_coconut/CNP0213544.log\n'mass' ../coconut_data/results_coconut/CNP0204567.log\n'mass' ../coconut_data/results_coconut/CNP0148525.log\n'mass' ../coconut_data/results_coconut/CNP0053639.log\n'mass' ../coconut_data/results_coconut/CNP0118368.log\n'mass' ../coconut_data/results_coconut/CNP0226584.log\n'mass' ../coconut_data/results_coconut/CNP0254221.log\n'mass' ../coconut_data/results_coconut/CNP0241364.log\n'mass' ../coconut_data/results_coconut/CNP0348684.log\n'mass' ../coconut_data/results_coconut/CNP0053255.log\n'mass' ../coconut_data/results_coconut/CNP0167909.log\n'mass' ../coconut_data/results_coconut/CNP0142603.log\nTreated 384150 files, skipped 72\n\n\n\n\n\n\n## Populating the mgf headers\n\n### Preparation of the adducted metadata table\n\nWe need to prepare and adducted dataframe containing the protonated and deprotonated masses\n\nThis script recquire rdkit so we build a environment.yml file from a dedicated conda env\n\nconda env export -n conda-env -f /path/to/environment.yml\n\nEventually you need to fetch the file from the internet (use wget )\n\nwget https://zenodo.org/record/3547718/files/COCONUT4MetFrag.csv?download=1\n\nSometimes since SMILES or INchi can yield error and since there is a MF field, the emass can be calculated directly form the MF as described here \n<https://bioinformatics.stackexchange.com/a/9273>. Noooop actually not working since the GetMass() function yield a molecular weight and not and exact mass ....\n\n\nScript table_adducter_script.py is adapted to cope with different delimiters ... beware and note that $ is mandatory to input the tab delim\n\npython table_adducter_npatlas_script.py ../npatlas_data/np_atlas_2019_12.tsv ../npatlas_data/np_atlas_2019_12_adducted.tsv\n\npython table_adducter_script.py ../coconut_data/COCONUT4MetFrag.csv ',' ../coconut_data/COCONUT4MetFrag_adducted.csv $'\\t'\n\n\n### Addition of the metadata to the individual mgf headers\n\nWe can now populate each raw mgf with its corresponding metadata. For this we use the treat_npatlas.py script\n\npython treat_npatlas.py ../npatlas_data/np_atlas_2019_12_adducted.tsv ../npatlas_data/results_npatlas/npatlas/\n\npython mgf_header_populater.py ../coconut_data/COCONUT4MetFrag_adducted.csv ../coconut_data/results_coconut/ Identifier\n\n\n\non coconut \n\nTreated 384150 files, skipped 28161.\n\n\n\n\n## Generating the final spectral file\n\nWe concatenate each documented mgf files to a single spectral mgf file.\n\nfind ./ -type f -name '*.mgf' | while read F; do cat ${F} >> ../../npatlas_ISDB_pos.mgf; done\nfind ./ -type f -name '*.mgf' | while read F; do cat ${F} >> ../../coconut_ISDB_pos.mgf; done\n\n\n## Outputting non-fragmented entries\n\nFor several reasons (charged compounds, some tautomers, structures too heavy to be fragmented in a reasonable amount of time) some entries might not have been fragmented. \n\nTo find them we will first list all correctly converted mgf\n\nfind ./ -type f -name '*.mgf' | sed 's!.*/!!' | sed 's!^!!' >  list_mgf.txt\n\n%%here eventually without the extension\n\nfind ./ -type f -name '*.mgf' | sed 's!.*/!!' | sed 's!.mgf!!' >  ../../list_mgf.txt\n\nAnd then the list is compared to the initial input using the table_comparator.py \n\npython table_comparator.py ../npatlas_data/npatlas_for_frag.txt ../npatlas_data/list_mgf.txt ../npatlas_data/unfragged_list.txt\n\n\n### check molVS for structure standardization\n\nhttps://molvs.readthedocs.io/en/latest/index.html\n","n":0.036}}},{"i":106,"$":{"0":{"v":"Beast","n":1},"1":{"v":"\n# Variant of the is fragmentation recipee on the beast\n\n![[tools.chemoinformatics.isfrag]]\n\n\nI launched too many job on the beast so at the end memory was full and all cores saturated.\nNeed to find a way to handle this.\nI killed everything using \n\nsudo pkill cfm\nsudo pkill docker\n\n\nI will now need to list all calculated spectra\n\n~/cfm/cfm_output$ ls > ../calculated_spectra.txt\n\n\nI then fetch this back \nOr rather I will set up a connection to the beast via VSCode\n\nWe use sed line to remove the extensions \n\nsed 's|.log||g' calculated_spectra.txt\n\nthe -i operator allows to do it inplace\n\nsed -i 's|.log||g' calculated_spectra.txt\n\nI upload the full platinium to the beast \nrsync -rvz -e 'ssh' --progress ./platinum.tsv.gz allardpm@biolpc045600:/home/allardpm/cfm/\n\nI run the \nfrag_list_preparator_nb.py\n\ngzip -d  sub_platinum_tofrag.tsv.gz\n\n\n\n#####\n\nmessing around with gnu parralel\n\nparallel -a names.txt echo\nhttps://blog.ronin.cloud/gnu-parallel/\n\n\n\nmv argument list too long \n\nfind . -name . -o -type d -prune -o \\\n       -name '*.jpg' -o -name '*.png' -o -name '*.bmp' -o \\\n       -exec mv -t targetdir/ {} +\n\nfind Programs/cfm-id-code/cfm/bin/cfm_output/ \\\n       -name '*.log' -o \\\n       -exec mv -t cfm/cfm_output/ {} +\n\n\nfind ./cfm_output -name '*.log' -exec mv {} . \\;\n","n":0.077}}},{"i":107,"$":{"0":{"v":"Bibliography","n":1}}},{"i":108,"$":{"0":{"v":"Inciteful","n":1},"1":{"v":"\n\n\nInciteful.xyz\n","n":1}}},{"i":109,"$":{"0":{"v":"Datawarrior","n":1},"1":{"v":"\n(sublime ZK imported)\n\n# idea_datawarrior\ntags = #database #datawarrior #bibliography o\n\nAdd bibliographic reference to each compounds using the google scholar patents links functionality of DataWarrior.\n\nIt looks like an automatic query of the SMILES string can be done.\nExample \n\nhttps://patents.google.com/?q=SMILES%3dO%3dC1(OC2(C(C4(CCCCN3(C4(C(C2(C1C))CC3))))CC))&patents=false&scholar&oq=SMILES%3dO%3dC1(OC2(C(C4(CCCCN3(C4(C(C2(C1C))CC3))))CC))\n\n# directly fetches results and download them as csv file\nhttps://patents.google.com/xhr/query?url=q%3DSMILES%253dO%253dC1(OC2(C(C4(CCCCN3(C4(C(C2(C1C))CC3))))CC))%26patents%3Dfalse%26scholar%26oq%3DSMILES%253dO%253dC1(OC2(C(C4(CCCCN3(C4(C(C2(C1C))CC3))))CC))&exp=&download=concepts\n\n\n# actually it goes even further as on can add terms to filter the query.\nHere for example terms form the European Patent Office corresponding to Medicinal preparations of undetermined constitution containing material from algae, lichens, fungi or plants, or derivatives thereof, e.g. traditional herbal medicines (A61K36/00) https://worldwide.espacenet.com/classification#!/CPC=A61K36/00\n\nhttps://patents.google.com/xhr/query?url=q%3DSMILES%253dO(C3(%253dC1(C(NC2(%253dC1C%253dCC%253dC2O))%253dC(C%253dC)N%253dC3)))C%26q%3DA61K%26patents%3Dfalse%26scholar%26sort%3Dold&exp=&download=concepts\n\nNote that the %3D character can pe passed to = for more readibility\n\n<https://patents.google.com/xhr/query?url=q=SMILES%253dO(C3(%253dC1(C(NC2(%253dC1C%253dCC%253dC2O))%253dC(C%253dC)N%253dC3)))C%26q=A61K36/00%26patents=false%26scholar%26sort=old&exp=&download=concepts>\n\n\nNote that a scrapper as been written to download all associated pdfs\n\nhttps://github.com/wenyalintw/Google-Patents-Scraper\n\nhttps://patents.google.com/xhr/query?url=q=SMILES%253dO(C3(%253dC1(C(NC2(%253dC1C%253dCC%253dC2O))%253dC(C%253dC)N%253dC3)))C%26q=A61K36/00%26patents=false%26scholar%26sort=old\n","n":0.094}}},{"i":110,"$":{"0":{"v":"Argumentation","n":1},"1":{"v":"\nCheck an investigate about Argdown\nhttps://github.com/christianvoigt/argdown, a VSCode plugin to create md formated [argument maps](https://en.wikipedia.org/wiki/Argument_map)\n\nCheck also the associated research of the group http://debatelab.philosophie.kit.edu/\n\n\nNote : observed conflicts with dendron plgions\n","n":0.189}}},{"i":111,"$":{"0":{"v":"Todo Archived","n":0.707},"1":{"v":"\n# TODO\n\n2021-01-17 14:49\n\n- [ ] finalize the matchms based ISDB spectral matching script [[#doing|tag.doing]]\nWork in progress over here https://github.com/mandelbrot-project/spectral_lib_matcher\n\n\n2021-01-10 21:45\n\n- [ ] build an automated pipeline for \"classical\" metabolomics data treatment nothing fancy, just automatize the typical steps:\n\n    - [ ] spectral files conversion This should help https://github.com/compomics/ThermoRawFileParser\n    - [ ] mzmine Some stuff here \n    - [ ] mn generation\n    - [ ] annotation\n    - [ ] report generation\n\n2021-01-10 20:54 \n- [ ] See how to organize todos in dendron [[#doing|doing]]\n- [ ] Pass ZK notes from Sublime to dendron [[#doing|doing]]\n\n\n# DONE\n\n2021-01-12 21:28\n\n- [x] ~~add anki phyto decks~~ https://ankiweb.net/shared/info/594735105\n\n\n2021-01-10 22:10\n\n- [x] ~~check for automatic md formatting as striketru insted of just checked~~ added the ctrl + shift + t shortcut to strikethrough efficiently\n    - [x] ~~like this~~\n    - [x] rather than just this \n\n- [x] ~~Check and explore tags / backlinks system in Dendron (put this there [[tools.tags]]).~~ See [[tools.tags]]\n","n":0.081}}},{"i":112,"$":{"0":{"v":"Sandbox","n":1}}},{"i":113,"$":{"0":{"v":"Sand","n":1},"1":{"v":"\n# Testing links to stuff vscode cant open directly\n\nSee https://wiki.dendron.so/notes/3472226a-ff3c-432d-bf5d-10926f39f6c2.html#other-links\n\n[pdf]('/Users/pma/Dropbox/Papers/ABS_Nagoya/UEBT-CentralAmerica-Factsheet-final-nov+2018.pdf')\n\n\n[pdf2]('~/Dropbox/Papers/ABS_Nagoya/UEBT-CentralAmerica-Factsheet-final-nov+2018.pdf')\n\nNote: so you should higlight the link without quotes, then cmd+shift+P Dendron Open Link\n\n\n# Cross-vault links\n\nhttps://wiki.dendron.so/notes/3472226a-ff3c-432d-bf5d-10926f39f6c2.html#other-links\n\nI dont know if this doc is outdated but it looks like I am not required to prefix any of my links to references across vaults.\n\nSee a link to dendron-ws-private note [[tools.chemoinformatics.mol2name]]\n\nActually this one is now a public note.\nLets try to a private note \n\n[[private.people.wim-hordijk]]\n\nsss\n\n\n![[private.people.wim-hordijk]]\n\n![[dendron://mapp-dws-private/private.people.wim-hordijk]]\n\n![[dendron://mapp-dws-private/vault/private.people.wim-hordijk]]\n\n\n## further test with cross links for references\n\n<!-- ![[project.commons-public.wikidata.mibig]]\n\n![[dendron://commons-dws-public/project.commons-public.wikidata.mibig]] -->\n","n":0.113}}},{"i":114,"$":{"0":{"v":"Readlist","n":1}}},{"i":115,"$":{"0":{"v":"Web Articles","n":0.707},"1":{"v":"\n\nThursday 07 October 2021\n\n# Le Macroscope : vers une vision globale, de Joël de Rosnay\n\nhttps://www.persee.fr/doc/colan_0336-1500_1976_num_29_1_4283\nhttps://iphylo.blogspot.com/2021/10/reflections-on-macroscope-tool-for-21st.html\n\n\n\nJeudi 19 Août 2021\n\nMatthew Walker on SLEEP \n\nTuesday 11 May 2021\n\n# The chemist of evolution\n\n- [x] \nOtto Gottlieb associated the structural complexity of substances with the development plants and their environment\n\nhttps://revistapesquisa.fapesp.br/en/the-chemist-of-evolution/\n\n\n2021.04.21\n\n# Dining Philosophers problem\n- [ ] \n\nhttps://en.wikipedia.org/wiki/Dining_philosophers_problem\n\n# COMPASS Pathways Is Trying to Patent Psilocybin for More Mental Health Conditions Than You Can Name\n- [ ] \n\nhttps://www.psymposia.com/magazine/compass-pathways-is-trying-to-patent-psilocybin-for-more-mental-health-conditions-than-you-can-name/?mc_cid=1bb7bcbd03&mc_eid=0ace6c7a40\n\n\n# Adding New Literature Sources to the Wikidata Integrator\n- [ ] \n\nhttps://cthoyt.com/2021/01/23/updating-the-wikidata-integrator.html\n\n[[#wikidata|tag.wikidata]]\n\n\n# Maps, the territory, and meta-rationality\n\n- [ ] \n\nhttps://metarationality.com/maps-and-territory?ck_subscriber_id=1121227337&utm_source=convertkit&utm_medium=email&utm_campaign=Jumping+out+of+the+system+%F0%9F%A6%98%20-%205201481\n\n[[#maps|tag.maps]]\n\n#  The Dunning–Kruger effect: you don’t know what you don’t know\n\n- [x] (didnt read, I think I knew it already)\n\nhttps://nesslabs.com/dunning-kruger-effect\n\n\n# Reflections on 2020 as an independent researcher\n\n- [ ] \n\nhttps://andymatuschak.org/2020/\n\n(reading)\n\n\n# AI in Drug Discovery 2020 - A Highly Opinionated Literature Review \n\n- [ ] \n\n\nhttps://practicalcheminformatics.blogspot.com/2021/01/ai-in-drug-discovery-2020-highly.html?m=1\n\n\n# 2021-01-14 21:52\n\n![[tools.mnemonics#prompts,1]]\n\n","n":0.087}}},{"i":116,"$":{"0":{"v":"Socialmamoth","n":1},"1":{"v":"\nTaming the Mammoth: Why You Should Stop Caring What Other People Think\n\nhttps://waitbutwhy.**com**/2014/06/taming-mammoth-let-peoples-opinions-run-life.html\n\nLinked to https://nesslabs.com/egocentric-bias\n\n","n":0.267}}},{"i":117,"$":{"0":{"v":"Papers","n":1},"1":{"v":"\n\n# Readlist of publications\n\n\nThis is a dump.\nEntries here should be sent to their respective dendron notes when treated.\n\n\n# A knowledge graph to interpret clinical proteomics data\n\n\nhttps://www.nature.com/articles/s41587-021-01145-6\n\n# Infrastructure and Population of the OpenBiodiv Biodiversity Knowledge Graph\n\nhttps://bdj.pensoft.net/article/67671/\n\n\n# Reshaping the Academic Self: Connecting Education & Open Science\n\nSunday 05 September 2021\n\nhttps://zenodo.org/record/5345573#.YTSAwDZfiDW\n\n\n\nMonday 14 June 2021\n\n# Functional biology in its natural context: A search for emergent simplicity\n\nhttps://elifesciences.org/articles/67646\n\nMonday 31 May 2021\n\n# A deep generative model enables automated structure elucidation of novel psychoactive substances\n\nhttps://chemrxiv.org/articles/preprint/A_Deep_Generative_Model_Enables_Automated_Structure_Elucidation_of_Novel_Psychoactive_Substances/14644854/1\n\n\nThursday 27 May 2021\n\n# Multiomic Big Data Analysis Challenges: Increasing Confidence in the Interpretation of Artificial Intelligence Assessments\nhttps://pubs.acs.org/doi/abs/10.1021/acs.analchem.0c04850\n\n\nTuesday 25 May 2021\n\n\n# Identifying molecules as biosignatures with assembly theory and mass spectrometry\n\nhttps://www.nature.com/articles/s41467-021-23258-x\n> \n> The search for alien life is hard because we do not know what signatures are unique to life. We show why complex molecules found in high abundance are universal biosignatures and demonstrate the first intrinsic experimentally tractable measure of molecular complexity, called the molecular assembly index (MA). To do this we calculate the complexity of several million molecules and validate that their complexity can be experimentally determined by mass spectrometry. This approach allows us to identify molecular biosignatures from a set of diverse samples from around the world, outer space, and the laboratory, demonstrating it is possible to build a life detection experiment based on MA that could be deployed to extraterrestrial locations, and used as a complexity scale to quantify constraints needed to direct prebiotically plausible processes in the laboratory. Such an approach is vital for finding life elsewhere in the universe or creating de-novo life in the lab.\n\n# Supervised topic modeling for predicting molecular substructure from mass spectrometry [version 1; peer review: awaiting peer review]\n\nhttps://f1000research.com/articles/10-403\n\n> Small-molecule metabolites are principal actors in myriad phenomena\n> across biochemistry and serve as an important source of biomarkers\n> and drug candidates. Given a sample of unknown composition,\n> identifying the metabolites present is difficult given the large number\n> of small molecules both known and yet to be discovered. Even for\n> biofluids such as human blood, building reliable ways of identifying\n> biomarkers is challenging. A workhorse method for characterizing\n> individual molecules in such untargeted metabolomics studies is\n> tandem mass spectrometry (MS/MS). MS/MS spectra provide rich\n> information about chemical composition. However, structural\n> characterization from spectra corresponding to unknown molecules\n> remains a bottleneck in metabolomics. Current methods often rely on\n> matching to pre-existing databases in one form or another.  Here we\n> develop a preprocessing scheme and supervised topic modeling\n> approach to identify modular groups of spectrum fragments and\n> neutral losses corresponding to chemical substructures using labeled\n> latent Dirichlet allocation (LLDA) to map spectrum features to known\n> chemical structures. These structures appear in new unknown spectra\n> and can be predicted. We find that LLDA is an interpretable and\n> reliable method for structure prediction from MS/MS spectra.\n> Specifically, the LLDA approach has the following advantages: (a)\n> molecular topics are interpretable; (b) A practitioner can select any set\n> of chemical structure labels relevant to their problem; (c ) LLDA\n> performs well and can exceed the performance of other methods in\n> predicting substructures in novel contexts.\n\n\nTuesday 11 May 2021\n\n# Plant scientists’ research attention is skewed towards colourful, conspicuous and broadly distributed flowers\n\nhttps://www.nature.com/articles/s41477-021-00912-2\n\n\nTuesday 20 April 2021\n\n# Repository scale classification and decomposition of tandem mass spectral data\nScientific Reports volume 11, Article number: 8314 (2021) Cite this article\n\nhttps://www.nature.com/articles/s41598-021-87796-6\n\n\nMonday 29 March 2021\n\n# Capturing scientific knowledge in computable form\n\nhttps://biofactoid.org\n\nhttps://www.biorxiv.org/content/10.1101/2021.03.10.382333v1\n\n\n\n# First known gene transfer from plant to insect identified\n\nhttps://www.nature.com/articles/d41586-021-00782-w\n\n\n\nFriday 05 March 2021\n\n\n# Connecting molecular sequences to their voucher specimens\n\nhttps://biohackrxiv.org/93qf4/\n\n[[#wikidata|tag.wikidata]]\n\n\n2021-02-10 10:13\n\n# Large-scale tandem mass spectrum clustering using fast nearest neighbor searching\n\n\nhttps://www.biorxiv.org/content/10.1101/2021.02.05.429957v1\n\n[[#spectral_comparison|tag.spectral_comparison]]\n\n2021-02-09 11:45\n\n# NetLSD: Hearing the Shape of a Graph\n\nGraph comparison an analysis at large scale\n\nhttps://arxiv.org/pdf/1805.10712.pdf\n\n[[#graph|tag.graph]]\n\n\n2021-02-08 19:42\n\n# Automated assembly of a reference taxonomy for phylogenetic data synthesis\n\nThe original OTOL paper\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC5515096/\n\n[[#taxo|tag.taxo]] \n\n\n2021-02-03 16:51\n\n# Data integration enables global biodiversity synthesis\n\nhttps://www.pnas.org/content/118/6/e2018093118\n\n[[#biodiversity|tag.biodiversity]] [[#gbif|tag.gbif]]\n\n2021-01-31 20:19\n\n\n# Interoperable chemical structure search service\n\nhttps://jcheminf.biomedcentral.com/articles/10.1186/s13321-019-0367-2\n\n\n\n\n2021-01-29 19:22\n\n# Mapping the space of chemical reactions using attention-based neural networks\n\nReymond's paper on reactions based tmaps. Try this on BNICE set of react or on MetaNetX\n\nhttps://www.nature.com/articles/s42256-020-00284-w.epdf?sharing_token=CGHu6tcqBiFmC1nRfnOrxNRgN0jAjWel9jnR3ZoTv0NiJSBmQfyOiLfbwen1TgEszNU5Xao_0Gs7D0u8tLUOJxaLAUc469WZKWG5K9wsqIe98dZOREVhQ33gqcr33AgNUjnp4cVXojp4aKe2xCbWtNaxOZtpOjBOsdX3O8yxVkI%3D\n\n\n\n\n2021-01-24 17:04\n\n# Estimate Metabolite Taxonomy and Structure with a FragmentCentered Database and Fragment Network\n\n\nhttps://arxiv.org/pdf/2101.03784.pdf\n\n\n\n\n2021-01-17 09:21\n\n# Network-based strategies in metabolomics data analysis and interpretation: from molecular networking to biological interpretation\n\nhttps://www.tandfonline.com/doi/full/10.1080/14789450.2020.1766975\n\n[[networks]]\n\n\n\n\n2021-01-13 22:12\n\n# Towards a biodiversity knowledge graph\n\nhttps://riojournal.com/articles.php?journal_name=rio&id=8767\nCheck RIO in general\nDig into http://beta.briefideas.org/\n//TODO Make a nanopub and related  note\n\n\n2021-01-12 16:41\n\n# Metabolite networks filtering and explo\n\nhttps://www.biorxiv.org/content/biorxiv/early/2021/01/06/2021.01.06.425569.full.pdf\n\n\n2021-01-09 14:18\n\n# Florian Huber blog post msmsmatch tuto\nhttps://blog.esciencecenter.nl/build-your-own-mass-spectrometry-analysis-pipeline-in-python-using-matchms-part-i-d96c718c68ee\n\n\n\n2021-01-09 13:15\n\n# Chemical graph generators\nhttps://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008504\n\n\n\n\nThis resource represents an important advancement in the design and deployment of a comprehensive and collaborative natural products knowledge base.\n","n":0.037}}},{"i":118,"$":{"0":{"v":"Marchal","n":1},"1":{"v":"\nBruno Marchal\n\nLe secret de l'amibe conseillé par Jo Bonnemort en 2009\n\nhttp://iridia.ulb.ac.be/~marchal/publications.html\n\n","n":0.302}}},{"i":119,"$":{"0":{"v":"Laborit","n":1},"1":{"v":"\n\nEloge de la fuite Henri Laborit\n","n":0.408}}},{"i":120,"$":{"0":{"v":"Books","n":1},"1":{"v":"\n# Latour's prod\n\nhttp://www.bruno-latour.fr/fr/livres_volumes_edites.html\n\n\n\n# Check in Biblioteca Itinerante de Tramonte \n\nhttps://fr-fr.facebook.com/BibliotecaTramonte/\n\n\n\n# Long-Term Preservation of Digital Documents \n\nhttps://sci-hub.se/https://www.springer.com/gp/book/9783540336396\nhttp://libgen.rs/book/index.php?md5=0D4205155AD0AF24C0D84698A49C0815\n\n\n","n":0.25}}},{"i":121,"$":{"0":{"v":"Bihouix","n":1},"1":{"v":"\nLimit to growth - Rapport du club de Rome (preface Vancovicci)\n\nPhilippe Bihouix - l'age des lowtechs\nIvan Illitch - Energie et equité\n\nWednesday 17 March 2021\n\nQuelle innovation pour un monde durable?\nConférence par Philipe Bihouix, expert des ressources non renouvelables et de leurs enjeux technologiques, et auteur de L’Âge des low tech\n \nLundi 22 mars, 18h30, en ligne\nhttps://www.sdd-unige.org/lundi\n\n# Notes on the conf \n\nModérée par Fabrice Calame (Unige)\n\n\nEhrlich The population bomb\nhttps://fr.wikipedia.org/wiki/La_Bombe_P\n\nhttps://www.wikidata.org/wiki/Q377983 Q377983\n\nA bet with Simon https://en.wikipedia.org/wiki/Simon%E2%80%93Ehrlich_wager\n\nhttps://www.wikidata.org/wiki/Q562481 Q562481 William Nordhaus American economist\n\nhttps://www.wikidata.org/wiki/Q505154 Q505154 Jeremy Rifkin American economist\n\nCalcul de coin de table (Intel)\n1M de voiture autonomes = le volume d'internet mondial actuel\n\n\"La technique n'est ni bonne ni mauvaise, ni neutre, elle est ambivalente.\" Jacques Ellul\nhttps://www.wikidata.org/wiki/Q322922 Q322922 Jacques Ellul French sociologist, technology critic, and Christian anarchist\n\nAttention aux promesses du high-tech. Plutot que des solutions techniques, il faut des solutions socio-techniques. \nVers plus de frugalité. Réduction de l'impact d'internet : /100 en evitant les transferts via reseaux mobiles.\nReduction de l'obsolence. OK soyons plus frugaux, plus sobres mais ou placer cette innovation ? Techno-discernement. Ne pas numériser a outrance.\n\nInnovation organisationelle:\nImaginons que l'on souhaite passer a des bouteilles consignées : on sait laver des bouteilles ! On a la techno pour. Cela requiert plutot un effort de reorganisation.\n\nUn rapide calcul taux de croissance a 2% ca double tous les 37 ans donc en  1000 ans ca fait x 400 000 000 M\n\n\"Nous autres, pauvres mortels, avons bien du mal à nous représenter les courbes exponentielles. Le fait est que celles-ci montent vite… trop vite ! Par exemple, l’ingénieur Philippe Bihouix nous rappelle qu’avec une modeste croissance de 2%, maintenue sur 1000 ans, il faudrait multiplier par 400 million notre consommation d’énergie actuelle.\"\n\nSide notes : \n\nCompteur numérique\nhttps://www.francetvinfo.fr/replay-radio/nouveau-monde/nouveau-monde-un-compteur-de-co2-pour-mesurer-limpact-environnemental-du-numerique_4135593.html\nctrl+s http://ctrls.studio/\nhttps://www.qqf.fr/infographie/69/pollution-numerique-du-clic-au-declic\n","n":0.06}}},{"i":122,"$":{"0":{"v":"Arutam","n":1},"1":{"v":"(ZK imported)\n\nDans le numéro 57 de Les Grands Dossiers des Sciences Humaines.\n\nPage 71. Quelques bonnes piste de lectures en philosophie environnementale.\nAnalyse du courant français qui était initialement préoccupé par une articulation de la philosophie environnementale aux perspectives d'émancipation sociale (années 60 -70) et développant un critique de la modernité de la société technicienne.\n\n### \"L'école française\"\n\n* Jacques Ellul (Le personalsimen gascon) 1930\n* Bernard Charbonneau\n* André Gorz - défense de l'autonomie individuelle et de la critique du productivisme\n* Serge Moscovici\n* Edgar Morin\n* Michel Serres - Le contrat Naturel 1990\n* Bruno Latour - Travaux sur l'Anthropocène \n* Catherine et Raphaël Larrère - premiers échanges entre philosophie française et éthique environnementales anglo-saxonnes\n* Hicham-Stéphane Afeissa\n\n### \"Ailleurs dans le Monde\"\n\n* Aldo Leopold\n* Val Plumwood (1936 - 2008) - Ecofeminisme\n* Baird Callicot - (1941 - ) Thinking like a planet\n* Stephan Vogel - \"Against Nature- THe concept of Nature in critical theory\"\n* Arne Naess (1912 - 2009) - Deep ecology, Ecologie, communauté et style de vie (1989) Ecosophie\n* Holmes Rolston (1932 - ) Terre Objective\n* Anna Lowenhaupt Tsing - Le Champignon de la fin du monde (pote de Marion Neumann, Utopiana Genève)\n\n","n":0.074}}},{"i":123,"$":{"0":{"v":"Random","n":1}}},{"i":124,"$":{"0":{"v":"Bib","n":1},"1":{"v":"\nWhat happens here is that we test for a bib whithout specifying the path in the frontmatter of the md files\n\n\n@Blunt2009\n\n\n@Gerwick2012a\n\n\nAuthor: Blunt, John W and Copp, Brent R and Hu, Wan-Ping and Munro, Murray H G and Northcote, Peter T and Prinsep, Mich{\\`ele R Journal: Natural product reports Title: Marine natural products. Year: 2009\n\n@\n","n":0.136}}},{"i":125,"$":{"0":{"v":"Quotes","n":1},"1":{"v":"\n\n\n\n\t\nWordsworth, W.\nEnvoyer\n\n\t\n\nVerse > William Wordsworth > Complete Poetical Works\n\n\t  PREVIOUS\tNEXT  \t\n\nCONTENTS      BIBLIOGRAPHIC RECORD\n\n\n\"A VOLANT TRIBE OF BARDS ON EARTH ARE FOUND\"\n A VOLANT Tribe of Bards on earth are found, Who, while the flattering Zephyrs round them play, On \"coignes of vantage\" hang their nests of clay; How quickly from that aery hold unbound, Dust for oblivion! To the solid ground Of nature trusts the Mind that builds for aye; Convinced that there, there only, she can lay Secure foundations. As the year runs round, Apart she toils within the chosen ring; While the stars shine, or while day's purple eye 10 Is gently closing with the flowers of spring; Where even the motion of an Angel's wing Would interrupt the intense tranquillity Of silent hills, and more than silent sky. 1823. \n\n\n\n\n","n":0.087}}},{"i":126,"$":{"0":{"v":"Questions","n":1},"1":{"v":"\n\n# 2021-01-12 18:38\n- [ ]  ~~Would this type (CRAPL) of license collide with CC0 licence ? Is it possible to have multiple licence for a single object. [[garage]] [[[Garage|garage]] << trying a relative link here not sure its working !~~ Looks like the answer is yes, see at the end of this page http://matt.might.net/bio/#isformal=1&isfocus=0&isfunders=0&isbertrand=0&iscstechlit=0&iscsbackground=0&iseducation=0&issocial=0\n\n","n":0.136}}},{"i":127,"$":{"0":{"v":"Public","n":1}}},{"i":128,"$":{"0":{"v":"Note","n":1},"1":{"v":"This is a public note.\n","n":0.447}}},{"i":129,"$":{"0":{"v":"Links","n":1},"1":{"v":"\nNow, vice versa, on a public note we link : \n\n- within the public ws [[public.note]]\n- to the private repo [[private.note.random]]\n- and to an alternative dws [[material.consumables.gaz]]\n","n":0.192}}},{"i":130,"$":{"0":{"v":"Projects","n":1},"1":{"v":"So toin the dendron-ws-publi we also have a projects architecture.\n\nWe can for example reference to Martin Dupont' top secret project [[projects.martin-dupont]] however, this one should only be visible if you are on the dendron-ws-private or dendron-global repos or website.\nLet's see if this is the case.\n\n","n":0.149}}},{"i":131,"$":{"0":{"v":"Martin Dupont","n":0.707},"1":{"v":"\nProject of Martin Dupont is for now a sample project which is top secret.\n","n":0.267}}},{"i":132,"$":{"0":{"v":"Alberto Dupont","n":0.707},"1":{"v":"This is a even more crazy project than [[projects.martin-dupont.md]] one and it should normally not be published if the dendron.yml in dendron-global ws is set correctly. However it should normally be git versioned on the dendron-ws-private repo.\nLet's see if this is the case.\n\nSo Martin Dupont's project is crazy because he uses information that are coming from the MAPP metabolomics platform. And these are not accessible to everyone by default theay re living here [[material.consumables.gaz]].\n","n":0.116}}},{"i":133,"$":{"0":{"v":"Pledge","n":1},"1":{"v":"\n# About\n\nThis dendrite contains materials about things I am publicly committed to. It has been inspired from Daniel Mietchen's pledges (https://github.com/Daniel-Mietchen/pledges)\n\n# Pledge\n\nI pledge to observe the following principles in my knowledge-related professional and volunteering activities:\n\n1. only engage in activities where I see sufficient societal benefit;\n1. publicly document my insights into the societal benefits of activities that take up a major part of my time;\n1. take measures to minimize the likelihood that engagement in these activities is detrimental to the health, well-being and integrity of myself other living beings and our planet;\n1. encourage open participation, scrutiny and repurposing of the processes and workflows underlying my activities;\n1. release public outputs of my activities under an [open license](https://opendefinition.org/licenses/), and under the [CC0 1.0 Universal Public Domain Dedication (CC0 1.0)](https://creativecommons.org/publicdomain/zero/1.0/) if I am the sole contributor;\n1. present these principles as my starting point when negotiating collaborations with others;\n1. maintain a [list of frequently asked questions] ([[pledge.faq]]) related to activities covered by these principles;\n1. allow for exceptions, and feed data about them into future versions of these principles.\n1. review these principles at least annually and refine them as necessary.\n","n":0.074}}},{"i":134,"$":{"0":{"v":"Faq","n":1},"1":{"v":"\n# About\n\nThis file contains clarifications pertaining to questions I could be asked. If you have additional questions or need further clarifications, please let me know.\n\n# Questions\n\n## Authoring\n\n* Do I consent to drafting manuscripts by sending around email attachments?\n  - No\n* Which platforms am I willing to use for collaborative drafting?\n  - ARPHA\n  - Etherpad\n  - GitHub\n  - Google docs\n  - MediaWiki\n  - Overleaf\n\n\n## Collaboration\n\n* Am I open to collaborate \n  - with people I do not know?\n    - Sure\n  - with people from other backgrounds than mine?\n    - Sure\n  - in an online-first fashion?\n    - Sure\n\n\n## Editing\n\n* Am I available as an editor for scholarly venues?\n  - Yes, if\n    - I have sufficient expertise\n    - All publications in the venue are openly licensed \n\n\n## Events\n\n* Am I willing to \n  - attend remotely?\n    - Yes\n  - organize remotely?\n    - Yes\n  - present remotely?\n    - Yes\n\n\n## Peer review\n\n* Am I available as a peer reviewer for scholarly manuscripts?\n  - Yes, if\n    - I have sufficient expertise\n    - All publications in the venue are openly licensed \n* Am I available as a peer reviewer for scholarly grant proposals?\n  - Yes\n* Am I available as a peer reviewer for scholarly data?\n  - Yes\n* Am I available as a peer reviewer for scholarly software?\n  - Yes\n* Am I available as a peer reviewer for scholarly output management plans?\n  - Yes\n* Am I available as a peer reviewer for other outputs of scholarly workflows?\n  - Yes\n* Am I available as a peer reviewer for scholarly manuscripts?\n  - Yes\n\n\n## Publishing\n\nAs an author or co-author of scholarly manuscripts, am I willing\n  - to post the manuscripts as preprints?\n    - Yes, if\n      - they are put under an open license\n  - to pay open-access charges?\n    - Yes, if \n      - appropriate funding is available\n      - fees are reasonable\n  - to publish behind paywalls?\n    - No  \n  - to publish under non-open licenses?\n    - No  \n  - to sign copyright transfer agreements?\n    - No\n","n":0.055}}},{"i":135,"$":{"0":{"v":"Plants","n":1}}},{"i":136,"$":{"0":{"v":"Sellers","n":1},"1":{"v":"\n\nhttps://www.pma28.fr/\n","n":1}}},{"i":137,"$":{"0":{"v":"Philosophy","n":1},"1":{"v":"## Gaston Bachelard\n\nhttps://www.franceculture.fr/emissions/series/confines-avec-gaston-bachelard\n\n(listened ep1. with one ear) <<< je devrais peut-être moins écouter d'une oreille, écrire d'une main ou penser a un hemisphère d'ailleurs ...\n\nhttps://www.babelio.com/livres/Bachelard-La-poetique-de-lespace/2168\nLa _poétique de l'espace_ serait les 300 pages les plus lues et citées de Bachelard. Un condensé de sa philosophie.\n\n## Isabelle Stengers\n\nhttps://www.franceculture.fr/emissions/hors-champs/isabelle-stengers\n(listened on the 2021-01-17)\n\nOne of Bruno Latour \"master's\" Isabelle Stengers\nhttps://fr.wikipedia.org/wiki/Isabelle_Stengers\n\n### Notes\n\n* premier ouvrage \"la Nouvelle Alliance\" 1979, avec Ilya Prigogine (Nobel de Chimie) https://fr.wikipedia.org/wiki/Ilya_Prigogine [[readlist]]\n* déconstruction des schémas de la psychanalyse. A participer au livre noir de la psychanalyse\n* \"Je ne vis plus a l'époque de Bachelard ou l'on pouvait faire rimer progrès scientifique et progrès générale de l'humanité\" [[bachelard]]\n* science et résistance Gilles Deleuze. Un des premier a penser la science par la philosophie. [[deleuze]]\n* check Arthur Koestler https://fr.wikipedia.org/wiki/Arthur_Koestler \"Le somnanbules\"\n* Dans son travail avec Prigogine, la relation est intéressante. Pas de volonté d'être d'égal a égal sur le plan pour elle de la chimie et pour lui de la philosophie. Une relation de confiance s'établi donc. C'est sans doute une des clés de collaboration réussies. Pour des raison toutes simples de redondances des compétences mais aussi pour des affaires d'égos ! Attention il faut bien sur garder des espaces de recouvrement entre thématiques. Les champs d'intérêt de chaque collaborateurs doivent se fertiliser mutuellement.\n\n* à l'origine du concept **d'écologie des pratiques** : un concept spéculatif, dans le sens d'attaché a un possible et non pas a un probable (le possible ne se calcule pas, il se sent).\nCe concept fait donc le pari de relation fertiles entres \"praticiens\" (scientifiques, juristes, philosophes, artistes, ouvrier ... somme toute des \"expert dans leur domaine\"). Ces praticiens qui peuvent se placer dans des zones ou _\"ici vous ne bousculerez pas\"_ (G. Deleuze) mais pas nécessairement en termes d'autorité ou de légitimité. Il est nécessaire d'avoir une \"activation\", dans le sens chimique du terme, du praticien. Intervention sur la manière dont les praticiens se pensent eux-mêmes et se présentent aux autres de façon a ce qu'autre choses soit possible qu'une relation de rivalité, d'autorité à autorité. Que du nouveau soit possible, que de la pensée soit possible entre acteurs. Ne plus être prix entre deux feux.\n\n* Il n'y a pas de réponse sans questions. Ne l'oublions pas.\n\n> _\"Ce sont les questions qui s'articulent et non pas les réponses que l'on essaie de coordonner\"._\n\n* L'art de faire attention aux conséquences. Allez vers un nouveau type d'intelligence responsable. (link to [[collective_intelligence]])\n\n> _\"Nous les occidentaux somme devenus adultes / a notre passé et aux autres peuples qui avaient ou ont besoin de croyances comme des béquilles. Je tente de réfléchir contre certitude. Nous avons oublié que nous ne sommes pas seuls au monde._\n\n\n* grande admiratrice de Whitehead (https://fr.wikipedia.org/wiki/Alfred_North_Whitehead), auteur de Principia Mathematica [[readlist]]\n\n> _\"The object of the following Chapters is not to teach mathematics, but to enable students from the very beginning of their course to know what the science is about, and why it is necessarily the foundation of exact thought as applied to natural phenomena.\"_\n>\n> -- A. N. Whithehead & B. Russell \n\n\n\n\n## B. Latour\n\nHistorien des science et sociologue \"je ne suis pas un philosophe\"\n\nhttps://www.franceculture.fr/emissions/les-chemins-de-la-philosophie/profession-philosophe-4074-bruno-latour-philosophe-des-modes-dexistence (listened on the 2021-01-17)\n\n### Notes \n\n* recherche sur les différents \"modes\" de vérité (scientifique, politique, technique, philosophique)\n* travail vers la non-hégémonie d'un des modes / aux autres \n* les cahiers de doléances\n* recupération des concepts de Gaia de Lovelock\n","n":0.043}}},{"i":138,"$":{"0":{"v":"Metabolomics","n":1}}},{"i":139,"$":{"0":{"v":"Ressources","n":1},"1":{"v":"\n(once pasted on the MARS slack channel)\n\nMetabolomics Databases (Met Soc) http://metabolomicssociety.org/resources/metabolomics-databases (edited) \n\nMoteur de recherche Google pour la recherche de datasets https://toolbox.google.com/datasetsearch (edited) \n\nExample avec les mots clés \"arabidopis mass spectrometry\" https://toolbox.google.com/datasetsearch/search?query=arabidopsis%20mass%20spectrometry&docid=gObMnqKKWSkjxWOeAAAAAA%3D%3D\n\nMoteur de recherche OmicsDI de datasets (focus métabo, comme l'indique le nom) https://www.omicsdi.org\n\nhttps://www.ebi.ac.uk/\n\nhttps://bio.tools/\n\nhttps://www.ms-utils.org/\n\n\n","n":0.151}}},{"i":140,"$":{"0":{"v":"Mathematics","n":1}}},{"i":141,"$":{"0":{"v":"Grothendieck","n":1},"1":{"v":"\n\n# Alexandre Grothendieck : un mathématicien qui prit la tangente\n\n2021-02-10 16:04\n\nListened this morning to \n\nhttps://www.franceculture.fr/emissions/les-nuits-de-france-culture/la-conversation-scientifique-alexandre-grothendieck-un-mathematicien-qui-prit-la-tangente-1ere\n\nhttps://fr.wikipedia.org/wiki/Alexandre_Grothendieck\n\n\nGénie de la géométrie algébrique.\nParticipe a survivre et vivre, mouvement d'écologie radicale.\nMauvais en calcul. \nExpulsé du Collége de France en 72, prends sa retraite en 91 et laisse plus de 20000 pages de notes qui restent a decrypter.\n\nImpossible pour ma pauvre personne de penser entendre grand chose de son oeuvre mathématique (Cedric Villani indique qu'il lui faudrait 5 a 6 ans de travail assidu pour entrer dans les mathématiques de Grothendieck ...) je suis néanmoins intéressé par lire les partie de  son oeuvre qui me serait peut être plus accessibles.\n\nS'est posé des questions sur la pertinence de la continuité de la recherche scientifique ayant pris conscience de la gravité de la crise écologique.\n\nhttps://archive.org/details/AlexandreGrothendieck-UneVieDigneDtreVcue (a écouter)\n\n\nLes premières pages de la clé des songes ou Dialogue avec le bon dieu font immédiatement penser a la psychologie introspective de Paul Diel\nhttps://b-ok.cc/book/3434286/ed3320\n\n\n","n":0.081}}},{"i":142,"$":{"0":{"v":"Linux","n":1}}},{"i":143,"$":{"0":{"v":"Get System Info","n":0.577},"1":{"v":"https://vitux.com/get-linux-system-and-hardware-details-on-the-command-line/\n\n\n\nsudo lshw -short -html > sandbox/SWITCH_output_PF_GNPS_3/PF_GNPS3/beast_info.html\n","n":0.408}}},{"i":144,"$":{"0":{"v":"Delete User","n":0.707},"1":{"v":"\nhttps://www.howtogeek.com/656549/how-to-delete-a-user-on-linux-and-remove-every-trace/\n\n# change password\n\nhttps://www.lifewire.com/how-to-change-your-user-password-in-linux-4694406\n\n","n":0.577}}},{"i":145,"$":{"0":{"v":"Create User","n":0.707},"1":{"v":"# User creation on a linux server\n\n\nFollowing these instructions \n\nhttps://linuxize.com/post/how-to-create-users-in-linux-using-the-useradd-command/\n\n\n\n","n":0.316}}},{"i":146,"$":{"0":{"v":"Knowledge","n":1},"1":{"v":"$\n\n","n":1}}},{"i":147,"$":{"0":{"v":"Statistics","n":1},"1":{"v":"\n# Gradient boosting \n\nWhat's behind xgboost ?\n\nhttps://en.wikipedia.org/wiki/Gradient_boosting\nhttps://www.lovelyanalytics.com/2016/09/12/gradient-boosting-comment-ca-marche/\nhttps://www.kaggle.com/mjeulidia/exploration-random-forest-en-fran-ais\n","n":0.378}}},{"i":148,"$":{"0":{"v":"Bayesian","n":1},"1":{"v":"\n# What is the difference between frequentist and bayesian inferences ?\n\nhttps://stats.stackexchange.com/a/56\n\nHere is how I would explain the basic difference to my grandma:\n\nI have misplaced my phone somewhere in the home. I can use the phone locator on the base of the instrument to locate the phone and when I press the phone locator the phone starts beeping.\n\nProblem: Which area of my home should I search?\n\n## Frequentist Reasoning\nI can hear the phone beeping. I also have a mental model which helps me identify the area from which the sound is coming. Therefore, upon hearing the beep, I infer the area of my home I must search to locate the phone.\n\n## Bayesian Reasoning\nI can hear the phone beeping. Now, apart from a mental model which helps me identify the area from which the sound is coming from, I also know the locations where I have misplaced the phone in the past. So, I combine my inferences using the beeps and my prior information about the locations I have misplaced the phone in the past to identify an area I must search to locate the phone.\n\n\nResponse two is of interest also !\nhttps://stats.stackexchange.com/a/1602\n\n\nA Bayesian is one who, vaguely expecting a horse, and catching\na glimpse of a donkey, strongly believes he has seen a mule\n\nStephen Senn, Statistician & Bayesian Skeptic (mostly)\n\nhttps://faculty.washington.edu/kenrice/BayesIntroClassEpi2018.pdf\n\n\n# Application to Mandelbrot project\nBayesian are especially powerful for functional optimization.\nIn the frame of the mandelbrot project we could try to functionalize our drug discovery quest < this alone is a big part of the problem. \n\n- an ensemble of molecules found to be present in various amount in plants displaying a high inhibitory activity and a low cytotoxicity.\n- the more this ensemble of molecules is restricted and unique to the highly bioactive plants, the more they are the potential responsible of this bioactivity.\n- some priors could be defined: we know that scaffold X and Y usually display these activities.\n\n\n# Resources\n\n# podcasts\n\nhttps://www.learnbayesstats.com/episodes/4#showEpisodes\n\n# readlist\n\nhttps://researchoutreach.org/articles/bayesian-inference-for-21st-century-drug-development-and-approval/\n\n\nSee paper notes on Hidden Markov Models PMA8_147\n\n\n","n":0.055}}},{"i":149,"$":{"0":{"v":"Ool","n":1},"1":{"v":"\n# Origins of Life\n\nSome papers and ressources of interest on Origin of Life research\n\n/Users/pma/Dropbox/Papers/Philosophy_of_science/What-is-Life.pdf\n\n# Chemotons\n\nhttps://en.wikipedia.org/wiki/Chemoton\n\n# Jeewanu \n\nhttps://en.wikipedia.org/wiki/Jeewanu\n\n\n# Abiogenesis\nhttps://en.wikipedia.org/wiki/Abiogenesis#Primordial_origin_of_biological_molecules:_Chemistry\n\nRead the section on dissipative structures\n\n\nhttps://sci-hub.st/10.1126/science.aaw1955\n\n# Hypercycles\n\nhttps://en.wikipedia.org/wiki/Hypercycle_(chemistry)\n\n# Top down approaches \nhttps://en.wikipedia.org/wiki/Spiegelman%27s_Monster\n\n","n":0.189}}},{"i":150,"$":{"0":{"v":"Ml","n":1},"1":{"v":"\n## Neural Network Zoo\n\nhttps://www.asimovinstitute.org/neural-network-zoo/\n\n- [ ] \n\nTuesday 23 November 2021\n\n\n","n":0.316}}},{"i":151,"$":{"0":{"v":"Metabolism","n":1},"1":{"v":"\n# Metabolism\n\nWiki definition here https://fr.wikipedia.org/wiki/M%C3%A9tabolisme\nInteresting facts there\n\n","n":0.378}}},{"i":152,"$":{"0":{"v":"Distances","n":1},"1":{"v":"\n\nhttps://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa\n\n\n\n","n":1}}},{"i":153,"$":{"0":{"v":"Courses","n":1}}},{"i":154,"$":{"0":{"v":"Shiny","n":1},"1":{"v":"\n\nFollowing \n\nhttps://edu.isb-sib.ch/course/view.php?id=498\n\nSIB-shiny21 (mdp, log: ss-sib)\n\nhttps://docs.google.com/document/d/1pohr5PyiV-lTJquviSrmXaNz7Jaw-PFA-bgXJ8g0FiI/edit\n\n\n\nhttps://marionilab.cruk.cam.ac.uk/iSEE_allen/\n\nhttp://genebrowser.unige.ch/telagirdon/#query_the_atlas\n\n\n# COVID oriented shiny apps\n\nhttps://infocovid.smc.unige.ch/\n\nhttps://ibz-shiny.ethz.ch/covid-19-re-international/\n\nsee associated git \nhttps://github.com/covid-19-Re\n\n\nhttps://renkulab.shinyapps.io/COVID-19-Epidemic-Forecasting/_w_c80f7467/?tab=jhu_pred&country=Switzerland\n\n\n# deployment\n\nusing shinyproxy.io\nvia Apache\n\n## for the price app\nhttps://oolonek.shinyapps.io/price_app/\n\ncd to price_app folder\n\nlibrary(rsconnect)\ndeployApp()\n","n":0.213}}},{"i":155,"$":{"0":{"v":"Garage","n":1},"1":{"v":"\n\n![](/assets/images/2021-01-03-19-44-16.png)\n\n# Working with the garage door opened\n\nA way of working briefly described by Andy Matuschak here https://notes.andymatuschak.org/z21cgR9K3UcQ5a7yPsj2RUim3oM2TzdBByZu. If we apply this \"working with the garage door open\" idea to a scientific research endeavor I understand it as respecting the core concepts of open-science.\n\nWhat is interesting is that in a garage you can peek in and get a sense of the tools, the dirt and a bunch of unrelated stuff and the object crafted in the workshop (furnitures, cars, computers, bombs, strange chemicals). You can see these objects in their final form but most of the time you will see them in their unfinished forms. The fact that people passing by are able to peek at the garage in the very early stages of the projects are of much interest and maybe still not very much adopted in science. I would like to experiment on this concept also. This second note of Andy explains this Anti-marketing concept nicely as https://notes.andymatuschak.org/z4bK6LaSBRetDzuYkeCs3A8mJ8DufTbK4o6FS\n\n![](/assets/images/2022-01-17-20-56-15.png)\n\nhttps://michaelnielsen.org/\nhttps://quantum.country/qcvc cf [[vault/tools.mnemonics]]\n\n# Principles\n\n> \n> _Make the first draft deliberately bad.\n> _\n> _It’s hard to write something good from nothing. But it’s easy to look at something and say “I can at least do better than this idiot.”_\n> \n> _Be the idiot._\n> \n> _Then be better. Then be better again...\n> _\n> \n> -- (https://twitter.com/cahollenbeck/status/1327296301596352512)\n\n\n## A list of similar research endeavors \n\n//TODO make a list of similar types of research strategies in academic or personal research \n\n- OSM The Open Source Malaria https://opensourcemalaria.org/. Hey they also have a fork for TB http://opensourcetb.org/\n\n- Have a look over there http://matt.might.net/.\nAlso check the CRAPL license http://matt.might.net/articles/crapl/ \n(thanks to Adriano Rutz for fwd)\n\n- http://matt.might.net/articles/programmers-resolutions/\n\n\n\nDaniel Mietchen github is a treasure trove for open science resources and actually a pretty good example of garage with an open door https://github.com/Daniel-Mietchen\n\nIt looks like Daniel has started to compile some information and examples. Here for the use of Commons in science\nhttps://github.com/Daniel-Mietchen/datascience/blob/master/commons.md\n\n\n\n\n\n\n# Links\n\n\nhttps://galaxyproject.org/jxtx/\n\nA community-centric approach https://app.jogl.io/\n","n":0.057}}},{"i":156,"$":{"0":{"v":"Test","n":1},"1":{"v":"\n![](/assets/images/2022-01-17-20-56-42.png)\n","n":1}}},{"i":157,"$":{"0":{"v":"Principles","n":1}}},{"i":158,"$":{"0":{"v":"Meetings","n":1}}},{"i":159,"$":{"0":{"v":"Mietchen","n":1},"1":{"v":"\n\n\n# Discussion between Daniel Mietchen And Pierre-Marie Allard\n\nWednesday 03 February 2021\nhttps://etherpad.wikimedia.org/p/Pierre-Marie_Allard-and-Daniel-Mietchen\n\n\n## Some starting points regarding the publishing of research ideas:\n\n* very rough https://github.com/Daniel-Mietchen/ideas/issues?q=is%3Aissue+is%3Aopen+sort%3Acomments-desc\n\n* more formally https://riojournal.com/browse_journal_articles.php?form_name=filter_articles&sortby=0&journal_id=17&search_in_=0&section_type%5B%5D=179\n\n//TODO Publish an hyper-early stage research project idea on Rio\n\n* community-centric https://jogl.io\n\n* Journal of Brief Ideas\nhttps://beta.briefideas.org/about\n\n* Nano publications \nhttp://nanopub.org/wordpress/\nLinked to RDF ? Didnt understand why ...\n\n\nData curation is somehow a neglected aspect of academic research\n\n> Data science 80% data wrangling and 20 % of cool stuff\n> \n\nNo \"dynamics\" view of the evolution of research ideas / objects\n\nhttps://www.wikidata.org/wiki/Wikidata:WikiProject_Source_MetaData\nhttps://commons.wikimedia.org/wiki/File:Usage_history_of_some_key_WikiCite_properties_as_of_January_17,_2019.png\n\nSnapshots :\n\n* video not doable\n* internet archive not precise enough, tedious\n\n\nScholia profiles\nhttps://scholia.toolforge.org/topic/Q56641686\n\nsome similarities with Inciteful.xyz ?\n\n🤔  thoughts : do we only need tools enabling to link/aggregate resources within discipline. Or should we also think about ways to enable links across disciplines. This comes with challenges : not the same keywords, not the same vocabulary potentially different way to share knowledge.\n\n## Open research\n\nhttps://en.wikipedia.org/wiki/Open_research\n\n Share it as soon as you get the result/data but also idea/process \n See introductory video \n\nNew collaborators\nhttps://github.com/Daniel-Mietchen/pledges\n\nPioneers of open research in Chemistry\n\nJean-Claude Bradley https://en.wikipedia.org/wiki/Jean-Claude_Bradley\nPeter Murray-Rust https://fr.wikipedia.org/wiki/Peter_Murray-Rust\n\n> the blue obelisk project link is not active on Peter's page. To fix.\nSo in fact there is no link to the french page of the blue obelisk project. \nSee how to make an interlanguage link https://en.wikipedia.org/wiki/Help:Interlanguage_links#:~:text=This%20help%20page%20is%20a%20how%2Dto%20guide.&text=It%20is%20not%20one%20of,levels%20of%20consensus%20and%20vetting.&text=Interlanguage%20links%20are%20links%20from,equivalent%20page%20in%20another%20language.&text=As%20links%20in%20the%20%22Languages%22%20section%20of%20the%20page's%20left%20sidebar\n\nFirst wikipedia edit :) https://fr.wikipedia.org/w/index.php?title=Peter_Murray-Rust&oldid=179529908\n\nAlso added links to Panton Principles and the World Wide Molecular Matrix\nhttps://fr.wikipedia.org/w/index.php?title=Peter_Murray-Rust&oldid=179531097\n\n\n## Concrete societal impact of research / open-research\n\nBiodiversity conservation \n\n\nhttps://doi.org/10.3389/fcosc.2020.615419   \nUnderestimating the Challenges of Avoiding a Ghastly Future\n\nNote the Ghastly keyword \n\n> We should marketing specialist prepare our research paper titles so they get picked up by the media !\n\n\n## Documenting research is also valuable for teaching.\n\nIf you have open access to lab book of a researcher then students can at least no stay in the textbooks only but also get a direct feeling or even interaction (pull request/comments) of frontier research.\n\nhttps://github.com/Daniel-Mietchen/learning2code\n","n":0.058}}},{"i":160,"$":{"0":{"v":"Garage Garage","n":0.707},"1":{"v":"# Garage|garage\n\n","n":0.707}}},{"i":161,"$":{"0":{"v":"Docker","n":1}}},{"i":162,"$":{"0":{"v":"CLI","n":1},"1":{"v":"\n\nsudo docker kill $(sudo docker container ls -q)\n","n":0.354}}},{"i":163,"$":{"0":{"v":"Dendron","n":1}}},{"i":164,"$":{"0":{"v":"Workflows","n":1}}},{"i":165,"$":{"0":{"v":"Meetings","n":1},"1":{"v":"\n# Meeting Notes\n\nThis is a video of keeping meeting notes in Dendron. Meeting notes are kept as **journal notes** on a per-project basis. \n\n<a href=\"https://www.loom.com/share/c04dd4b3c82a412b82b1f9f75e2291bd\">  <img style=\"\" src=\"https://cdn.loom.com/sessions/thumbnails/c04dd4b3c82a412b82b1f9f75e2291bd-with-play.gif\"> </a>\n\n## Resources\n\nSettings and files used for the above video. \n\n- project schema\n```yml\n- id: pro\n  title: pro\n  desc: \"\"\n  parent: root\n  namespace: true\n  children:\n    - people\n    - meet\n    - todo\n    - retrospective\n- id: people\n- id: meet\n- id: todo\n- id: retrospective\n```\n\n- journal specific settings\n\n```json\n{\n    \"dendron.defaultJournalAddBehavior\": \"childOfDomainNamespace\",\n    \"dendron.defaultJournalDateFormat\": \"Y.MM.DD\",\n}\n```\n","n":0.116}}},{"i":166,"$":{"0":{"v":"Welcometodendron","n":1},"1":{"v":"\n# Welcome to Dendron 🌲\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/logo-256.png)\n\nDendron is a new approach to note taking, one that combines the freedom of Roam's *every note exists everywhere philosophy* with the organization provided by *flexible hierarchies*. \n\nWe call this the [hierarchy first approach](https://www.kevinslin.com/notes/3dd58f62-fee5-4f93-b9f1-b0f0f59a9b64.html) to note taking.\n\n## What is a Dendron?\n1. Dendron is the greek word for tree. It's a reference to the hierarchal note taking that Dendron(3) enables. \n2. Dendron is another word for [dendrite](https://en.wikipedia.org/wiki/Dendrite) which is an extension of the nerve cell that sends and receives signals in the brain. Think of Dendron(3) as a digital nervous system that helps you consolidate all the information that you care about in the fastest and most efficient way possible.\n3. Dendron is a local-first, markdown based, hierarchical note taking tool. It is meant to help you build, organize, and share knowledge bases of any size.\n\n## How do I get started?\n\n1. Launch the _command bar_ inside vscode:\n    - Linux: `Ctrl+Shift+P`\n    - macOS: `Cmd+Shift+P`\n    - Windows: `Ctrl+Shift+P`\n2. Paste the following command and press `Enter`:\n\n```bash\n> Dendron: Initialize Workspace\n```\n\n![Initialize workspace](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/dendron-init.gif)\n\nWhen the workspace opens, it will show dialogue to install additional recommended extensions. \n","n":0.074}}},{"i":167,"$":{"0":{"v":"Vega","n":1},"1":{"v":"\n# Vega\n\nInteractive vega display are available in VSCode.\nThis would be an amazing option to have such pages uploadable to a dendron published space.\n\n//TODO investigate vega display in dendron\n\nBut maybe, meanwhile a quick vega link is the best workaround\n\n[Open the Chart in the Vega Editor](https://vega.github.io/editor/#/url/vega/N4IgJAzgxgFgpgWwIYgFwhgF0wBwqgegIDc4BzJAOjIEtMYBXAI0poHsDp5kTykSArJQBWENgDsQAGhAATONABONHJnaT0AQQAEUJABs442UkXbiNCAwM0AXkjUTtbAGbaTNfQE9dMJOLIFbUw2YPhtAGUAMgAFbQEABgTtCBpxKDhtACYkhMppEBwkWVk0sjQBGVSycQMINABtUFqEODQQCEw4HALiAwY21ABGADYAXylmpFb21xcIOExe-sGhhImpmfQAdxpZegKGHBMu9s7u7QAqeKztAGpnF3nFq+0hoZANkBbBjDgaMhYQ7HBy-c44V4CT6Tb7TMGwRBtGR9fQDdo4NIAay8cH0+jY2zIijgRgKTDSsjQoDSOAYS3QC0MUCWMjYqnU9VQDUKWJxeIJRJJkhkTFRcDYin8gTJigJ4lFA0FpJktMUOEMSuFhQYasMEqlSJAxNkCsNxsFXgKxr5+O2pqtcFkNoFxOVHRwcGZkv0IAAumMxr6ZCcUFzNmCcIkEodFD70CHOJGkgBaHJJShQCDEAouCXIemgTBeD3tTPZlWmBZUkBQfFV9DiBgIJhwRQFE6-DufCYgTCS8QQXOKBCNQvF367YwEgpiRQFkAuGi4ynx0EFCXyNvoJDQIylALQkBsznc-RIcpBhdL-SyE81uttS87xqFYnZ-0wosl9BDhAMM8FHAAAeOBbnIDhNpQoFwMQ2gAPzaAAFCckG1mwCzaMm7gQQgUFvgAlNoBDYZgkHQbBqDaNGMjPugKJol8X6-L+-4oDIwGge0OKmMhOGUB2+EFLRIDcW2jHju0aitAw4h0Dm14ruBpwyDJdB3qJBTbCSmJ+jRd7bNRIDbB8H5jt+C55qxgEgWBUlwAA8k8CyYIhADkJheK5UgkZBBmCXp7QGdCZm-HZqksley7tF2KmyZgd4ebpIC0dysiGbIJmBoGVR6IYJ7hlxBRMe0TD+JSwZsMgaTViGZxJoZi5RfGhmzvSfYDD2-bSqgoDgtW1S1HGHRdD0AZfD8pZsPibYyMV6D6GkcCmAUtbTD0qDtXAMhdYMvUIlsvUAoNZz7W0AYVVVGgNMmeQJCMUgJA9lB3f6l4anu+VXnik3TUVdCGO0AAiSCeD4ADCfgBFtkSxPESR-ZghgAGISJgER2KsWSzf9DnKEY9IgIYLgRWoiNwDExT7uUqA5KyTmLGgQyVEeePiATIQ9LNEnoESxRLmz7Y0MSzLqO0MASnYqMGAUvOlPjAAyRhkAcNOJDIsv85gAAqMA0FAmLiAonJrDIv4OO0ACknxvUgXhsHS1ZQFNTYDozFYlGUjMCD2yCKJin1zSARL25zC6yiOPULkgGTzrVDL1QUE10Ss9Tq7KRxMJa6AaedHQSvOjU3tFfEaayiibtFCgZMYns9nHTSwlsIDIEBM724oGTtPRChFf2g55qOvbc8lZCChQylHngL4t0lhe3i+XaveNcKBdpqe9n3v6D4HCwAI4DOkhqdKY9KPcNbIVAAzAFOzaY2I7ieZLEAexNnF10dmIUUxJs5QoneY9N49wfK4S0nAA2TZXgAHZ-LJU5EpM6n5h5hTiocOK6klozSMtpWeCl36GhSkZQyxk-SP2YpZF+IAOK2RoK0RyzwXLuVtl5EBlA-JCXgUFMh7RFz6C6Fg6h79IIdm0AAHhIkgNyLdXL4QaAkX0lAW4AH0uxZUvNAAwPcwyN1+K3Lm5lSrGHbJVEGGhQBx2weA9ec9AotXzmgTanUDT9RGv1I60sGSuLGk+ICWiG4S3xu0ImEUNEA2zn9fWnIXB1C2nIEx1VUDRP0AsGQZ4Wz6Aph7A8qAAAcps8zm3QBbNiFlhwOC1sg2hhpSZhMOjUDxhRTD4z-pgw8NS4CaACGEs+7TNALRqO0ZQgISY4wABpoGTHk3sOMACaEysbTLJijNm6NbCrHWDCAJAt0AcxnLlXRET-ZoCSSkuJl1jkxPyWUgmFsmA5gKdrSpMxUlIHSX0o6QS4DE0AukNg8hqxpNxJyUARwuyR1bpHUJBzTZ4OTmKMkZU0BnzmM5Nx9ShoIFRjAXipFcLd0ItcFFDNc5smjnQLOdTjqri6DiyC+KxHaByfBIBlFoxjQDJeX2RztGB2FhFFw4caoOFDCAbu9QexGCdv8yO+NWzVghXtTR7Q9GRSLjsQyRL5wDQaZitm2KUK4QEq8TV3YZC7H2DAfq+zlUIqMcMOmDCJlDB7BSjo1rwkwqanINlMh4AAiBJC91IlbUriGA61FqBkzOpkE7RQhtFAACU+YMGBaKlYaAsg9hCFNNQ61KUNLsija5tLDWgm8q5Yp2hblVtkN5C2MyZHANcgAHWbeIVywCzYuQNZQbu5a7iUCyBbGRpqQCgrXJHXhcZFVhJrFNCU8kvXd27ByrKQA/view)\n\n\nNB:  \n\nBefor loosing time on the tool remember about the question. What exactly am I trying to solve here ?\nData viz. OK for sure but do I have vega ready data ? The ones generated by Emperor and qiime display ... \nLet's see if it worth putting time into this.\n","n":0.104}}},{"i":168,"$":{"0":{"v":"Tasks","n":1},"1":{"v":"Testing the dendron task options and functionalities \n\nhttps://wiki.dendron.so/notes/SEASewZSteDK7ry1AshNG/\n\n\n[[dendron.tasks.test-task]]\n","n":0.354}}},{"i":169,"$":{"0":{"v":"Test Task","n":0.707},"1":{"v":"This is a higly important task created with Dendron\n\nMonday 29 November 2021\n","n":0.289}}},{"i":170,"$":{"0":{"v":"Questions","n":1},"1":{"v":"\n# dendron export markdown preview note to html and share\n2021-01-28 09:46\n\nFor now I need to manually save the file to .html and share it via a dropbox link.\nMPE has an export_on_save option however this is not active in Dendron MPE Could it be possible to have in activated.\nElse what are the option you would propose to share an html rendered markdown file (ideally with a clickable TOC as a sidebar)\n\n\n# dendron snippets definition\n~~I changed my workspace to the direct upper level (in order to have dendron.yml file and all in the VSCode sidebar). It appears to work however now i dont have more completion of my snippets (todo, time etc.)\nIs it linked ?~~ Yes, as I understand it now, the snippets should be in the dendron.code-snippets.json file in the .vscode folder of the current workspace.\n\n\n\n# dendron copy notes across vaults\n\n\nvault1\n    root\n    notes\n    project\n    project.pr1\n    project.pr1.context\nvault2\n    root\n    blabla\n    project\n    project.pr1\n    project.pr1.context\n","n":0.082}}},{"i":171,"$":{"0":{"v":"Progressbar","n":1},"1":{"v":"\n# Different implementation of a progress bar \n\n## Works when published\n\n<iframe src=\"https://progress-bar.dev/34\" frameborder=\"0\" scrolling=\"0\" width=\"170\" height=\"30\" title=\"34\"></iframe>\n\n## Works only locally\n![ ](https://progress-bar.dev/70)\n\nhttps://progress-bar.dev/35\n\n## Added a snippet \n\n    \"pbar\": {\n        \"prefix\": \"pbar\",\n        \"scope\": \"markdown,yaml\",\n        \"body\": \"<iframe src=\\\"https://progress-bar.dev/${1:25}\\\" frameborder=\\\"0\\\" scrolling=\\\"0\\\" width=\\\"170\\\" height=\\\"30\\\" title=\\\"${1}\\\"></iframe>\",\n        \"description\": \"pbar\"\n    }\n\n<iframe src=\"https://progress-bar.dev/23\" frameborder=\"0\" scrolling=\"0\" width=\"170\" height=\"30\" title=\"23\"></iframe>\n","n":0.144}}},{"i":172,"$":{"0":{"v":"Multivault","n":1},"1":{"v":"\n# What are we talking about ?\n\nMultivault configuration is a way to put your Dendron notes into compartements.\nMultiple reason can lead you to head towards a multivaults setup. \nHere are some of them https://wiki.dendron.so/notes/24b176f1-685d-44e1-a1b0-1704b1a92ca0.html#use-cases\n\nHowever they are multiple ways of setting up a multivault configuration.\nIn my case I have been wanting to set this up for a long time and tried at least 3 times with no success. \n\n# Why this note ?\n\nSo I will write a note regarding the recipe I followed for what seems to be (up to now) a convenient solution for me. This is a note for my future self but also for people how have been having difficulties to setup up a multivault configurations.\n\n# What do I want ?\n\nMy requirements were the following ones:\n\n- at least two vaults but possibility to accomodate more if needed\n- all vaults should be git versioned and have a remote repo (github)\n- the vaults should be git versioned on a private or public git repo \n- all vaults should be possibly publishable as github pages\n\n\nOne thing that confounded me at first was the distinction between vaults and workspace.\nAfter enough trial an error the setup I adopted is the following one.\n\n# What do I have now ?\n\nI have 3 dendron **workspaces**. \n\n- **dendron-global**\n- **dendron-ws-private**\n- **dendron-ws-public**\n\n**dendron-global** and **dendron-ws-private** are git-versioned on a private github repos (https://github.com/oolonek/dendron-global and https://github.com/oolonek/dendron-ws-private, respectively) while **dendron-ws-public** is versioned on a public repo (https://github.com/oolonek/dendron-ws-public). \n\nI did a 'Dendron: Vault add' command from the **dendron-global** vault to incorporate **dendron-ws-private** and **dendron-ws-public**.\n\nAs a result I have three websites:\n\nhttps://oolonek.github.io/dendron-global/\nhttps://oolonek.github.io/dendron-ws-private/\nhttps://oolonek.github.io/dendron-ws-public/\n\nThese reflect their own vaults (**dendron-ws-private** and **dendron-ws-public**) or the totality (dendron-global). \n\n\nSee flowchart below : \n\n```mermaid\n flowchart TB\n   subgraph dendron-global-workspace\n     dendron-global-workspace-vault.dendron-global-workspace[dendron-global-workspace-vault]\n   subgraph dendron-ws-private-workspace\n     dendron-ws-private-vault.dendron-ws-private-workspace[dendron-ws-private-vault]\n   end\n   subgraph dendron-ws-public-workspace\n     dendron-ws-public-vault.dendron-ws-public-workspace[dendron-ws-public-vault]\n   end\n   end\n   dendron-global-workspace --> dendron-global.git\n   dendron-ws-private-workspace --> dendron-ws-private.git\n   dendron-ws-public-workspace --> dendron-ws-public.git\n   dendron-global.git --> dendron-global.gitpage\n   dendron-ws-private.git --> dendron-ws-private.gitpage\n   dendron-ws-public.git --> dendron-ws-public.gitpage\n```\n\nWhere : \n\n- dendron-global.git is https://github.com/oolonek/dendron-global \n- dendron-ws-private.git is https://github.com/oolonek/dendron-ws-private\n- dendron-ws-public.git is https://github.com/oolonek/dendron-ws-public\n\nand\n\n- dendron-global.gitpage is https://oolonek.github.io/dendron-global/\n- dendron-ws-private.gitpage is https://oolonek.github.io/dendron-ws-private/\n- dendron-ws-public.gitpage is https://oolonek.github.io/dendron-ws-public/\n\n# Recipe\n\n- Initialize a new workspace by cmd+shit+p Dendron:Initialize Workspace\nName it as you want but let the default vault name as vault\n\n- Go to Github and create new private or public repo as you wish\n\n- Open VSCode at the workspace level (not at the vault level) and in terminal:\n\n```\ngit init\ngit add . \ngit commit -m 'initial commit'\ngit remote add origin https://github.com/oolonek/dendron-global.git\ngit push -u origin main\n(complains)\ngit pull origin main  \ngit config pull.rebase true\ngit pull origin main  \ngit push -u origin main\n```\n\n- repeat the previous steps for the two other workspaces\n\n- We set up the repo so that they are publish automatically using the gh actions\n\nhttps://wiki.dendron.so/notes/230d0ccf-5758-4a8f-b39b-3b68e1482e2b.html\nand \nhttps://wiki.dendron.so/notes/877f4347-f013-43ba-aec4-87412b2e1bec.html\n\nBut follow only the steps required for gh action triggered publishing (no need for local publishing first)\nSo just change your dendron.yml  by adding\n\n```\n    siteUrl: https://oolonek.github.io\n    assetsPrefix: dendron-ws-public\n```\n\n- To create the package.json at the ws roots we run from the terminal\n\n```\nnpm init -y\nnpm install @dendronhq/dendron-cli@latest\nnpm install @dendronhq/dendron-11ty@latest\n```\n\n- We modify the dendron.yml to have the gh edit link\n\n```\n    gh_edit_link: true\n    gh_edit_link_text: Click here to edit this page on Github !\n    gh_edit_repository: 'https://github.com/oolonek/dendron-ws-public'\n    gh_edit_branch: main\n    gh_edit_view_mode: edit\n    assetsPrefix: dendron-ws-public\n```\n\n- Repeat for all repos. \n\n- Check that all websites publish correctly when you push a new note.\n\n- Now at the vault level (not workspace level) of your global workspace (here called dendron-global in the previous schema) you cmd+shit+p Dendron: Vault Add/remote and paste the github adress of the repos you want to integrate.\nThis should automatically upgrade the dendron.yml of the global workspace.\n\n- The last step is important else you will not be able to publish from the global repo. You need to add checkout actions to the .github/workflows/dendron-actions.yml See example below to checkout a publi and a private repo:\n\n```\n            - name: Checkout source\n              uses: actions/checkout@v2\n\n            - name: Checkout public repo\n              uses: actions/checkout@v2\n              with:\n                repository: oolonek/dendron-ws-public\n                path: dendron-ws-public\n\n            - name: Checkout private repo\n              uses: actions/checkout@v2\n              with:\n                repository: oolonek/dendron-ws-private\n                token: ${{ secrets.BUILD_ACCESS_SECRET }} # `GitHub_PAT` is a secret that contains your PAT\n                path: dendron-ws-private\n\n```\n\nNote that you will need to prepare a PAT if you pull from a private repo.\n\n# Questions or editions\n\nPlease comment directly on github by clicking the link below 👇\n\n\n\n\n\n","n":0.038}}},{"i":173,"$":{"0":{"v":"New_recipee","n":1},"1":{"v":"\n# New recipee (draft) fro multivault setup\n\nThursday 02 December 2021 \n\nSince some time the 11ty publishing system as changed and this implies some modification on the previous multivault procedure.\nI will try to summarise the steps here while setting up a dendron fro a MAPP collaborator\n\n\nCreate private git \nClone private git\nctrl shit p initilaize workspace\npush to git\n\nWe then follow stuff here https://wiki.dendron.so/notes/e5st4LFLtIwwbQmC6JBaF/\n\n\nnpm install -g @dendronhq/dendron-cli\n\n\nnpm install -g yarn\n\necho .next >> .gitignore\n\ndendron publish init\n\n\nhttps://wiki.dendron.so/notes/FnK2ws6w1uaS1YzBUY3BR/\n\n\nnpm init -y \nnpm install --save @dendronhq/dendron-cli\n\ngit checkout -b pages\ngit push -u origin HEAD\n\n\ngit checkout main\n\nmkdir -p .github/workflows\nni .github/workflows/publish.yml\n\n\n","n":0.105}}},{"i":174,"$":{"0":{"v":"CLI","n":1},"1":{"v":"\n# add batch extensions to files\n\nfor f in *; do mv \"$f\" \"$f.txt\"; done\n\n\n# lists one file per line\n\nls -1a\n\n\n# list files and their path\n\nls -d -1 \"$PWD/\"*.*\n\nsee https://stackoverflow.com/a/3572628\n\n# find files and order by date \n\nfind ~/ -type f -name \"*.key\" 2> /dev/null | xargs -0 ls -tl\n\n\n# check stockage via terminal\n\ndf -h\n\ndu -h /my/folder\n\n","n":0.135}}},{"i":175,"$":{"0":{"v":"Vscode","n":1},"1":{"v":"\n# Multicursor editing in vscode\n\nhttps://tahoeninjas.blog/2019/03/30/multi-cursor-editing-in-visual-studio-code/\n\n\nCTRL+ALT+ ↑ / ↓: Select next/previous line\nALT-CLICK: Create cursors\nCTRL-U: Undo last cursor operation\nCTRL-SHIFT-L: Select current match\n\n# Fold markdown \n\nVisual Studio Code now supports code folding for Markdown documents by heading. Folding a header collapses all content and subheadings under that header. \nCMD + K + CMD + 0/1/2/3 — to fold\nCMD + K + CMD + J — to unfold","n":0.125}}},{"i":176,"$":{"0":{"v":"Vim","n":1},"1":{"v":"\n# delete a line \n\ndd\n\n# undo\n\nu\n\n# exit\n\nesc :q\n\n# save and exit\n\nesc :wq\n\n\n\n","n":0.289}}},{"i":177,"$":{"0":{"v":"Tar","n":1},"1":{"v":"\n\n## tar command lines \n\nTo create a tar.gz archive from a given folder you can use the following command. This will compress the contents of source-folder-name to a tar.gz \narchive named tar-archive-name.tar.gz\n\n```bash\ntar -zcvf tar-archive-name.tar.gz source-folder-name\n```\n\nTo extract a tar.gz compressed archive you can use the following command\n\n```bash\ntar -zxvf tar-archive-name.tar.gz\n```\n\nIf its a gzipped file\n\n```bash\ngzip -d tar-archive-name.tar.gz\n```\n\nThis will extract the archive to the folder tar-archive-name.\n\nTo Preserve permissions\n\n```bash\ntar -pcvzf tar-archive-name.tar.gz source-folder-name\n```\n\nSwitch the ‘c’ flag to an ‘x’ to extract (uncompress).\n\n```bash\ntar -pxvzf tar-archive-name.tar.gz\n```\n","n":0.113}}},{"i":178,"$":{"0":{"v":"Sed_bash","n":1},"1":{"v":"\n[[#oneday|tag.oneday]]\nautomate with a sed script ? the bib cleaning \n\nSome sed black magic \n\n```bash\necho \"\\{\" | sed \"s|\\\\\\{|\\\\\\'{|\"\n````\nDouble \\\\ to escape the \\\\\n\nAnd repeat \n\n```bash\necho \"\\{jhdgjshgjhfsjdhgf\\}\" | sed \"s|\\\\\\{|\\\\\\'{|g; s|\\\\\\}|\\\\\\'}|g;\"\n````\nNow add input and outputs \n\n```bash\nsed \"s|\\\\\\{|\\\\\\'{|g; s|\\\\\\}|\\\\\\'}|g\" library.bib > library_formatted.bib\n```\n\nWe'll try to automatize the process using https://stackoverflow.com/a/13807906 fswatch and alternative to inotifywatch on linux https://linux.die.net/man/1/inotifywatch\n\nSo here is the small bash script. It will take the command line arg 1 and add the _formatted prefix to it. Could be cleaner and directly extract the filename to accomodate for various type of extension. Not the point here. If any body has an idea, please contribute ! :point_down: \n\n\n```bash\n#!/bin/bash\nsed \"s|\\\\\\{|\\\\\\'{|g; s|\\\\\\}|\\\\\\'}|g\" \"$1\" > \"${1%.bib}_formatted.bib\"\n```\n\n```bash\n#!/bin/bash\n\n# fullfilename=\"$(basename $1)\"\n# extension=\"${fullfilename##*.}\"\n# filename=\"${fullfilename%.*}\"\n\n# echo $fullfilename\n# echo $extension\n# echo $filename\n\n#echo \"File added: \" \"$(basename $1)\" \"$(basename $1)\"\nsed \"s|\\\\\\{|\\\\\\'{|g; s|\\\\\\}|\\\\\\'}|g\" \"$1\" > \"./formatted_bib/${filename}_formatted.bib\"\n\n````\n\n\n\n\nfswatch has been somehow a nightmare to understand ...\n\nto trouble shoot use the follwoing line to be sure of what exactly you take as input \n\n```bash\nfswatch -0 ./mendeley_output/ | xargs -0 -n1 -I{} echo \"{}\"\n```\n\n## quick replace in text file\n\n`sed -i 's/original/new/g' file.txt`ze\n","n":0.076}}},{"i":179,"$":{"0":{"v":"Csv","n":1},"1":{"v":"https://www.stefaanlippens.net/pretty-csv.html\n\n\nplaceholder (testing submodule)\n","n":0.577}}},{"i":180,"$":{"0":{"v":"Arutam","n":1},"1":{"v":"\ncc\n","n":1}}},{"i":181,"$":{"0":{"v":"Plant Status","n":0.707},"1":{"v":"\n(ZK imported)\n\n\n\n\n\n# Un appel a propositions pour repenser le statut des plantes.\n\nhttps://lapenseeecologique.com/repenser-le-statut-des-plantes/\n\nUn tournant ontologique est observé dans les sciences sociales qui se mettent a intégrer (à très faibles doses sans doute) des entités non-humaine.\nQuatre chercheurs en agro, sciences sociales, écologie et foresterie le propose.\nAurélie Javelle (ingénieure de recherche à Montpellier Supagro), Dusan Kazic (doctorant en sociologie, AgroParisTech), Jacques Tassin (chercheur en écologie au Cirad), et Ernst Zürcher (chercheur et ingénieur forestier à la Haute École spécialisée bernoise).\n\n\nComment entrer en relations avec les plantes de façon sensible ? <<<en les intégrant>>\nIci les psychotropes semble etre la voie royale. Ce qui amène a voir la chimie comme moyen de connexion entre l'humain et le végétal. Et a penser la molécule comme signal sémiotique porteur de sens (entre plantes mais aussi entre plantes et humains).\n\nADN (objet biologique porteur d'information par excellence - code) > Enzymes > Molécules > Récepteurs 5HT > Pensées complexes > ADN (recursive process) [[recursive]]\n\nContinuer les recherches sur la biosémiose et toutes les investigations effectuées dans ce sens par l’équipe de l'Université de Turku.\nAlso investigate recursive processes. https://fr.wikipedia.org/wiki/R%C3%A9cursivit%C3%A9\n\n//Done schema and diagrams in markdown\nMove this in a separate note. Again check amoeba pattern\n\n\n2021-01-17 13:44\n\nTesting Mermaid with dendron md preview plugins \n\n```mermaid\ngraph TD;\n    A-->B;\n    A-->C;\n    B-->D;\n    B-->C;\n    C-->D;\n    D-->A;\n    D-->B;\n```\n\n\n```mermaid\ngraph TD;\n    DNA-->Enzymes;\n    Enzymes-->Molecules;\n    Molecules-->Receptors-5HT;\n    Receptors-5HT-->Complex_thoughts;\n    Complex_thoughts-->DNA;\n    Complex_thoughts-->Enzymes;\n    Complex_thoughts-->Molecules;\n    Complex_thoughts-->Receptors-5HT;\n    Complex_thoughts-->Complex_thoughts;\n```\n\nThis should appear like the image below, when https://github.com/dendronhq/dendron/issues/454 is addressed.\n\n![](/assets/images/2021-01-17-14-17-22.png)\n","n":0.066}}},{"i":182,"$":{"0":{"v":"Documents","n":1},"1":{"v":"\n\n# Propositions pour un retour sur terre\n\n(pasted from Sublime ZK)\n\n\nLu manifesto de Dominique Bourg et Pablo Servigne (entre autres) Propositions pour un Retour a la Terre (fev 2020)\n\nhttps://lapenseeecologique.com/propositions-pour-un-retour-sur-terre/\nApparemment down (2021-01-17 12:57) https://www.terrestres.org/2020/04/30/propositions-pour-un-retour-sur-terre/\n\n## Notes de lecture:\n\nTrès intéressant. Relativement technique sur certains point notamment au niveau des mesures économiques et présente de trop nombreux acronymes.\n\nMais sinon présente une série de mesures divisée en \n\n1. mesure économiques\n2. mesure étatiques\n3. mesures internationales\n\nSouligne le rôle clef de l'état dans une ré-orientation de notre système capitaliste.\n\n\n# Gregory Giuliani \n\nLecture d'un bref interview de Gregory Giuliani sur le mag de l'unige (https://www.unige.ch/lejournal/ejournal/ejournal03/climat-coronavirus)\n\nGregory Giuliani est responsable du Swiss Data Cube.\nLe Swiss Data Cube a pour objectif de standardiser les data de remotely sensed EO (Earth Observation) via des data cubes. \nDes structures standardisées permettant d'exploiter de façon optimal de set multidimensionnels et nécessairement complexes d'EO de différents type.\n\n\nUn des projet actuel, dans le cadre de la crise Covid est donc d’évaluer les liens entre pollution atmosphérique et mortalité covid.\n\nL'interview est légèrement bateau mais effectivement, comme le dit Gregory Giuliani, l'impact positif de la crise corona ne pourra se faire sentir post-déconfinement que si l'on \"garde les bonnes habitudes\" et que l'on poursuit se mouvement a peine amorcé durant cette brève période :\n- d'avion\n- de voitures\n- de conso\n+ de local.\n\nFaire des recherche sur les façons de \"conserver ces bonnes habitudes\".\n","n":0.067}}},{"i":183,"$":{"0":{"v":"Biodiversity","n":1}}},{"i":184,"$":{"0":{"v":"Value","n":1},"1":{"v":"\n(ZK imported)\n\nTHe VALUE of biodiversity is NOT the same as it's PRICE.\n\nIt is a complex task to evaluate the contribution of biodiversity for human economic growth, since this same growth is directly and negatively impacting biodiversity.\nHowever, despite this complexity, an argument to lead such a task is that establishing the value of biodiversity helps policy makers worldwide understand that there is a COST in loosing Nature.\n\n- [ ] find sources again \n  \n","n":0.117}}},{"i":185,"$":{"0":{"v":"Conservation","n":1},"1":{"v":"\nAn article from UniGe on the dangers and death threats faced by conservation activists across the globe\n<https://www.unige.ch/lejournal/analyse/archives/larsen>\n\n@Kagansky @Bio2Bio @RSI\n\n#Kagansky\n\n[#kagansky]\n\n\n\n2021-02-10 18:10\n\n \n\n# Raviver les braises du vivant. Baptiste Morizot (reading ...)\n\n\n\nFoyers de libre évolution:\n\nhttps://www.neozone.org/ecologie-planete/vercors-une-extraordinaire-cagnotte-de-235-millions-deuros-pour-acheter-et-proteger-500-hectares-de-nature-sauvage/\nhttps://www.helloasso.com/associations/foret-vivante/collectes/achat-collectif-de-forets-a-thones\n\n\nA micro echelle:\n\nhttps://www.leboncoin.fr/ventes_immobilieres/1925363991.htm?ac=558505705\nhttps://www.leboncoin.fr/ventes_immobilieres/1748629342.htm?ac=558505705\n\nASPAS https://www.aspas-nature.org/\n\n\n","n":0.167}}},{"i":186,"$":{"0":{"v":"Argdown Scratch 2021 02 01 122240 Argdown","n":0.378},"1":{"v":"# Argdown|scratch.2021.02.01.122240.argdown\n\n","n":0.707}}},{"i":187,"$":{"0":{"v":"Academics","n":1}}},{"i":188,"$":{"0":{"v":"Publication","n":1},"1":{"v":"# Alternative publication strategies\n\n\nhttps://beta.briefideas.org/\nhttps://riojournal.com/\n\n\nShould try to publish at least one in each of the above this year [[pledge]]\n\nhttps://github.com/openjournals/brief-ideas\n\n\n\nhttps://github.com/openjournals\nNote related to [[garage.principles]]\n\nLook into Rio Thematic collection \nhttps://github.com/Daniel-Mietchen/ideas/issues/1484\n\n","n":0.196}}}]}
